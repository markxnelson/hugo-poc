[
{
	"uri": "/weblogic-kubernetes-operator/security/domain-security/image-protection/",
	"title": "Docker Image Protection",
	"tags": [],
	"description": "WebLogic Domain in Docker Image Protection",
	"content": " WebLogic Domain in Docker Image Protection Oracle strongly recommends storing the Docker images that contain a WebLogic Domain Home as private in the Docker registry. In addition to any local registry, public Docker registries include Docker Hub and the Oracle Cloud Infrastructure Registry (OCIR).\n\rThe WebLogic Domain home that is part of a Docker based image contains sensitive information about the domain including keys and credentials that are used to access external resources (e.g. datasource password). In addition, the Docker image may be used to create a running server that further exposes the WebLogic Domain outside of the Kubernetes cluster.\nThere are two main options to pull images from a private registry:\n Specify the image pull secret on the WebLogic Domain resource Setup the ServiceAccount in the domain namespace with an image pull secret  A) Use imagePullSecrets with the Domain Resource In order to access Docker image that is protected by a private registry the imagePullSecrets should be specificed on Kubernetes Domain resource defintion:\napiVersion: \u0026quot;weblogic.oracle/v2\u0026quot; kind: Domain metadata: name: domain1 namespace: domain1-ns labels: weblogic.resourceVersion: domain-v2 weblogic.domainUID: domain1 spec: domainHomeInImage: true image: \u0026quot;my-domain-home-in-image\u0026quot; imagePullPolicy: \u0026quot;IfNotPresent\u0026quot; imagePullSecrets: - name: \u0026quot;my-registry-pull-secret\u0026quot; webLogicCredentialsSecret: name: \u0026quot;domain1-weblogic-credentials\u0026quot;  To create the Kubernetes secret called my-registry-pull-secret in the namespace where the domain will be running, domain1-ns, the following command can be used:\n$ kubectl create secret docker-registry my-registry-pull-secret \\ -n domain1-ns \\ --docker-server=\u0026lt;registry-server\u0026gt; \\ --docker-username=\u0026lt;name\u0026gt; \\ --docker-password=\u0026lt;password\u0026gt; \\ --docker-email=\u0026lt;email\u0026gt;  For more information about creating Kubernetes secrets for accessing the registry, see the Kubernetes documentation about pulling an image from a private registry.\nB) Setup the Kubernetes ServiceAccount with imagePullSecrets An additional option for accessing a Docker image protected by a private registry is to setup the Kubernetes ServiceAccount in the namespace running the WebLogic Domain with a set of image pull secrets thus avoiding the need to set imagePullSecrets for each Domain resource being created (as each resource instance represents a WebLogic Domain that the operator is managing).\nThe Kubernestes secret would be created in the same manner as shown above and then the ServiceAccount would be updated to include this image pull secret:\n$ kubectl patch serviceaccount default -n domain1-ns \\ -p '{\u0026quot;imagePullSecrets\u0026quot;: [{\u0026quot;name\u0026quot;: \u0026quot;my-registry-pull-secret\u0026quot;}]}'  For more information about updating a Kubernetes ServiceAccount for accessing the registry, see the Kubernetes documentation about configuring service accounts.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/security/certificates/",
	"title": "Certificates",
	"tags": [],
	"description": "WebLogic Operator SSL/TLS certificate handling",
	"content": " Reference  Configure the external REST interface SSL/TLS identity REST interface configuration settings Sample to create external certificate and key  Updating operator external certificate If the operator needs to update the external certificate and key currently being used or was installed without an external REST API SSL/TLS identity, the helm upgrade command is used to re-start the operator with the new or updated kubernetes tls secret that contains the desired certificate(s).\nThe operator requires a re-start in order to begin using the new or udpated external certificate. The Helm --recreate-pods flag is used to cause the existing kubernetes pod to be terminated and a new pod to be started with the updated configuration.\nFor example, if the operator was installed with the Helm release name weblogic-operator in the namespace weblogic-operator-ns and the kubernetes tls secret is named weblogic-operator-cert, the following commands can be used to update the operator certificate(s) and key:\n$ kubectl create secret tls weblogic-operator-cert -n weblogic-operator-ns \\ --cert=\u0026lt;path-to-certificate\u0026gt; --key=\u0026lt;path-to-private-key\u0026gt; # $ helm get values weblogic-operator # $ helm upgrade --wait --recreate-pods --reuse-values \\ --set externalRestEnabled=true \\ --set externalRestIdentitySecret=weblogic-operator-cert \\ weblogic-operator kubernetes/charts/weblogic-operator  "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/ingress/nodeports/",
	"title": "Nodeports",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/samples/simple/domains/manually-create-domain/",
	"title": "Manually",
	"tags": [],
	"description": "",
	"content": " Manually creating the domain custom resource In some circumstances you may wish to manually create your domain custom resource. If you have created your own Docker image containing your domain and the specific patches that you require, then this approach will probably be most suitable for your needs.\nTo create the domain custom resource, just make a copy of the sample domain.yaml, and then edit it as per the instructions provided in the comments in that file. When it is ready, you can create the domain in your Kubernetes cluster using the command:\n$ kubectl apply -f domain.yaml  You can verify the domain custom resource was created using this command:\n$ kubectl -n YOUR_NAMESPACE get domains  You can view details of the domain using this command:\n$ kubectl -n YOUR_NAMESPACE describe domain YOUR_DOMAIN  In both of these commands, replace YOUR_NAMESPACE with the namespace that you created the domain in, and replace YOUR_DOMAIN with the domainUID you chose.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/samples/simple/credentials/",
	"title": "Credentials",
	"tags": [],
	"description": "",
	"content": " Creating credentials for a WebLogic domain This sample demonstrates how to create a Kubernetes secret containing the credentials for a WebLogic domain. The operator expects this secret to be named following the pattern domainUID-weblogic-credentials, where domainUID is the unique identifier of the domain. It must be in the same namespace that the domain will run in.\nTo use the sample, run the command:\n$ ./create-weblogic-credentials.sh -u username -p password -d domainUID -n namespace -s secretName  The parameters are as follows:\n -u user name, must be specified. -p password, must be specified. -d domainUID, optional. The default value is domain1. If specified, the secret will be labeled with the domainUID unless the given value is an empty string. -n namespace, optional. Use the default namespace if not specified. -s secretName, optional. If not specified, the secret name will be determined based on the domainUID value.  This creates a generic secret containing the user name and password as literal values.\nYou can check the secret with the kubectl get secret command. An example is shown below, including the output:\n$ kubectl -n domain-namespace-1 get secret domain1-weblogic-credentials -o yaml apiVersion: v1 data: password: d2VsY29tZTE= username: d2VibG9naWM= kind: Secret metadata: creationTimestamp: 2018-12-12T20:25:20Z labels: weblogic.domainName: domain1 weblogic.domainUID: domain1 name: domain1-weblogic-credentials namespace: domain-namespace-1 resourceVersion: \u0026quot;5680\u0026quot; selfLink: /api/v1/namespaces/domain-namespace-1/secrets/domain1-weblogic-credentials uid: 0c2b3510-fe4c-11e8-994d-00001700101d type: Opaque  "
},
{
	"uri": "/weblogic-kubernetes-operator/developerguide/requirements/",
	"title": "Requirements",
	"tags": [],
	"description": "",
	"content": " In addition to the requirements listed in the User Guide, the following software is also required to obtain and build the operator:\n Git (1.8 or later recommended) Java Developer Kit (1.8u131 or later recommended; please use 1.8, tests will not work on 1.9 or later versions) Apache Maven (3.3 or later recommended)  The operator is written primarily in Java, BASH shell scripts, and WLST scripts. The Java code uses features introduced in Java 1.8 \u0026ndash; for example, closures \u0026ndash; but does not use any Java 1.9 features.\nBecause the target runtime environment for the operator is Oracle Linux, no particular effort has been made to ensure the build or tests run on any other operating system. Please be aware that Oracle will not provide support, or accept pull requests to add support, for other operating systems.\nObtaining the operator source code The operator source code is published on GitHub at https://github.com/oracle/weblogic-kubernetes-operator. Developers may clone this repository to a local machine or, if desired, create a fork in their personal namespace and clone the fork. Developers who are planning to submit a pull request are advised to create a fork.\nTo clone the repository from GitHub, issue this command:\n$ git clone https://github.com/oracle/weblogic-kubernetes-operator.git  "
},
{
	"uri": "/weblogic-kubernetes-operator/samples/simple/",
	"title": "Simple Samples",
	"tags": [],
	"description": "",
	"content": "This section provides samples for individual tasks. The samples in this section are intended to be modified before production use.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-operators/using-the-operator/using-helm/",
	"title": "Use Helm",
	"tags": [],
	"description": "Useful Helm operations",
	"content": " Useful Helm operations Show the available operator configuration parameters and their default values:\n$ helm inspect values kubernetes/charts/weblogic-operator  Show the custom values you configured for the operator Helm release:\n$ helm get values weblogic-operator  Show all of the values your operator Helm release is using:\n$ helm get values --all weblogic-operator  List the Helm releases that have been installed in this Kubernetes cluster:\n$ helm list  Get the status of the operator Helm release:\n$ helm status weblogic-operator  Show the history of the operator Helm release:\n$ helm history weblogic-operator  Roll back to a previous version of this operator Helm release, in this case, the first version:\n$ helm rollback weblogic-operator 1  Change one or more values in the operator Helm release. In this example, the --reuse-values flag indicates that previous overrides of other values should be retained:\n$ helm upgrade \\ --reuse-values \\ --set \u0026quot;domainNamespaces={sample-domains-ns1}\u0026quot; \\ --set \u0026quot;javaLoggingLevel=FINE\u0026quot; \\ --wait \\ weblogic-operator \\ kubernetes/charts/weblogic-operator  Operator Helm configuration values This section describes the details of the operator Helm chart\u0026rsquo;s available configuration values.\nOverall operator information serviceAccount Specifies the name of the service account in the operator\u0026rsquo;s namespace that the operator will use to make requests to the Kubernetes API server. You are responsible for creating the service account.\nDefaults to default.\nExample:\nserviceAccount: \u0026quot;weblogic-operator\u0026quot;  javaLoggingLevel Specifies the level of Java logging that should be enabled in the operator. Valid values are: SEVERE, WARNING, INFO, CONFIG, FINE, FINER, and FINEST.\nDefaults to INFO.\nExample:\njavaLoggingLevel: \u0026quot;FINE\u0026quot;  Creating the operator pod image Specifies the Docker image containing the operator code.\nDefaults to weblogic-kubernetes-operator:2.0.\nExample:\nimage: \u0026quot;weblogic-kubernetes-operator:LATEST\u0026quot;  imagePullPolicy Specifies the image pull policy for the operator Docker image.\nDefaults to IfNotPresent.\nExample:\nimage: \u0026quot;Always\u0026quot;  imagePullSecrets Contains an optional list of Kubernetes secrets, in the operator\u0026rsquo;s namepace, that are needed to access the registry containing the operator Docker image. You are responsible for creating the secret. If no secrets are required, then omit this property.\nExample:\nimagePullSecrets: - name: \u0026quot;my-image-pull-secret\u0026quot;  WebLogic domain management domainNamespaces Specifies a list of WebLogic domain namespaces which the operator manages. The names must be lower case. You are responsible for creating these namespaces.\nThis property is required.\nExample 1: In the configuration below, the operator will monitor the default Kubernetes namespace:\ndomainNamespaces: - \u0026quot;default\u0026quot;  Example 2: In the configuration below, the Helm installation will manage namespace1 and namespace2:\ndomainNamespaces: [ \u0026quot;namespace1\u0026quot;, \u0026quot;namespace2\u0026quot; ]  You must include the default namespace in the list if you want the operator to monitor both the default namespace and some other namespaces.\n\rThese examples show two valid YAML syntax options for arrays.\n\rElastic Stack integration elkIntegrationEnabled Specifies whether or not Elastic Stack integration is enabled.\nDefaults to false.\nExample:\nelkIntegrationEnabled: true  logStashImage Specifies the Docker image containing Logstash. This parameter is ignored if elkIntegrationEnabled is false.\nDefaults to logstash:6.6.0.\nExample:\nlogStashImage: \u0026quot;logstash:6.2\u0026quot;  elasticSearchHost Specifies the hostname where Elasticsearch is running. This parameter is ignored if elkIntegrationEnabled is false.\nDefaults to elasticsearch.default.svc.cluster.local.\nExample:\nelasticSearchHost: \u0026quot;elasticsearch2.default.svc.cluster.local\u0026quot;  elasticSearchPort Specifies the port number where Elasticsearch is running. This parameter is ignored if elkIntegrationEnabled is false.\nDefaults to 9200.\nExample:\nelasticSearchPort: 9201  REST interface configuration externalRestEnabled Determines whether the operator\u0026rsquo;s REST interface will be exposed outside the Kubernetes cluster.\nDefaults to false.\nIf set to true, you must provide the externalRestIdentitySecret property that contains the name of the Kubernetes secret which contains the SSL certificate and private key for the operator\u0026rsquo;s external REST interface.\nExample:\nexternalRestEnabled: true  externalRestHttpsPort Specif`ies the node port that should be allocated for the external operator REST HTTPS interface.\nOnly used when externalRestEnabled is true, otherwise ignored.\nDefaults to 31001.\nExample:\nexternalRestHttpsPort: 32009  externalRestIdentitySecret Specifies the user supplied secret that contains the SSL/TLS certificate and private key for the external operator REST HTTPS interface. The value must be the name of the Kubernetes tls secret previously created in the namespace where the WebLogic operator is deployed. This parameter is required if externalRestEnabled is true, otherwise, it is ignored. In order to create the Kubernetes tls secret you can use the following command:\n$ kubectl create secret tls \u0026lt;secret-name\u0026gt; \\ -n \u0026lt;operator-namespace\u0026gt; \\ --cert=\u0026lt;path-to-certificate\u0026gt; \\ --key=\u0026lt;path-to-private-key\u0026gt;  There is no default value.\nThe Helm installation will produce an error, similar to the following, if externalRestIdentitySecret is not specified (left blank) and externalRestEnabled is true:\nError: render error in \u0026quot;weblogic-operator/templates/main.yaml\u0026quot;: template: weblogic-operator/templates/main.yaml:9:3: executing \u0026quot;weblogic-operator/templates/main.yaml\u0026quot; at \u0026lt;include \u0026quot;operator.va...\u0026gt;: error calling include: template: weblogic-operator/templates/_validate-inputs.tpl:42:14: executing \u0026quot;operator.validateInputs\u0026quot; at \u0026lt;include \u0026quot;utils.endVa...\u0026gt;: error calling include: template: weblogic-operator/templates/_utils.tpl:22:6: executing \u0026quot;utils.endValidation\u0026quot; at \u0026lt;fail $scope.validati...\u0026gt;: error calling fail: string externalRestIdentitySecret must be specified  Example:\nexternalRestIdentitySecret: weblogic-operator-external-rest-identity  externalOperatorCert (Deprecated) Use externalRestIdentitySecret instead\n\rSpecifies the user supplied certificate to use for the external operator REST HTTPS interface. The value must be a string containing a Base64 encoded PEM certificate. This parameter is required if externalRestEnabled is true, otherwise, it is ignored.\nThere is no default value.\nThe Helm installation will produce an error, similar to the following, if externalOperatorCert is not specified (left blank) and externalRestEnabled is true:\nError: render error in \u0026quot;weblogic-operator/templates/main.yaml\u0026quot;: template: weblogic-operator/templates/main.yaml:4:3: executing \u0026quot;weblogic-operator/templates/main.yaml\u0026quot; at \u0026lt;include \u0026quot;operator.va...\u0026gt;: error calling include: template: weblogic-operator/templates/_validate-inputs.tpl:53:4: executing \u0026quot;operator.validateInputs\u0026quot; at \u0026lt;include \u0026quot;operator.re...\u0026gt;: error calling include: template: weblogic-operator/templates/_utils.tpl:137:6: executing \u0026quot;operator.reportValidationErrors\u0026quot; at \u0026lt;fail .validationErro...\u0026gt;: error calling fail: The string property externalOperatorCert must be specified.  Example:\nexternalOperatorCert: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUQwakNDQXJxZ0F3S ...  externalOperatorKey (Deprecated) Use externalRestIdentitySecret instead\n\rSpecifies user supplied private key to use for the external operator REST HTTPS interface. The value must be a string containing a Base64 encoded PEM key. This parameter is required if externalRestEnabled is true, otherwise, it is ignored.\nThere is no default value.\nThe Helm installation will produce an error, similar to the following, if externalOperatorKey is not specified (left blank) and externalRestEnabled is true:\nError: render error in \u0026quot;weblogic-operator/templates/main.yaml\u0026quot;: template: weblogic-operator/templates/main.yaml:4:3: executing \u0026quot;weblogic-operator/templates/main.yaml\u0026quot; at \u0026lt;include \u0026quot;operator.va...\u0026gt;: error calling include: template: weblogic-operator/templates/_validate-inputs.tpl:53:4: executing \u0026quot;operator.validateInputs\u0026quot; at \u0026lt;include \u0026quot;operator.re...\u0026gt;: error calling include: template: weblogic-operator/templates/_utils.tpl:137:6: executing \u0026quot;operator.reportValidationErrors\u0026quot; at \u0026lt;fail .validationErro...\u0026gt;: error calling fail: The string property externalOperatorKey must be specified.  Example:\nexternalOperatorKey: QmFnIEF0dHJpYnV0ZXMKICAgIGZyaWVuZGx5TmFtZTogd2VibG9naWMtb3B ...  Debugging options remoteDebugNodePortEnabled Specifies whether or not the operator will start a Java remote debug server on the provided port and suspend execution until a remote debugger has attached.\nDefaults to false.\nExample:\nremoteDebugNodePortEnabled: true  internalDebugHttpPort Specifies the port number inside the Kubernetes cluster for the operator\u0026rsquo;s Java remote debug server.\nThis parameter is required if remoteDebugNodePortEnabled is true. Otherwise, it is ignored.\nDefaults to 30999.\nExample:\ninternalDebugHttpPort: 30888  externalDebugHttpPort Specifies the node port that should be allocated for the Kubernetes cluster for the operator\u0026rsquo;s Java remote debug server.\nThis parameter is required if remoteDebugNodePortEnabled is true. Otherwise, it is ignored.\nDefaults to 30999.\nExample:\nexternalDebugHttpPort: 30777  Common mistakes and solutions Installing the operator a second time into the same namespace A new FAILED Helm release is created.\n$ helm install --no-hooks --name op2 --namespace myuser-op-ns --values custom-values.yaml kubernetes/charts/weblogic-operator Error: release op2 failed: secrets \u0026quot;weblogic-operator-secrets\u0026quot; already exists  Both the previous and new release own the resources created by the previous operator.\n You can\u0026rsquo;t modify it to change the namespace (because helm upgrade doesn\u0026rsquo;t let you change the namespace). You can\u0026rsquo;t fix it by deleting this release because it removes your previous operator\u0026rsquo;s resources. You can\u0026rsquo;t fix it by rolling back this release because it is not in the DEPLOYED state. You can\u0026rsquo;t fix it by deleting the previous release because it removes the operator\u0026rsquo;s resources too. All you can do is delete both operator releases and reinstall the original operator. See https://github.com/helm/helm/issues/2349  Installing an operator and telling it to manage a domain namespace that another operator is already managing A new FAILED Helm release is created.\n$ helm install --no-hooks --name op2 --namespace myuser-op2-ns --values custom-values.yaml kubernetes/charts/weblogic-operator Error: release op2 failed: rolebindings.rbac.authorization.k8s.io \u0026quot;weblogic-operator-rolebinding-namespace\u0026quot; already exists  To recover:\n helm delete --purge the failed release.  NOTE: This deletes the role binding in the domain namespace that was created by the first operator release to give the operator access to the domain namespace.  helm upgrade \u0026lt;old op release\u0026gt; kubernetes/charts/weblogic-operator --values \u0026lt;old op custom-values.yaml\u0026gt;  This recreates the role binding. There might be intermittent failures in the operator for the period of time when the role binding was deleted.   Upgrading an operator and telling it to manage a domain namespace that another operator is already managing The helm upgrade succeeds, and silently adopts the resources the first operator\u0026rsquo;s Helm chart created in the domain namespace (for example, rolebinding), and, if you also told it to stop managing another domain namespace, it abandons the role binding it created in that namespace.\nFor example, if you delete this release, then the first operator will get messed up because the role binding it needs is gone. The big problem is that you don\u0026rsquo;t get a warning, so you don\u0026rsquo;t know that there\u0026rsquo;s a problem to fix.\n This can be fixed by just upgrading the Helm release. This may also be fixed by rolling back the Helm release.  Installing an operator and telling it to use the same external REST port number as another operator A new FAILED Helm release is created.\n$ helm install --no-hooks --name op2 --namespace myuser-op2-ns --values o.yaml kubernetes/charts/weblogic-operator Error: release op2 failed: Service \u0026quot;external-weblogic-operator-svc\u0026quot; is invalid: spec.ports[0].nodePort: Invalid value: 31023: provided port is already allocated  To recover:\n $ helm delete --purge the failed release. Change the port number and helm install the second operator again.  Upgrading an operator and telling it to use the same external REST port number as another operator The helm upgrade fails and moves the release to the FAILED state.\n$ helm upgrade --no-hooks --values o23.yaml op2 kubernetes/charts/weblogic-operator --wait Error: UPGRADE FAILED: Service \u0026quot;external-weblogic-operator-svc\u0026quot; is invalid: spec.ports[0].nodePort: Invalid value: 31023: provided port is already allocated   You can fix this by upgrading the Helm release (to fix the port number). You can also fix this by rolling back the Helm release.  Installing an operator and telling it to use a service account that doesn\u0026rsquo;t exist The helm install eventually times out and creates a failed release.\n$ helm install kubernetes/charts/weblogic-operator --name op2 --namespace myuser-op2-ns --values o24.yaml --wait --no-hooks Error: release op2 failed: timed out waiting for the condition kubectl logs -n kube-system tiller-deploy-f9b8476d-mht6v ... [kube] 2018/12/06 21:16:54 Deployment is not ready: myuser-op2-ns/weblogic-operator ...  To recover:\n helm delete --purge the failed release. Create the service account. helm install again.  Upgrading an operator and telling it to use a service account that doesn\u0026rsquo;t exist The helm upgrade succeeds and changes the service account on the existing operator deployment, but the existing deployment\u0026rsquo;s pod doesn\u0026rsquo;t get modified, so it keeps running. If the pod is deleted, the deployment creates another one using the OLD service account. However, there\u0026rsquo;s an error in the deployment\u0026rsquo;s status section saying that the service account doesn\u0026rsquo;t exist.\nlastTransitionTime: 2018-12-06T23:19:26Z lastUpdateTime: 2018-12-06T23:19:26Z message: 'pods \u0026quot;weblogic-operator-88bbb5896-\u0026quot; is forbidden: error looking up service account myuser-op2-ns/no-such-sa2: serviceaccount \u0026quot;no-such-sa2\u0026quot; not found' reason: FailedCreate status: \u0026quot;True\u0026quot; type: ReplicaFailure  To recover:\n Create the service account. helm rollback helm upgrade again.  Installing an operator and telling it to manage a domain namespace that doesn\u0026rsquo;t exist A new FAILED Helm release is created.\n$ helm install --no-hooks --name op2 --namespace myuser-op2-ns --values o.yaml kubernetes/charts/weblogic-operator Error: release op2 failed: namespaces \u0026quot;myuser-d2-ns\u0026quot; not found  To recover:\n helm delete --purge the failed release. Create the domain namespace. helm install again.  Upgrading an operator and telling it to manage a domain namespace that doesn\u0026rsquo;t exist The helm upgrade fails and moves the release to the FAILED state.\n$ helm upgrade myuser-op kubernetes/charts/weblogic-operator --values o.yaml --no-hooks Error: UPGRADE FAILED: failed to create resource: namespaces \u0026quot;myuser-d2-ns\u0026quot; not found  To recover:\n helm rollback Create the domain namespace. helm upgrade again.  "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/domain-lifecycle/startup/",
	"title": "Startup and shutdown",
	"tags": [],
	"description": "",
	"content": " There are properties on the domain resource that specify which servers should be running and which servers should be restarted. To start, stop, or restart servers, modify these properties on the domain resource (for example, by using kubectl or the Kubernetes REST API). The operator will notice the changes and apply them.\nStarting and stopping servers The serverStartPolicy property on the domain resource controls which servers should be running. The operator runtime monitors this property and creates or deletes the corresponding server pods.\nserverStartPolicy rules You can specify the serverStartPolicy property at the domain, cluster, and server levels. Each level supports a different set of values.\nAvailable serverStartPolicy values    Level Default Value Supported Values     Domain IF_NEEDED IF_NEEDED, ADMIN_ONLY, NEVER   Cluster IF_NEEDED IF_NEEDED, NEVER   Server IF_NEEDED IF_NEEDED, ALWAYS, NEVER    Administration Server start and stop rules    Domain Admin Server Started / Stopped     NEVER any value Stopped   ADMIN_ONLY, IF_NEEDED NEVER Stopped   ADMIN_ONLY, IF_NEEDED IF_NEEDED, ALWAYS Started    Standalone Managed Server start and stop rules    Domain Standalone Server Started / Stopped     ADMIN_ONLY, NEVER any value Stopped   IF_NEEDED NEVER Stopped   IF_NEEDED IF_NEEDED, ALWAYS Started    Clustered Managed Server start and stop rules    Domain Cluster Clustered Server Started / Stopped     ADMIN_ONLY, NEVER any value any value Stopped   IF_NEEDED NEVER any value Stopped   IF_NEEDED IF_NEEDED NEVER Stopped   IF_NEEDED IF_NEEDED ALWAYS Started   IF_NEEDED IF_NEEDED IF_NEEDED Started if needed to get to the cluster\u0026rsquo;s replicas count    Servers configured as ALWAYS count toward the cluster\u0026rsquo;s replicas count.\n\rIf more servers are configured as ALWAYS than the cluster\u0026rsquo;s replicas count, they will all be started and the replicas count will be ignored.\n\rCommon scenarios Normal running state Normally, the Administration Server, all of the standalone Managed Servers, and enough Managed Servers in each cluster to satisfy its replicas count, should be started. In this case, the domain resource does not need to specify serverStartPolicy, or list any clusters or servers, but it does need to specify a replicas count.\nFor example:\n domain: spec: image: ... replicas: 10  Shut down all the servers Sometimes you need to completely shut down the domain (for example, take it out of service).\n domain: spec: serverStartPolicy: \u0026quot;NEVER\u0026quot; ...  Only start the Administration Server Sometimes you want to start the Administration Server only, that is, take the domain out of service but leave the Administration Server running so that you can administer the domain.\n domain: spec: serverStartPolicy: \u0026quot;ADMIN_ONLY\u0026quot; ...  Shut down a cluster To shut down a cluster (for example, take it out of service), add it to the domain resource and set its serverStartPolicy to NEVER.\n domain: spec: clusters: - clusterName: \u0026quot;cluster1\u0026quot; serverStartPolicy: \u0026quot;NEVER\u0026quot; ...  Shut down a specific standalone server To shut down a specific standalone server, add it to the domain resource and set its serverStartPolicy to NEVER.\n domain: spec: managedServers: - serverName: \u0026quot;server1\u0026quot; serverStartPolicy: \u0026quot;NEVER\u0026quot; ...  Force a specific clustered Managed Server to start Normally, all of the Managed Servers in a cluster are identical and it doesn\u0026rsquo;t matter which ones are running as long as the operator starts enough of them to get to the cluster\u0026rsquo;s replicas count. However, sometimes some of the Managed Servers are different (for example, support some extra services that the other servers in the cluster use) and need to always be started.\nThis is done by adding the server to the domain resource and setting its serverStartPolicy to ALWAYS.\n domain: spec: managedServers: - serverName: \u0026quot;cluster1_server1\u0026quot; serverStartPolicy: \u0026quot;ALWAYS\u0026quot; ...  The server will count toward the cluster\u0026rsquo;s replicas count. Also, if you configure more than the replicas servers count to ALWAYS, they will all be started, even though the replicas count will be exceeded.\n\rRestarting servers The operator runtime automatically recreates (restarts) server pods when properties on the domain resource that affect server pods change (such as image, volumes, and env). The restartVersion property on the domain resource lets you force the operator to restart a set of server pods.\nThe operator runtime does rolling restarts of clustered servers so that service is maintained.\nProperties that cause servers to be restarted The operator will restart servers when any of the follow properties on the domain resource that affect the server are changed:\n containerSecurityContext domainHome domainHomeInImage env image imagePullPolicy imagePullSecrets includeServerOutInPodLog logHomeEnabled logHome livenessProbe nodeSelector podSecurityContext readinessProbe resources restartVersion serverStartState volumes volumeMounts  If the only change detected is the addition or modification of a domain-specified label or annotation, the operator will patch the server\u0026rsquo;s pod rather than restarting it. Removing a label or annotation from the domain resource will cause neither a restart nor a patch. It is possible to force a restart to remove such a label or annotation by modifying the restartVersion.\n\rRolling restarts Clustered servers that need to be restarted are gradually restarted (for example, rolling restarted) so that the cluster is not taken out of service and in-flight work can be migrated to other servers in the cluster.\nThe maxUnavailable property on the domain resource determines how many of the cluster\u0026rsquo;s servers may be taken out of service at a time when doing a rolling restart. It can be specified at the domain and cluster levels and defaults to 1 (that is, by default, clustered servers are restarted one at a time).\nWhen using in-memory session replication, Oracle WebLogic Server employs a primary-secondary session replication model to provide high availability of application session state (that is, HTTP and EJB sessions). The primary server creates a primary session state on the server to which the client first connects, and a secondary replica on another WebLogic Server instance in the cluster. Specifying a maxUnavailable property value of 1 protects against inadvertent session state loss which could occur if both the primary and secondary servers are shut down at the same time during the rolling restart process.\nUsing restartVersion to force the operator to restart servers The restartVersion property lets you force the operator to restart servers.\nIt\u0026rsquo;s basically a user-specified string that gets added to new server pods (as a label) so that the operator can tell which servers need to be restarted. If the value is different, then the server pod is old and needs to be restarted. If the value matches, then the server pod has already been restarted.\nEach time you want to restart some servers, you need to set restartVersion to a different string (the particular value doesn\u0026rsquo;t matter).\nThe operator will notice the new value and restart the affected servers (using the same mechanisms as when other properties that affect the server pods are changed, including doing rolling restarts of clustered servers).\nThe restartVersion property can be specified at the domain, cluster, and server levels. A server will be restarted if any of these three values change.\nThe servers will also be restarted if restartVersion is removed from the domain resource (for example, if you had previously specified a value to cause a restart, then you remove that value after the previous restart has completed).\n\rCommon scenarios Restart all the servers in the domain Set restartVersion at the domain level to a new value.\n domain: spec: restartVersion: \u0026quot;domainV1\u0026quot; ...  Restart all the servers in the cluster Set restartVersion at the cluster level to a new value.\n domain: spec: clusters: - clusterName : \u0026quot;cluster1\u0026quot; restartVersion: \u0026quot;cluster1V1\u0026quot; maxUnavailable: 2 ...  Restart the Administration Server Set restartVersion at the adminServer level to a new value.\n domain: spec: adminServer: restartVersion: \u0026quot;adminV1\u0026quot; ...  Restart a standalone or clustered Managed Server Set restartVersion at the managedServer level to a new value.\n domain: spec: managedServers: - serverName: \u0026quot;standalone_server1\u0026quot; restartVersion: \u0026quot;v1\u0026quot; - serverName: \u0026quot;cluster1_server1\u0026quot; restartVersion: \u0026quot;v1\u0026quot; ...  Full domain restarts To do a full domain restart, first shut down all of the domain\u0026rsquo;s servers (Administration and Managed Servers), taking the domain out of service, then restart them. Unlike rolling restarts, the operator cannot detect and initiate a full domain restart; you must always manually initiate it.\nTo manually initiate a full domain restart:\n Change the domain level serverStartPolicy on the domain resource to NEVER.\n domain: spec: serverStartPolicy: \u0026quot;NEVER\u0026quot; ...  Wait for the operator to stop ALL the servers for that domain.\n To restart the domain, set the domain level serverStartPolicy back to IF_NEEDED. Alternatively, you do not have to specify the serverStartPolicy as the default value is IF_NEEDED.\n domain: spec: serverStartPolicy: \u0026quot;IF_NEEDED\u0026quot; ...  The operator will restart all the servers in the domain.\n  "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/integrations/exporting-metrics/metrics-exporter/",
	"title": "Monitoring Exporter",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-operators/installation/",
	"title": "Install the operator",
	"tags": [],
	"description": "",
	"content": " The operator uses Helm to create and deploy the necessary resources and then run the operator in a Kubernetes cluster.\nInstall the operator Helm chart Use the helm install command to install the operator Helm chart. As part of this, you must specify a \u0026ldquo;release\u0026rdquo; name for the operator.\nYou can override default configuration values in the operator Helm chart by doing one of the following: - Creating a custom YAML file containing the values to be overridden, and specifying the --value option on the Helm command line. - Overriding individual values directly on the Helm command line, using the --set option.\nYou supply the –namespace argument from the helm install command line to specify the namespace in which the operator should be installed. If not specified, then it defaults to default. If the namespace does not already exist, then Helm will automatically create it (and create a default service account in the new namespace), but will not remove it when the release is deleted. If the namespace already exists, then Helm will re-use it. These are standard Helm behaviors.\nSimilarly, you may override the default serviceAccount configuration value to specify which service account in the operator\u0026rsquo;s namespace, the operator should use. If not specified, then it defaults to default (for example, the namespace\u0026rsquo;s default service account). If you want to use a different service account, then you must create the operator\u0026rsquo;s namespace and the service account before installing the operator Helm chart.\nFor example:\n$ helm install kubernetes/charts/weblogic-operator \\ --name weblogic-operator --namespace weblogic-operator-namespace \\ --values custom-values.yaml --wait  or:\n$ helm install kubernetes/charts/weblogic-operator \\ --name weblogic-operator --namespace weblogic-operator-namespace \\ --set \u0026quot;javaLoggingLevel=FINE\u0026quot; --wait  This creates a Helm release, named weblogic-operator in the weblogic-operator-namespace namespace, and configures a deployment and supporting resources for the operator.\nIf weblogic-operator-namespace exists, then it will be used. If it does not exist, then Helm will create it.\nYou can verify the operator installation by examining the output from the helm install command.\nRemoving the operator The helm delete command is used to remove an operator release and its associated resources from the Kubernetes cluster. The release name used with the helm delete command is the same release name used with the helm install command (see Install the Helm chart). For example:\n$ helm delete --purge weblogic-operator  If the operator\u0026rsquo;s namespace did not exist before the Helm chart was installed, then Helm will create it, however, helm delete will not remove it.\n\rAfter removing the operator deployment, you should also remove the domain custom resource definition:\n$ kubectl delete customresourcedefinition domains.weblogic.oracle  Note that the domain custom resource definition is shared if there are multiple operators in the same cluster.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/integrations/exporting-metrics/",
	"title": "Export Metrics",
	"tags": [],
	"description": "",
	"content": "Lorem Ipsum.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/domain-in-image/base-images/",
	"title": "Base Images",
	"tags": [],
	"description": "",
	"content": "Lorem Ipsum.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/choosing-a-model/",
	"title": "Choose a Model",
	"tags": [],
	"description": "",
	"content": "When using the operator, a WebLogic domain can be located either in a persistent volume (PV) or in a Docker image. There are advantages to both approaches, and there are sometimes technical limitations of various cloud providers that may make one approach better suited to your needs. You can also mix and match on a domain-by-domain basis.\n   Domain on a persistent volume Domain in a Docker image     Let\u0026rsquo;s you use the same standard read-only Docker image for every server in every domain. Requires a different image for each domain, but all servers in that domain use the same image.   No state is kept in Docker images making them completely throw away (cattle not pets). Runtime state should not be kept in the images, but applications and configuration are.   The domain is long-lived, so you can mutate the configuration or deploy new applications using standard methods (Administration Console, WLST, and such). If you want to mutate the domain configuration or deploy application updates, you must create a new image.   Logs are automatically placed on persistent storage. Logs are kept in the images, and sent to the pod\u0026rsquo;s log (stdout) unless you manually place them on persistent storage.   Patches can be applied by simply changing the image and rolling the domain. To apply patches, you must create a new domain-specific image and then roll the domain.   Many cloud providers do not provide persistent volumes that are shared across availability zones, so you may not be able to use a single persistent volume. You may need to use some kind of volume replication technology or a clustered file system. You do not have to worry about volume replication across availability zones since each pod has its own copy of the domain. WebLogic replication will handle propagation of any online configuration changes.   CI/CD pipelines may be more complicated because you would probably need to run WLST against the live domain directory to effect changes. CI/CD pipelines are simpler because you can create the whole domain in the image and don\u0026rsquo;t have to worry about a persistent copy of the domain.   There are less images to manage and store, which could provide significant storage and network savings. There are more images to manage and store in this approach.   You may be able to use standard Oracle-provided images or, at least, a very small number of self-built images, for example, with patches installed. You may need to do more work to set up processes to build and maintain your images.    "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/prepare/",
	"title": "Prepare to run a domain",
	"tags": [],
	"description": "",
	"content": "Perform these steps to prepare your Kubernetes cluster to run a WebLogic domain:\n Create the domain namespace(s). One or more domains can share a namespace. A single instance of the operator can manage multiple namespaces.\n$ kubectl create namespace domain-namespace-1  Replace domain-namespace-1 with name you want to use. The name must follow standard Kubernetes naming conventions, that is, lower case, numbers, and hyphens.\n Create a Kubernetes secret containing the Administration Server boot credentials. You can do this manually or by using the provided sample. To create the secret manually, use this command:\n$ kubectl -n domain-namespace-1 \\ create secret generic domain1-weblogic-credentials \\ --from-literal=username=weblogic \\ --from-literal=password=welcome1   Replace domain-namespace-1 with the namespace that the domain will be in. Replace domain1-weblogic-credentials with the name of the secret. The operator expects the secret name to be the domainUID followed by the literal string -weblogic-credentials and many of the samples assume this name. Replace the string weblogic in the third line with the user name for the administrative user. Replace the string welcome1 in the fourth line with the password.  Optionally, create a PV \u0026amp; persistent volume claim (PVC) which can hold the domain home, logs, and application binaries. Even if you put your domain in a Docker image, you may want to put the logs on a persistent volume so that they are available after the pods terminate. This may be instead of, or as well as, other approaches like streaming logs into Elasticsearch.\n Configure load balancer(s) to manage access to any WebLogic clusters.\n  "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/overview/prepare/",
	"title": "Prepare your environment",
	"tags": [],
	"description": "Prepare your environment, then install and use the operator to manage domains.",
	"content": " Set up your Kubernetes cluster If you need help setting up a Kubernetes environment, check our cheat sheet.\nAfter creating Kubernetes clusters, you can optionally:\n Create load balancers to direct traffic to backend domains. Configure Kibana and Elasticsearch for your operator logs.  Load balancing with an Ingress controller or a web server You can choose a load balancer provider for your WebLogic domains running in a Kubernetes cluster. Please refer to the WebLogic Operator Load Balancer Samples for information about the current capabilities and setup instructions for each of the supported load balancers.\nConfiguring Kibana and Elasticsearch You can send the operator logs to Elasticsearch, to be displayed in Kibana. Use this sample script to configure Elasticsearch and Kibana deployments and services.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/introduction/introduction/",
	"title": "Get Started",
	"tags": [],
	"description": "",
	"content": " An operator is an application-specific controller that extends Kubernetes to create, configure, and manage instances of complex applications. The Oracle WebLogic Server Kubernetes Operator follows the standard Kubernetes operator pattern, and simplifies the management and operation of WebLogic domains and deployments.\nYou can have one or more operators in your Kubernetes cluster that manage one or more WebLogic domains each. We provide a Helm chart to manage the installation and configuration of the operator. Detailed instructions are available here.\nPrerequisites  Kubernetes 1.10.11+, 1.11.5+, and 1.12.3+ (check with kubectl version). Flannel networking v0.9.1-amd64 (check with docker images | grep flannel). Docker 18.03.1.ce (check with docker version). Helm 2.8.2+ (check with helm version). Oracle WebLogic Server 12.2.1.3.0 with patch 29135930.  The existing WebLogic Docker image, store/oracle/weblogic:12.2.1.3, was updated on January 17, 2019, and has all the necessary patches applied. A docker pull is required if you pulled the image prior to that date. Check the WLS version with docker run store/oracle/weblogic:12.2.1.3 sh -c 'source $ORACLE_HOME/wlserver/server/bin/setWLSEnv.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; java weblogic.version'. Check the WLS patches with docker run store/oracle/weblogic:12.2.1.3 sh -c '$ORACLE_HOME/OPatch/opatch lspatches'.  You must have the cluster-admin role to install the operator.  Operator Docker image You can find the operator image in Docker Hub.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/reference/javadoc/",
	"title": "Javadoc",
	"tags": [],
	"description": "",
	"content": "You can view the Java API documentation here.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/faq/samplepage/",
	"title": "Sample Page",
	"tags": [],
	"description": "",
	"content": " Here is some neat stuff we can do We can draw decision diagrams:\ngraph LR;\rA[Install Operator] --|Now decide| C{Domain Type}\rC --|Persistent| D[Create persistent domain]\rC --|Domain in Image| E[Create domain image]\r\rAnd some more And have expanding more detail thingies\n\r\rLike this\r\r\rLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n\r And also this   "
},
{
	"uri": "/weblogic-kubernetes-operator/quickstart/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Use this Quick Start guide to create a WebLogic deployment in a Kubernetes cluster with the Oracle WebLogic Kubernetes Operator. Please note that this walk-through is for demonstration purposes only, not for use in production. These instructions assume that you are already familiar with Kubernetes. If you need more detailed instructions, please refer to the User guide.\nIf you have an older version of the operator installed on your cluster, you must remove it before installing this version. This includes the 2.0-rc1 version; it must be completely removed. You should remove the deployment (for example, kubectl delete deploy weblogic-operator -n your-namespace) and the custom resource definition (for example, kubectl delete crd domain). If you do not remove the custom resource definition you may see errors like this:\nError from server (BadRequest): error when creating \u0026quot;/scratch/output/uidomain/weblogic-domains/uidomain/domain.yaml\u0026quot;: the API version in the data (weblogic.oracle/v2) does not match the expected API version (weblogic.oracle/v1  \rYou should be able to upgrade from version 2.0-rc2 to 2.0 because there are no backward incompatible changes between these two releases.\n\r"
},
{
	"uri": "/weblogic-kubernetes-operator/quickstart/",
	"title": "Quick Start",
	"tags": [],
	"description": "",
	"content": " Quick Start The Quick Start guide provides a simple tutorial to help you get the operator up and running quickly.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/security/domain-security/",
	"title": "Domain Security",
	"tags": [],
	"description": "WebLogic Domain security and the WebLogic Operator",
	"content": "\r\rDocker Image Protection\r\rWebLogic Domain in Docker Image Protection\n\rChannels\r\rWebLogic Channels\n\r"
},
{
	"uri": "/weblogic-kubernetes-operator/security/domain-security/weblogic-channels/",
	"title": "Channels",
	"tags": [],
	"description": "WebLogic Channels",
	"content": " WebLogic T3 Channels Oracle recommends not to expose any admin, RMI, or T3 channels outisde the Kubernetes cluster unless absolulety necessary. If exposing any of these channels, limit access using controls like security lists or setup a Bastion to provide access.\n\rWhen accesing T3/RMI based channels, the preferred approach is to kubectl exec into the kubernetes pod and then run wlst or setup Bastion access and then run wlst from the Bastion host to connect to the Kubernetes cluster.\nAlso, consider a private VPN if you need use cross-domain T3 access between clouds, data centers, etc.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/domain-lifecycle/restarting/",
	"title": "Restarting",
	"tags": [],
	"description": "",
	"content": " This document describes when to restart servers in the Oracle WebLogic Server in Kubernetes environment.\nOverview There are many situations where changes to the Oracle WebLogic Server in Kubernetes environment require that all the servers in a domain or cluster be restarted, for example, when applying a WebLogic Server patch or when upgrading an application.\nOne of the operator\u0026rsquo;s most important jobs is to start and stop WebLogic Servers by creating and deleting their corresponding Kubernetes pods. Sometimes, you need to make changes that make the pods obsolete, therefore the pods need to be deleted and recreated. Depending on the change, sometimes the pods can be gradually recreated, without taking the entire domain out of service (for example, rolling restarts) and sometimes all the pods need to be deleted then recreated, taking the entire domain out of service for a while (for example, full restarts).\nThe following types of server restarts are supported in Oracle WebLogic Server in Kubernetes:\n Rolling restarts - a coordinated and controlled shut down of all of the servers in a domain or cluster while ensuring that service to the end user is not interrupted.\n Operator initiated - where the WebLogic Kubernetes Operator can detect some types of changes and will automatically initiate rolling restarts of server pods in a WebLogic domain.\n Manually initiated - required when certain changes in the Oracle WebLogic Server in Kubernetes environment cannot be detected by the operator, so a rolling restart must be manually initiated.\n  Full domain restarts - the Administration Server and all the Managed Servers in a domain are shutdown, impacting service availability to the end user, and then restarted. Unlike a rolling restart, the operator cannot detect and initiate a full domain restart; it must always be manually initiated.\n  For detailed information on how to restart servers in a Oracle WebLogic Server in Kubernetes environment, see Starting, stopping, and restarting servers.\nCommon restart scenarios This document describes what actions you need to take to properly restart your servers for a number of common scenarios:\n Modifying the WebLogic configuration Changing the custom domain configuration overrides (also called situational configuration) Changing the WebLogic Server credentials (the user name and password) Changing properties on the domain resource that affect server pods (such as image, volumes, and env) Applying WebLogic Server patches Updating deployed applications for domain home in image  Use cases Modifying the WebLogic configuration Changes to the Oracle WebLogic Server configuration may require either a rolling or full domain restart depending on the domain home location and the type of configuration change.\n Domain home in image: For domain home in image, any changes (dynamic or non-dynamic) to the WebLogic configuration requires a full domain restart.\n If you create a new image with a new name, then you must avoid a rolling restart, which can cause unexpected behavior for the running domain due to configuration inconsistencies as seen by the various servers, by following the steps in Avoiding a rolling restart when changing image property on a domain resource. If you create a new image with the same name, then you must manually initiate a full domain restart. See Full domain restarts in Starting, stopping, and restarting servers.  Domain home on PV: For domain home on PV, the type of restart needed to apply the changes, depends on the nature of the WebLogic configuration change:\n Changes to parts of the WebLogic configuration that the operator introspects, require a full restart, even if the changes are dynamic. The following are the types of changes to the WebLogic Server configuration that the operator introspects:  Adding or removing a cluster, server, dynamic server, or network access point Changing a cluster, server, dynamic server, or network access point name Enabling or disabling the listen port, SSL port, or admin port Changing any port numbers Changing a network access point\u0026rsquo;s public address  Other dynamic WebLogic configuration changes do not require a restart. For example, a change to a server\u0026rsquo;s connection timeout property is dynamic and does not require a restart. Other non-dynamic WebLogic configuration changes require either a manually initiated rolling restart or a full domain restart, depending on the nature of the change. For example, a rolling restart is applicable when changing a WebLogic Server\u0026rsquo;s stuck thread timer interval property. See Restart all the servers in the domain in Starting, stopping, and restarting servers.   Changing the custom domain configuration overrides Any change to domain configuration overrides requires a full domain restart. This includes:\n Changing the domain resource\u0026rsquo;s configOverides to point to a different configuration map Changing the domain resource\u0026rsquo;s configOverridesSecrets to point to a different list of secrets Changing the contents of the configuration map referenced by configOverrides Changing the contents to any of the secrets referenced by configOverridesSecrets  Changing the WebLogic Server credentials A change to the WebLogic Server credentials (the user name and password), contained in the Kubernetes secret for the domain, requires a full domain restart. The Kubernetes secret can be updated directly or a new secret can be created and then referenced by the webLogicCredentialsSecret property in the domain resource.\nChanging properties on the domain resource that affect server pods The operator will initiate a rolling restart of the domain when you modify any of the domain resource properties that affect the server pods configuration, such as image, volumes, and env. For a complete list, see Properties that cause servers to be restarted in Starting, stopping, and restarting servers.\nYou can modify these properties using the kubectl command-line tool\u0026rsquo;s edit and patch commands or through the Kubernetes REST API.\nFor example, to edit the domain resource directly using the kubectl command-line tool:\nkubectl edit domain \u0026lt;domain name\u0026gt; -n \u0026lt;domain namespace\u0026gt;  The edit command opens a text editor which lets you edit the domain resource in place.\nTypically, it\u0026rsquo;s better to edit the domain resource directly; otherwise, if you scaled the domain, and you just edit the original domain.yaml file and reapply it, you could go back to your old replicas count.\n\rApplying WebLogic Server patches Oracle provides different types of patches for WebLogic Server, such as Patch Set Updates, Security Patch Updates, and One-Off patches. Information on whether a patch is rolling compatible or requires a manual full domain restart usually can be found in the patch\u0026rsquo;s documentation, such as the README file.\nWebLogic Server patches can be applied to either a domain home in image or a domain home on PV.\nWith rolling compatible patches:\n If you update the image property with a new image name, then the operator will initiate a rolling restart. If you keep the same image name, then you must manually initiate a rolling restart. See Restart all the servers in the domain in Starting, stopping, and restarting servers.  With patches that are not rolling compatible:\n If you keep the same image name, then you must manually initiate a full domain restart. See Full domain restarts in Starting, stopping, and restarting servers. If you update the image property with a new image name, then you must avoid the rolling restart by following the steps in Avoiding a rolling restart when changing image property on a domain resource.  Updating deployed applications for domain home in image Frequent updates of deployed applications using a continuous integration/continuous delivery (CI/CD) process is a very common use case. The process for applying an updated application is different for domain home in image than it is for domain home on PV. A rolling compatible application update is where some servers are running the old version and some are running the new version of the application during the rolling restart process. On the other hand, an application update that is not rolling compatible requires that all the servers in the domain be shutdown and restarted.\nIf the application update is rolling compatible:\n If you update the image property with a new image name, then the operator will initiate a rolling restart. If you keep the same image name, then you must manually initiate a rolling restart. See Restart all the servers in the domain in Starting, stopping, and restarting servers.  If the application update is not rolling compatible:\n If you keep the same image name, then you must manually initiate a full domain restart. See Full domain restarts in Starting, stopping, and restarting servers. If you update the image property with a new image name, then you must avoid the rolling restart by following the steps in Avoiding a rolling restart when changing image property on a domain resource.  Rolling out an updated domain home in image Follow these steps to create new rolling compatible image if you only need to patch your WebLogic Server domain or update application deployment files:\na. Select a different name for the new image.\nb. Using the same domain home-in-image Docker image as a base, create a new Docker image by copying (COPY command in a Dockerfile) the updated application deployment files or WebLogic Server patches into the Docker image during the Docker image build.\nThe key here is to make sure that you do not re-run WLST or WDT to create a new domain home even though it will have the same configuration. Creating a new domain will change the domain secret and you won\u0026rsquo;t be able to do a rolling restart.\n\rc. Deploy the new Docker image to your Docker repository with the new name.\nd. Update the image property of the domain resource specifying the new image name.\nFor example:\n ``` domain: spec: image: oracle/weblogic-updated:2.0 ```  e. The operator will now initiate a rolling restart, which will apply the updated image, for all the server pods in the domain.\nAvoiding a rolling restart when changing image property on a domain resource If you\u0026rsquo;ve created a new image that is not rolling compatible, and you\u0026rsquo;ve changed the image name, then:\n Bring the domain down (stopping all the server pods) by setting the serverStartPolicy to NEVER. See Shut down all the servers in Starting, stopping, and restarting servers.\n Update the image property with a new image name.\n Start up the domain (starting all the server pods) by setting the serverStartPolicy to IF_NEEDED.\n  Other considerations for restarting a domain  Consider the order of changes:\nIf you need to make multiple changes to your domain at the same time, you\u0026rsquo;ll want to be careful about the order in which you do your changes, so that servers aren\u0026rsquo;t restarted prematurely or restarted needlessly. For example, if you want to change the readiness probe\u0026rsquo;s tuning parameters and the Java options (both of which are rolling compatible), then you should update the domain resource once, changing both values, so that the operator rolling restarts the servers once. Or, if you want to change the readiness probe\u0026rsquo;s tuning parameters (which is rolling compatible) and change the domain customizations (which require a full restart), then you should do a full shutdown first, then make the changes, and then restart the servers.\nAlternatively, if you know that your set of changes are not rolling compatible, then you must avoiding a rolling restart by:\n Bringing the domain down (stopping all the server pods) by setting the serverStartPolicy to NEVER. See Shut down all the servers in Starting, stopping, and restarting servers.\n Make all your changes to the Oracle WebLogic Server in Kubernetes environment.\n Starting up the domain (starting all the server pods) by setting the serverStartPolicy to IF_NEEDED.\n  Changes that require domain knowledge.\nSometimes you need to make changes that require server restarts, yet the changes are not to the WebLogic configuration, the image, or the Kubernetes resources that register your domain with the operator. For example, your servers are caching information from an external database and you\u0026rsquo;ve modified the contents of the database.\nIn these cases, you must manually initiate a restart.\n  "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/introduction/demo/",
	"title": "Demo",
	"tags": [],
	"description": "",
	"content": "This video provides a demonstration of the WebLogic Server Kubernetes Operator.\n  "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/ingress/ingress/",
	"title": "Ingress",
	"tags": [],
	"description": "",
	"content": " Ingresses are one approach provided by Kubernetes to configure load balancers. Depending on the version of Kubernetes you are using, and your cloud provider, you may need to use Ingresses. Please refer to the Ingress documentation for more information about Ingresses.\nWebLogic clusters as backends of an Ingress In an Ingress object, a list of backends are provided for each target that will be load balanced. Each backend is typically a Kubernetes service, more specifically, a combination of a serviceName and a servicePort.\nWhen the WebLogic operator creates a WebLogic domain, it also creates a service for each WebLogic cluster in the domain. The operator defines the service such that its selector will match all WebLogic server pods within the WebLogic cluster which are in the \u0026ldquo;ready\u0026rdquo; state.\nThe name of the service created for a WebLogic cluster follows the pattern \u0026lt;domainUID\u0026gt;-cluster-\u0026lt;clusterName\u0026gt;. For example, if the domainUID is domain1 and the cluster name is cluster-1, the corresponding service will be named domain1-cluster-cluster-1.\nThe service name must comply with standard Kubernetes rules for naming of objects and in particular with DNS-1035: \u0026gt; A DNS-1035 label must consist of lower case alphanumeric characters or \u0026lsquo;-\u0026rsquo;, start with an alphabetic character, and end with an alphanumeric character (e.g. \u0026lsquo;my-name\u0026rsquo;, or \u0026lsquo;abc-123\u0026rsquo;, regex used for validation is \u0026lsquo;a-z?\u0026lsquo;).\nTo comply with these requirements, if the domainUID or the cluster name contains some upper-case characters or underscores, then in the service name the upper-case characters will be converted to lower-case and underscores will be converted to hyphens. For example, if the domainUID is myDomain_1 and the cluster name is myCluster_1, the corresponding service will be named mydomain-1-cluster-mycluster-1.\nThe service, serviceName and servicePort, of a WebLogic cluster will be used in the routing rules defined in the Ingress object and the load balancer will route traffic to the WebLogic servers within the cluster based on the rules.\nMost common Ingress controllers, for example Traefik, Voyager, and nginx, understand that there are zero or more actual pods behind the service, and they actually build their backend list and route requests to those backends directly, not through the service. This means that requests are properly balanced across the pods, according to the load balancing algorithm in use. Most Ingress controllers also subscribe to updates on the service and adjust their internal backend sets when additional pods become ready, or pods enter a non-ready state.\n\rSteps to set up an Ingress load balancer  Install the Ingress controller.\nAfter the Ingress controller is running, it monitors Ingress resources in a given namespace(s) and acts accordingly.\n Create Ingress resource(s).\nIngress resources contain routing rules to one or more backends. An Ingress controller is responsible to apply the rules to the underlying load balancer. There are two approaches to create the Ingress resource:\n Use the Helm chart ingress-per-domain.\nEach Ingress provider supports a number of annotations in Ingress resources. This Helm chart allows you to define the routing rules without dealing with the detailed provider-specific annotations. Currently we support two Ingress providers: Traefik and Voyager.\n Create the Ingress resource manually from a YAML file.\nManually create an Ingress YAML file and then apply it to the Kubernetes cluster.\n   Guide and samples for Traefik and Voyager/HAProxy Traefik and Voyager/HAProxy are both popular Ingress controllers. Information about how to install and configure these to load balance WebLogic clusters is provided here:\n Traefik guide Voyager guide  Samples are also provided for these two Ingress controllers, showing how to manage multiple WebLogic clusters as the backends, using different routing rules, host-routing and path-routing; and TLS termination:\n Traefik samples Voyager samples  "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/accessing-the-domain/admin-console/",
	"title": "Administration Console",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/samples/simple/storage/",
	"title": "Storage",
	"tags": [],
	"description": "",
	"content": " Sample persistent volume and persistent volume claim The sample scripts demonstrate the creation of a Kubernetes persistent volume (PV) and persistent volume claim (PVC), which can then be used in a domain resource as a persistent storage for the WebLogic domain home or log files.\nA PV and PVC can be shared by multiple WebLogic domains or dedicated to a particular domain.\nPrerequisites Please read the Persistent Volumes guide before proceeding.\nUsing the scripts to create a PV and PVC Prior to running the create-pv-pvc.sh script, make a copy of the create-pv-pvc-inputs.yaml file, and uncomment and explicitly configure the weblogicDomainStoragePath property in the inputs file.\nRun the create script, pointing it at your inputs file and an output directory:\n$ ./create-pv-pvc.sh \\ -i create-pv-pvc-inputs.yaml \\ -o /path/to/output-directory  The create-pv-pvc.sh script will create a subdirectory pv-pvcs under the given /path/to/output-directory directory. By default, the script generates two YAML files, namely weblogic-sample-pv.yaml and weblogic-sample-pvc.yaml, in the /path/to/output-directory/pv-pvcs. These two YAML files can be used to create the Kubernetes resources using the kubectl create -f command.\n$ kubectl create -f weblogic-sample-pv.yaml $ kubectl create -f weblogic-sample-pvc.yaml  As a convenience, the script can optionally create the PV and PVC resources using the -e option.\nThe usage of the create script is as follows:\n$ sh create-pv-pvc.sh -h usage: create-pv-pvc.sh -i file -o dir [-e] [-h] -i Parameter inputs file, must be specified. -o Output directory for the generated yaml files, must be specified. -e Also create the Kubernetes objects using the generated yaml files -h Help  If you copy the sample scripts to a different location, make sure that you copy everything in the \u0026lt;weblogic-kubernetes-operator-project\u0026gt;/kubernetes/samples/scripts directory together into the target directory, maintaining the original directory hierarchy.\nConfiguration parameters The PV and PVC creation inputs can be customized by editing the create-pv-pvc-inputs.yaml file.\n   Parameter Definition Default     domainUID ID of the domain resource to which the generated PV and PVC will be dedicated. Leave it empty if the PV and PVC are going to be shared by multiple domains. no default   namespace Kubernetes namespace to create the PVC. default   baseName Base name of the PV and PVC. The generated PV and PVC will be \u0026lt;baseName\u0026gt;-pv and \u0026lt;baseName\u0026gt;-pvc respectively. weblogic-sample   weblogicDomainStoragePath Physical path of the storage for the PV. When weblogicDomainStorageType is set to HOST_PATH, this value should be set the to path to the domain storage on the Kubernetes host. When weblogicDomainStorageType is set to NFS, then weblogicDomainStorageNFSServer should be set to the IP address or name of the DNS server, and this value should be set to the exported path on that server. Note that the path where the domain is mounted in the WebLogic containers is not affected by this setting, that is determined when you create your domain. no default   weblogicDomainStorageReclaimPolicy Kubernetes PVC policy for the persistent storage. The valid values are: Retain, Delete, and Recycle. Retain   weblogicDomainStorageSize Total storage allocated for the PVC. 10Gi   weblogicDomainStorageType Type of storage. Legal values are NFS and HOST_PATH. If using NFS, weblogicDomainStorageNFSServer must be specified. HOST_PATH   weblogicDomainStorageNFSServer Name or IP address of the NFS server. This setting only applies if weblogicDomainStorateType is NFS. no default    Shared versus dedicated PVC By default, the domainUID is left empty in the inputs file, which means the generated PV and PVC will not be associated with a particular domain, but can be shared by multiple domain resources in the same Kubernetes namespaces as the PV and PVC.\nFor the use cases where dedicated PV and PVC are desired for a particular domain, the domainUID needs to be set in the create-pv-pvc-inputs.yaml file. The presence of a non-empty domainUID in the inputs file will cause the generated PV and PVC to be associated with the specified domainUID. The association includes that the names of the generated YAML files and the Kubernetes PV and PVC objects are decorated with the domainUID, and the PV and PVC objects are also labeled with the domainUID.\nVerify the results The create script will verify that the PV and PVC were created, and will report a failure if there was any error. However, it may be desirable to manually verify the PV and PVC, even if just to gain familiarity with the various Kubernetes objects that were created by the script.\nGenerated YAML files with the default inputs The content of the generated weblogic-sample-pvc.yaml:\n# Copyright 2018, Oracle Corporation and/or its affiliates. All rights reserved. # Licensed under the Universal Permissive License v 1.0 as shown at http://oss.oracle.com/licenses/upl. kind: PersistentVolumeClaim apiVersion: v1 metadata: name: weblogic-sample-pvc namespace: default labels: weblogic.resourceVersion: domain-v2 storageClassName: weblogic-sample-storage-class accessModes: - ReadWriteMany resources: requests: storage: 10Gi  The content of the generated weblogic-sample-pv.yaml:\n# Copyright 2018, Oracle Corporation and/or its affiliates. All rights reserved. # Licensed under the Universal Permissive License v 1.0 as shown at http://oss.oracle.com/licenses/upl. apiVersion: v1 kind: PersistentVolume metadata: name: weblogic-sample-pv labels: weblogic.resourceVersion: domain-v2 # weblogic.domainUID: spec: storageClassName: weblogic-sample-storage-class capacity: storage: 10Gi accessModes: - ReadWriteMany # Valid values are Retain, Delete or Recycle persistentVolumeReclaimPolicy: Retain hostPath: # nfs: # server: %SAMPLE_STORAGE_NFS_SERVER% path: \u0026quot;/scratch/k8s_dir\u0026quot;  Generated YAML files for dedicated PV and PVC The content of the generated domain1-weblogic-sample-pvc.yaml when domainUID is set to domain1:\n# Copyright 2018, Oracle Corporation and/or its affiliates. All rights reserved. # Licensed under the Universal Permissive License v 1.0 as shown at http://oss.oracle.com/licenses/upl. kind: PersistentVolumeClaim apiVersion: v1 metadata: name: domain1-weblogic-sample-pvc namespace: default labels: weblogic.resourceVersion: domain-v2 weblogic.domainUID: domain1 spec: storageClassName: domain1-weblogic-sample-storage-class accessModes: - ReadWriteMany resources: requests: storage: 10Gi  The content of the generated domain1-weblogic-sample-pv.yaml when domainUID is set to domain1:\n# Copyright 2018, Oracle Corporation and/or its affiliates. All rights reserved. # Licensed under the Universal Permissive License v 1.0 as shown at http://oss.oracle.com/licenses/upl. apiVersion: v1 kind: PersistentVolume metadata: name: domain1-weblogic-sample-pv labels: weblogic.resourceVersion: domain-v2 weblogic.domainUID: domain1 spec: storageClassName: domain1-weblogic-sample-storage-class capacity: storage: 10Gi accessModes: - ReadWriteMany # Valid values are Retain, Delete or Recycle persistentVolumeReclaimPolicy: Retain hostPath: # nfs: # server: %SAMPLE_STORAGE_NFS_SERVER% path: \u0026quot;/scratch/k8s_dir\u0026quot;  Verify the PV and PVC objects You can use this command to verify the persistent volume was created, note that the Status field should have the value Bound, indicating the that persistent volume has been claimed:\n$ kubectl describe pv weblogic-sample-pv Name: weblogic-sample-pv Labels: weblogic.resourceVersion=domain-v2 Annotations: pv.kubernetes.io/bound-by-controller=yes StorageClass: weblogic-sample-storage-class Status: Bound Claim: default/weblogic-sample-pvc Reclaim Policy: Retain Access Modes: RWX Capacity: 10Gi Message: Source: Type: HostPath (bare host directory volume) Path: /scratch/k8s_dir HostPathType: Events: \u0026lt;none\u0026gt;  You can use this command to verify the persistent volume claim was created:\n$ kubectl describe pvc weblogic-sample-pvc Name: weblogic-sample-pvc Namespace: default StorageClass: weblogic-sample-storage-class Status: Bound Volume: weblogic-sample-pv Labels: weblogic.resourceVersion=domain-v2 Annotations: pv.kubernetes.io/bind-completed=yes pv.kubernetes.io/bound-by-controller=yes Finalizers: [] Capacity: 10Gi Access Modes: RWX Events: \u0026lt;none\u0026gt;  "
},
{
	"uri": "/weblogic-kubernetes-operator/samples/simple/domains/domain-home-on-pv/",
	"title": "Domain Home on a PV",
	"tags": [],
	"description": "",
	"content": " WebLogic sample domain home on a persistent volume The sample scripts demonstrate the creation of a WebLogic domain home on an existing Kubernetes persistent volume (PV) and persistent volume claim (PVC). The scripts also generate the domain YAML file, which can then be used to start the Kubernetes artifacts of the corresponding domain. Optionally, the scripts start up the domain, and WebLogic Server pods and services.\nPrerequisites Before you begin, read this guide, Domain Resource.\nThe following prerequisites must be handled prior to running the create domain script:\n Make sure the WebLogic operator is running. The operator requires WebLogic Server 12.2.1.3.0 with patch 29135930 applied. The existing WebLogic Docker image, store/oracle/weblogic:12.2.1.3, was updated on January 17, 2019, and has all the necessary patches applied; a docker pull is required if you pulled the image prior to that date. Refer to WebLogic Docker images for details on how to obtain or create the image. Create a Kubernetes namespace for the domain unless the intention is to use the default namespace. In the same Kubernetes namespace, create the Kubernetes persistent volume (PV) where the domain home will be hosted, and the Kubernetes persistent volume claim (PVC) for the domain. For samples to create a PV and PVC, see Create sample PV and PVC. By default, the create-domain.sh script creates a domain with the domainUID set to domain1 and expects the PVC domain1-weblogic-sample-pvc to be present. You can create domain1-weblogic-sample-pvc using create-pv-pvc.sh with an inputs file that has the domainUID set to domain1. Create the Kubernetes secrets username and password of the admin account in the same Kubernetes namespace as the domain.  Use the script to create a domain Make a copy of the create-domain-inputs.yaml file, and run the create script, pointing it at your inputs file and an output directory:\n$ ./create-domain.sh \\ -i create-domain-inputs.yaml \\ -o /path/to/output-directory  The script will perform the following steps:\n Create a directory for the generated Kubernetes YAML files for this domain if it does not already exist. The pathname is /path/to/weblogic-operator-output-directory/weblogic-domains/\u0026lt;domainUID\u0026gt;. If the directory already exists, its contents must be removed before using this script. Create a Kubernetes job that will start up a utility WebLogic Server container and run offline WLST scripts, or WebLogic Deploy Tool (WDT) scripts, to create the domain on the shared storage. Run and wait for the job to finish. Create a Kubernetes domain YAML file, domain.yaml, in the directory that is created above. This YAML file can be used to create the Kubernetes resource using the kubectl create -f or kubectl apply -f command:\n$ kubectl apply -f /path/to/output-directory/weblogic-domains/\u0026lt;domainUID\u0026gt;/domain.yaml  Create a convenient utility script, delete-domain-job.yaml, to clean up the domain home created by the create script.\n  As a convenience, using the -e option, the script can optionally create the domain object, which in turn results in the creation of the corresponding WebLogic Server pods and services as well.\nThe usage of the create script is as follows:\n$ sh create-domain.sh -h usage: create-domain.sh -o dir -i file [-e] [-v] [-h] -i Parameter inputs file, must be specified. -o Output directory for the generated YAML files, must be specified. -e Also create the resources in the generated YAML files, optional. -v Validate the existence of persistentVolumeClaim, optional. -h Help  If you copy the sample scripts to a different location, make sure that you copy everything in the \u0026lt;weblogic-kubernetes-operator-project\u0026gt;/kubernetes/samples/scripts directory together into the target directory, maintaining the original directory hierarchy.\nThe default domain created by the script has the following characteristics:\n An Administration Server named admin-server listening on port 7001. A dynamic cluster named cluster-1 of size 5. Two Managed Servers, named managed-server1 and managed-server2, listening on port 8001. Log files that are located in /shared/logs/\u0026lt;domainUID\u0026gt;. No applications deployed. No data sources or JMS resources. A T3 channel.  The domain creation inputs can be customized by editing create-domain-inputs.yaml.\nConfiguration parameters The following parameters can be provided in the inputs file.\n   Parameter Definition Default     adminPort Port number for the Administration Server inside the Kubernetes cluster. 7001   adminNodePort Port number of the Administration Server outside the Kubernetes cluster. 30701   adminServerName Name of the Administration Server. admin-server   clusterName Name of the WebLogic cluster instance to generate for the domain. cluster-1   configuredManagedServerCount Number of Managed Server instances to generate for the domain. 5   createDomainFilesDir Directory on the host machine to locate all the files to create a WebLogic domain, including the script that is specified in the createDomainScriptName property. By default, this directory is set to the relative path wlst, and the create script will use the built-in WLST offline scripts in the wlst directory to create the WebLogic domain. It can also be set to the relative path wdt, and then the built-in WDT scripts will be used instead. An absolute path is also supported to point to an arbitrary directory in the file system. The built-in scripts can be replaced by the user-provided scripts or model files as long as those files are in the specified directory. Files in this directory are put into a Kubernetes config map, which in turn is mounted to the createDomainScriptsMountPath, so that the Kubernetes pod can use the scripts and supporting files to create a domain home. wlst   createDomainScriptsMountPath Mount path where the create domain scripts are located inside a pod. The create-domain.sh script creates a Kubernetes job to run the script (specified in the createDomainScriptName property) in a Kubernetes pod to create a domain home. Files in the createDomainFilesDir directory are mounted to this location in the pod, so that the Kubernetes pod can use the scripts and supporting files to create a domain home. /u01/weblogic   createDomainScriptName Script that the create domain script uses to create a WebLogic domain. The create-domain.sh script creates a Kubernetes job to run this script to create a domain home. The script is located in the in-pod directory that is specified in the createDomainScriptsMountPath property. If you need to provide your own scripts to create the domain home, instead of using the built-it scripts, you must use this property to set the name of the script that you want the create domain job to run. create-domain-job.sh   domainHome Home directory of the WebLogic domain. If not specified, the value is derived from the domainUID as /shared/domains/\u0026lt;domainUID\u0026gt;. /shared/domains/domain1   domainPVMountPath Mount path of the domain persistent volume. /shared   domainUID Unique ID that will be used to identify this particular domain. Used as the name of the generated WebLogic domain as well as the name of the Kubernetes domain resource. This ID must be unique across all domains in a Kubernetes cluster. This ID cannot contain any character that is not valid in a Kubernetes service name. domain1   exposeAdminNodePort Boolean indicating if the Administration Server is exposed outside of the Kubernetes cluster. false   exposeAdminT3Channel Boolean indicating if the T3 administrative channel is exposed outside the Kubernetes cluster. false   image WebLogic Docker image. The operator requires WebLogic Server 12.2.1.3.0 with patch 29135930 applied. The existing WebLogic Docker image, store/oracle/weblogic:12.2.1.3, was updated on January 17, 2019, and has all the necessary patches applied; a docker pull is required if you pulled the image prior to that date. Refer to WebLogic Docker images for details on how to obtain or create the image. store/oracle/weblogic:12.2.1.3   imagePullPolicy WebLogic Docker image pull policy. Legal values are IfNotPresent, Always, or Never IfNotPresent   imagePullSecretName Name of the Kubernetes secret to access the Docker Store to pull the WebLogic Server Docker image. The presence of the secret will be validated when this parameter is specified    includeServerOutInPodLog Boolean indicating whether to include the server .out to the pod\u0026rsquo;s stdout. true   initialManagedServerReplicas Number of Managed Servers to initially start for the domain. 2   javaOptions Java options for starting the Administration and Managed Servers. A Java option can have references to one or more of the following pre-defined variables to obtain WebLogic domain information: $(DOMAIN_NAME), $(DOMAIN_HOME), $(ADMIN_NAME), $(ADMIN_PORT), and $(SERVER_NAME). -Dweblogic.StdoutDebugEnabled=false   logHome The in-pod location for domain log, server logs, server out, and Node Manager log files. If not specified, the value is derived from the domainUID as /shared/logs/\u0026lt;domainUID\u0026gt;. /shared/logs/domain1   managedServerNameBase Base string used to generate Managed Server names. managed-server   managedServerPort Port number for each Managed Server. 8001   namespace Kubernetes namespace in which to create the domain. default   persistentVolumeClaimName Name of the persistent volume claim. If not specified, the value is derived from the domainUID as \u0026lt;domainUID\u0026gt;-weblogic-sample-pvc domain1-weblogic-sample-pvc   productionModeEnabled Boolean indicating if production mode is enabled for the domain. true   serverStartPolicy Determines which WebLogic Servers will be started up. Legal values are NEVER, IF_NEEDED, ADMIN_ONLY. IF_NEEDED   t3ChannelPort Port for the T3 channel of the NetworkAccessPoint. 30012   t3PublicAddress Public address for the T3 channel. This should be set to the public address of the Kubernetes cluster. This would normally be a load balancer address. For development environments only: In a single server (all-in-one) Kubernetes deployment, this may be set to the address of the master, or at the very least, it must be set to the address of one of the worker nodes. If not provided, the script will attempt to set it to the IP address of the kubernetes cluster   weblogicCredentialsSecretName Name of the Kubernetes secret for the Administration Server\u0026rsquo;s username and password. If not specified, the value is derived from the domainUID as \u0026lt;domainUID\u0026gt;-weblogic-credentials. domain1-weblogic-credentials   weblogicImagePullSecretName Name of the Kubernetes secret for the Docker Store, used to pull the WebLogic Server image. docker-store-secret    Note that the names of the Kubernetes resources in the generated YAML files may be formed with the value of some of the properties specified in the create-inputs.yaml file. Those properties include the adminServerName, clusterName and managedServerNameBase. If those values contain any characters that are invalid in a Kubernetes service name, those characters are converted to valid values in the generated YAML files. For example, an uppercase letter is converted to a lowercase letter and an underscore (\u0026quot;_\u0026quot;) is converted to a hyphen (\u0026quot;-\u0026quot;).\nThe sample demonstrates how to create a WebLogic domain home and associated Kubernetes resources for a domain that only has one cluster. In addition, the sample provides the capability for users to supply their own scripts to create the domain home for other use cases. The generated domain YAML file could also be modified to cover more use cases.\nVerify the results The create script will verify that the domain was created, and will report failure if there was any error. However, it may be desirable to manually verify the domain, even if just to gain familiarity with the various Kubernetes objects that were created by the script.\nNote that the example results below use the default Kubernetes namespace. If you are using a different namespace, you need to replace NAMESPACE in the example kubectl commands with the actual Kubernetes namespace.\nGenerated YAML files with the default inputs The content of the generated domain.yaml:\n# Copyright 2017, 2019, Oracle Corporation and/or its affiliates. All rights reserved. # Licensed under the Universal Permissive License v 1.0 as shown at http://oss.oracle.com/licenses/upl. # # This is an example of how to define a Domain resource. # apiVersion: \u0026quot;weblogic.oracle/v2\u0026quot; kind: Domain metadata: name: domain1 namespace: default labels: weblogic.resourceVersion: domain-v2 weblogic.domainUID: domain1 spec: # The WebLogic Domain Home domainHome: /shared/domains/domain1 # If the domain home is in the image domainHomeInImage: false # The WebLogic Server Docker image that the operator uses to start the domain image: \u0026quot;store/oracle/weblogic:12.2.1.3\u0026quot; # imagePullPolicy defaults to \u0026quot;Always\u0026quot; if image version is :latest imagePullPolicy: \u0026quot;IfNotPresent\u0026quot; # Identify which Secret contains the credentials for pulling an image #imagePullSecrets: #- name: # Identify which Secret contains the WebLogic Admin credentials (note that there is an example of # how to create that Secret at the end of this file) webLogicCredentialsSecret: name: domain1-weblogic-credentials # Whether to include the server out file into the pod's stdout, default is true includeServerOutInPodLog: true # Whether to enable log home logHomeEnabled: true # The in-pod name location for domain log, server logs, server out, and Node Manager log files logHome: /shared/logs/domain1 # serverStartPolicy legal values are \u0026quot;NEVER\u0026quot;, \u0026quot;IF_NEEDED\u0026quot;, or \u0026quot;ADMIN_ONLY\u0026quot; # This determines which WebLogic Servers the operator will start up when it discovers this Domain # - \u0026quot;NEVER\u0026quot; will not start any server in the domain # - \u0026quot;ADMIN_ONLY\u0026quot; will start up only the administration server (no managed servers will be started) # - \u0026quot;IF_NEEDED\u0026quot; will start all non-clustered servers, including the administration server and clustered servers up to the replica count serverStartPolicy: \u0026quot;IF_NEEDED\u0026quot; serverPod: # an (optional) list of environment variable to be set on the servers env: - name: JAVA_OPTIONS value: \u0026quot;-Dweblogic.StdoutDebugEnabled=false\u0026quot; - name: USER_MEM_ARGS value: \u0026quot;-Djava.security.egd=file:/dev/./urandom -Xms64m -Xmx256m \u0026quot; volumes: - name: weblogic-domain-storage-volume persistentVolumeClaim: claimName: domain1-weblogic-sample-pvc volumeMounts: - mountPath: /shared name: weblogic-domain-storage-volume # adminServer is used to configure the desired behavior for starting the administration server. adminServer: # serverStartState legal values are \u0026quot;RUNNING\u0026quot; or \u0026quot;ADMIN\u0026quot; # \u0026quot;RUNNING\u0026quot; means the listed server will be started up to \u0026quot;RUNNING\u0026quot; mode # \u0026quot;ADMIN\u0026quot; means the listed server will be start up to \u0026quot;ADMIN\u0026quot; mode serverStartState: \u0026quot;RUNNING\u0026quot; # adminService: # channels: # The Admin Server's NodePort # - channelName: default # nodePort: 30701 # Uncomment to export the T3Channel as a service # - channelName: T3Channel # clusters is used to configure the desired behavior for starting member servers of a cluster. # If you use this entry, then the rules will be applied to ALL servers that are members of the named clusters. clusters: - clusterName: cluster-1 serverStartState: \u0026quot;RUNNING\u0026quot; replicas: 2 # The number of managed servers to start for unlisted clusters # replicas: 1  Verify the domain To confirm that the domain was created, use this command:\n$ kubectl describe domain DOMAINUID -n NAMESPACE  Replace DOMAINUID with the domainUID and NAMESPACE with the actual namespace.\nHere is an example of the output of this command:\n$ kubectl describe domain domain1 Name: domain1 Namespace: default Labels: weblogic.domainUID=domain1 weblogic.resourceVersion=domain-v2 Annotations: kubectl.kubernetes.io/last-applied-configuration={\u0026quot;apiVersion\u0026quot;:\u0026quot;weblogic.oracle/v2\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Domain\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;labels\u0026quot;:{\u0026quot;weblogic.domainUID\u0026quot;:\u0026quot;domain1\u0026quot;,\u0026quot;weblogic.resourceVersion\u0026quot;:\u0026quot;do... API Version: weblogic.oracle/v2 Kind: Domain Metadata: Cluster Name: Creation Timestamp: 2019-01-10T14:50:52Z Generation: 1 Resource Version: 3700284 Self Link: /apis/weblogic.oracle/v2/namespaces/default/domains/domain1 UID: 2023ae0a-14e7-11e9-b751-fa163e855ac8 Spec: Admin Server: Server Pod: Annotations: Container Security Context: Env: Labels: Liveness Probe: Node Selector: Pod Security Context: Readiness Probe: Resources: Limits: Requests: Volume Mounts: Volumes: Server Service: Annotations: Labels: Server Start State: RUNNING Clusters: Cluster Name: cluster-1 Cluster Service: Annotations: Labels: Replicas: 2 Server Pod: Annotations: Container Security Context: Env: Labels: Liveness Probe: Node Selector: Pod Security Context: Readiness Probe: Resources: Limits: Requests: Volume Mounts: Volumes: Server Service: Annotations: Labels: Server Start State: RUNNING Domain Home: /shared/domains/domain1 Domain Home In Image: false Image: store/oracle/weblogic:12.2.1.3 Image Pull Policy: IfNotPresent Include Server Out In Pod Log: true Log Home: /shared/logs/domain1 Log Home Enabled: true Managed Servers: Server Pod: Annotations: Container Security Context: Env: Name: JAVA_OPTIONS Value: -Dweblogic.StdoutDebugEnabled=false Name: USER_MEM_ARGS Value: -Xms64m -Xmx256m Labels: Liveness Probe: Node Selector: Pod Security Context: Readiness Probe: Resources: Limits: Requests: Volume Mounts: Mount Path: /shared Name: weblogic-domain-storage-volume Volumes: Name: weblogic-domain-storage-volume Persistent Volume Claim: Claim Name: domain1-weblogic-sample-pvc Server Service: Annotations: Labels: Server Start Policy: IF_NEEDED Web Logic Credentials Secret: Name: domain1-weblogic-credentials Status: Conditions: Last Transition Time: 2019-01-10T14:52:33.878Z Reason: ServersReady Status: True Type: Available Servers: Health: Activation Time: 2019-01-10T14:52:07.351Z Overall Health: ok Subsystems: Node Name: slc16ffk Server Name: admin-server State: RUNNING Cluster Name: cluster-1 Health: Activation Time: 2019-01-10T14:53:30.352Z Overall Health: ok Subsystems: Node Name: slc16ffk Server Name: managed-server1 State: RUNNING Cluster Name: cluster-1 Health: Activation Time: 2019-01-10T14:53:26.503Z Overall Health: ok Subsystems: Node Name: slc16ffk Server Name: managed-server2 State: RUNNING Start Time: 2019-01-10T14:50:52.104Z Events: \u0026lt;none\u0026gt;  In the Status section of the output, the available servers and clusters are listed. Note that if this command is issued very soon after the script finishes, there may be no servers available yet, or perhaps only the Administration Server but no Managed Servers. The operator will start up the Administration Server first and wait for it to become ready before starting the Managed Servers.\nVerify the pods Use the following command to see the pods running the servers:\n$ kubectl get pods -n NAMESPACE  Here is an example of the output of this command:\n$ kubectl get pods NAME READY STATUS RESTARTS AGE domain1-admin-server 1/1 Running 0 1m domain1-managed-server1 1/1 Running 0 8m domain1-managed-server2 1/1 Running 0 8m  Verify the services Use the following command to see the services for the domain:\n$ kubectl get services -n NAMESPACE  Here is an example of the output of this command:\n$ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE domain1-admin-server ClusterIP 10.96.206.134 \u0026lt;none\u0026gt; 7001/TCP 23m domain1-admin-server-external NodePort 10.107.164.241 \u0026lt;none\u0026gt; 30012:30012/TCP 22m domain1-cluster-cluster-1 ClusterIP 10.109.133.168 \u0026lt;none\u0026gt; 8001/TCP 22m domain1-managed-server1 ClusterIP None \u0026lt;none\u0026gt; 8001/TCP 22m domain1-managed-server2 ClusterIP None \u0026lt;none\u0026gt; 8001/TCP 22m  Delete the generated domain home Sometimes in production, but most likely in testing environments, you might want to remove the domain home that is generated using the create-domain.sh script. Do this by running the generated delete domain job script in the /path/to/weblogic-operator-output-directory/weblogic-domains/\u0026lt;domainUID\u0026gt; directory.\n$ kubectl create -f delete-domain-job.yaml  Troubleshooting  Message: status on iteration 20 of 20 pod domain1-create-weblogic-sample-domain-job-4qwt2 status is Pending The create domain job is not showing status completed after waiting 300 seconds.\nThe most likely cause is related to the value of persistentVolumeClaimName, defined in domain-home-on-pv/create-domain-inputs.yaml. To determine if this is the problem:\n Execute kubectl get all --all-namespaces to find the name of the create-weblogic-sample-domain-job. Execute kubectl describe pod \u0026lt;name-of-create-weblogic-sample-domain-job\u0026gt; to see if there is an event that has text similar to persistentvolumeclaim \u0026quot;domain1-weblogic-sample-pvc\u0026quot; not found. Find the name of the PVC that was created by executing create-pv-pvc.sh, using kubectl describe pvc. It is likely to be weblogic-sample-pvc. Change the value of persistentVolumeClaimName to match the name created when you executed create-pv-pvc.sh. Rerun the create-domain.sh script with the same arguments as you did before. Verify that the operator is deployed. Use the command:  kubectl get all --all-namespaces  Look for lines similar to:  weblogic-operator1 pod/weblogic-operator-  If you do not find something similar in the output, the WebLogic Operator for Kubernetes may not have been installed completely. Review the operator installation instructions.  Message: ERROR: Unable to create folder /shared/domains\nThe most common cause is a poor choice of value for weblogicDomainStoragePath in the input file used when you executed:\ncreate-pv-pvc.sh  You should delete the resources for your sample domain, correct the value in that file, and rerun the commands to create the PV/PVC and the credential before you attempt to rerun:\ncreate-domain.sh  A correct value for weblogicDomainStoragePath will meet the following requirements:\n Must be the name of a directory. The directory must be world writable.\n  Optionally, follow these steps to tighten permissions on the named directory after you run the sample the first time:\n Become the root user. ls -nd $value-of-weblogicDomainStoragePath Note the values of the third and fourth field of the output. chown $third-field:$fourth-field $value-of-weblogicDomainStoragePath chmod 755 $value-of-weblogicDomainStoragePath Return to your normal user ID.  Message: ERROR: The create domain job will not overwrite an existing domain. The domain folder /shared/domains/domain1 already exists\nYou will see this message if the directory domains/domain1 exists in the directory named as the value of weblogicDomainStoragePath in create-pv-pvc-inputs.yaml. For example, if the value of weblogicDomainStoragePath is /tmp/wls-op-4-k8s, you would need to remove (or move) /tmp/wls-op-4-k8s/domains/domain1.\n  "
},
{
	"uri": "/weblogic-kubernetes-operator/samples/production/",
	"title": "Production Samples",
	"tags": [],
	"description": "",
	"content": "The samples in this section are intended to help you create a production deployment of WebLogic on Kubernetes.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-operators/using-the-operator/using-kubectl/",
	"title": "Use kubectl",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-operators/using-the-operator/",
	"title": "Use the Operator",
	"tags": [],
	"description": "",
	"content": "\r\rUse Helm\r\rUseful Helm operations\n\rUse kubectl\r\r\n\rThe REST API\r\rUse the operator\u0026#39;s REST services\n\rLife Cycle\r\r\n\rLogs\r\r\n\r"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/integrations/exporting-metrics/prometheus/",
	"title": "Prometheus",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/integrations/exporting-logs/",
	"title": "Export Logs",
	"tags": [],
	"description": "",
	"content": "Lorem Ipsum.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/domain-in-image/patching/",
	"title": "Patching",
	"tags": [],
	"description": "",
	"content": "Lorem Ipsum.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/persistent-storage/",
	"title": "Persistent Storage",
	"tags": [],
	"description": "",
	"content": " This document outlines how to set up a Kubernetes persistent volume and persistent volume claim which can be used as storage for WebLogic domain homes and log files. A persistent volume can be shared by multiple WebLogic domains or dedicated to a particular domain.\nPrerequisites The following prerequisites must be fulfilled before proceeding with the creation of the volume.\n Create a Kubernetes namespace for the persistent volume claim unless the intention is to use the default namespace. Note that a persistent volume claim has to be in the same namespace as the domain resource that uses it. Make sure that all the servers in the WebLogic domain are able to reach the storage location. Make sure that the host directory that will be used, already exists and has the appropriate file permissions set.  Storage locations Persistent volumes can point to different storage locations, for example NFS servers or a local directory path. The list of available options is listed in the Kubernetes documentation.\nNote regarding HostPath: In a single-node Kubernetes cluster, such as may be used for testing or proof of concept activities, HOST_PATH provides the simplest configuration. In a multinode Kubernetes cluster, a HOST_PATH that is located on shared storage mounted by all nodes in the Kubernetes cluster is the simplest configuration. If nodes do not have shared storage, then NFS is probably the most widely available option. There are other options listed in the referenced table.\nThe persistent volume for the domain must be created using the appropriate tools before running the script to create the domain. In the simplest case, namely the HOST_PATH provider, this means creating a directory on the Kubernetes master and ensuring that it has the correct permissions:\n$ mkdir -m 777 -p /path/to/domain1PersistentVolume  Note regarding NFS: In the current GA version, the OCI Container Engine for Kubernetes supports network block storage that can be shared across nodes with access permission RWOnce (meaning that only one can write, others can read only). At this time, the WebLogic on Kubernetes domain created by the WebLogic Server Kubernetes Operator, requires a shared file system to store the WebLogic domain configuration, which MUST be accessible from all the pods across the nodes. As a workaround, you need to install an NFS server on one node and share the file system across all the nodes.\nCurrently, we recommend that you use NFS version 3.0 for running WebLogic Server on OCI Container Engine for Kubernetes. During certification, we found that when using NFS 4.0, the servers in the WebLogic domain went into a failed state intermittently. Because multiple threads use NFS (default store, diagnostics store, Node Manager, logging, and domain_home), there are issues when accessing the file store. These issues are removed by changing the NFS to version 3.0.\nYAML files Persistent volumes and claims are described in YAML files. For each persistent volume, you should create one persistent volume YAML file and one persistent volume claim YAML file. In the example below, you will find two YAML templates, one for the volume and one for the claim. As stated above, they either can be dedicated to a specific domain, or shared across multiple domains. For the use cases where a volume will be dedicated to a particular domain, it is a best practice to label it with weblogic.domainUID=[domain name]. This makes it easy to search for, and clean up resources associated with that particular domain.\nFor sample YAML templates, refer to the Persistent volumes example.\nKubernetes resources After you have written your YAML files, you use them to create the persistent volume by creating Kubernetes resources using the kubectl create -f command.\n$ kubectl create -f pv.yaml $ kubectl create -f pvc.yaml  Verify the results To confirm that the persistent volume was created, use these commands:\n$ kubectl describe pv [persistent volume name] $ kubectl describe pvc -n NAMESPACE [persistent volume claim name]  Common problems This section provides details of common problems that might occur while running the script and how to resolve them.\nPersistent volume provider not configured correctly Possibly the most common problem experienced during testing was the incorrect configuration of the persistent volume provider. The persistent volume must be accessible to all Kubernetes nodes, and must be able to be mounted as Read/Write/Many. If this is not the case, the persistent volume creation will fail.\nThe simplest case is where the HOST_PATH provider is used. This can be either with one Kubernetes node, or with the HOST_PATH residing in shared storage available at the same location on every node (for example, on an NFS mount). In this case, the path used for the persistent volume must have its permission bits set to 777.\nFurther reading  See the blog, \u0026ldquo;How to run WebLogic clusters on the Oracle Cloud Infrastructure Container Engine for Kubernetes.\u0026rdquo;  "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "Learn about the operator&#39;s design, architecture, terms, and prerequisites.",
	"content": "\r\rGet Started\r\rAn operator is an application-specific controller that extends Kubernetes to create, configure, and manage instances of complex applications. The Oracle WebLogic Server Kubernetes Operator follows the standard Kubernetes operator pattern, and simplifies the management and operation of WebLogic domains and deployments. You can have one or more operators in your Kubernetes cluster that manage one or more WebLogic domains each. We provide a Helm chart to manage the installation and configuration of the operator.\n\rDemo\r\rThis video provides a demonstration of the WebLogic Server Kubernetes Operator. \rArchitecture\r\rThe operator consists of the following parts: The operator runtime, a process that runs in a Docker container deployed into a Kubernetes pod and which performs the actual management tasks. The model for a Kubernetes custom resource definition (CRD) that when installed in a Kubernetes cluster allows the Kubernetes API server to manage instances of this new type representing the operational details and status of WebLogic domains. A Helm chart for installing the operator runtime and related resources.\n\rDesign philosophy\r\rThe Oracle WebLogic Server Kubernetes Operator (the “operator”) is designed to fulfill a similar role to that which a human operator would fill in a traditional data center deployment. It contains a set of useful built-in knowledge about how to perform various life cycle operations on a domain correctly. Human operators are normally responsible for starting and stopping environments, initiating backups, performing scaling operations, performing manual tasks associated with disaster recovery and high availability needs and coordinating actions with other operators in other data centers.\n\rThis guide provides detailed user information for the Oracle WebLogic Server Kubernetes Operator. It provides instructions on how to install the operator in your Kubernetes cluster and how to use it to manage WebLogic domains. If you are looking for information about how the operator is designed, implemented, built, and such, then you should refer to the Developer guide.\nImportant terms This documentation uses several important terms which are intended to have a specific meaning.\n   Term Definition     Cluster Because this term is ambiguous, it will be prefixed to indicate which type of cluster is meant. A WebLogic cluster is a group of Managed Servers that together host some application or component and which are able to share load and state between them. A Kubernetes cluster is a group of machines (“nodes”) that all host Kubernetes resources, like pods and services, and which appear to the external user as a single entity. If the term “cluster” is not prefixed, it should be assumed to mean a Kubernetes cluster.   Domain A WebLogic domain is a group of related applications and resources along with the configuration information necessary to run them.   Ingress A Kubernetes Ingress provides access to applications and services in a Kubernetes environment to external clients. An Ingress may also provide additional features like load balancing.   Namespace A Kubernetes namespace is a named entity that can be used to group together related objects, for example, pods and services.   Operator A Kubernetes operator is software that performs management of complex applications.   Pod A Kubernetes pod contains one or more containers and is the object that provides the execution environment for an instance of an application component, such as a web server or database.   Job A Kubernetes job is a type of controller that creates one or more pods that run to completion to complete a specific task.   Secret A Kubernetes secret is a named object that can store secret information like user names, passwords, X.509 certificates, or any other arbitrary data.   Service A Kubernetes service exposes application endpoints inside a pod to other pods, or outside the Kubernetes cluster. A service may also provide additional features like load balancing.    Additional reading Before using the operator, you might want to read the design philosophy to develop an understanding of the operator\u0026rsquo;s design, and the architectural overview to understand its architecture, including how WebLogic domains are deployed in Kubernetes using the operator. Also, worth reading are the details of the Kubernetes RBAC definitions required by the operator.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/overview/",
	"title": "Overview",
	"tags": [],
	"description": "The information in the following sections is organized in the order that you would most likely need to use it.  If you want to set up an operator and use it to create and manage WebLogic domains, you should follow the User Guide sections from top to bottom, and the necessary information will be presented in the correct order.",
	"content": "\r\rPrepare your environment\r\rPrepare your environment, then install and use the operator to manage domains.\n\r"
},
{
	"uri": "/weblogic-kubernetes-operator/reference/swagger/",
	"title": "Swagger",
	"tags": [],
	"description": "",
	"content": "You can view the Swagger REST API documentation here.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/quickstart/prerequisites/",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": "For this exercise, you’ll need a Kubernetes cluster. If you need help setting one up, check out our cheat sheet. This guide assumes a single node cluster.\nThe operator uses Helm to create and deploy the necessary resources and then run the operator in a Kubernetes cluster. For Helm installation and usage information, see Install Helm and Tiller.\nYou should clone this repository to your local machine so that you have access to the various sample files mentioned throughout this guide:\n$ git clone https://github.com/oracle/weblogic-kubernetes-operator  "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/",
	"title": "User Guide",
	"tags": [],
	"description": "",
	"content": " User Guide The User Guide provides detailed information about all aspects of using the operator.\n\rIntroduction\r\rLearn about the operator\u0026#39;s design, architecture, terms, and prerequisites.\n\rOverview\r\rThe information in the following sections is organized in the order that you would most likely need to use it. If you want to set up an operator and use it to create and manage WebLogic domains, you should follow the User Guide sections from top to bottom, and the necessary information will be presented in the correct order.\n\rManage Operators\r\rHelm is used to create and deploy necessary operator resources and to run the operator in a Kubernetes cluster.\n\rManage Domains\r\rImportant considerations for WebLogic domains in Kubernetes\n\r"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/introduction/architecture/",
	"title": "Architecture",
	"tags": [],
	"description": "",
	"content": " The operator consists of the following parts:\n The operator runtime, a process that runs in a Docker container deployed into a Kubernetes pod and which performs the actual management tasks. The model for a Kubernetes custom resource definition (CRD) that when installed in a Kubernetes cluster allows the Kubernetes API server to manage instances of this new type representing the operational details and status of WebLogic domains. A Helm chart for installing the operator runtime and related resources. A variety of sample shell scripts for preparing or packaging WebLogic domains for running in Kubernetes. A variety of sample Helm charts or shell scripts for conditionally exposing WebLogic endpoints outside the Kubernetes cluster.  The operator is packaged in a Docker image which you can access using the following docker pull commands:\n$ docker login $ docker pull oracle/weblogic-kubernetes-operator:2.0-rc2  For more details on acquiring the operator image and prerequisites for installing the operator, consult the Quick Start guide.\nThe operator registers a Kubernetes custom resource definition called domain.weblogic.oracle (shortname domain, plural domains). More details about the domain resource type defined by this CRD, including its schema, are available here.\nThe diagram below shows the general layout of high-level components, including optional components, in a Kubernetes cluster that is hosting WebLogic domains and the operator:\nThe Kubernetes cluster has several namespaces. Components may be deployed into namespaces as follows:\n The operator is deployed into its own namespace. If the Elastic Stack integration option is configured, then a Logstash pod will also be deployed in the operator’s namespace. WebLogic domains will be deployed into various namespaces. There can be more than one domain in a namespace, if desired. There is no limit on the number of domains or namespaces that an operator can manage. Note that there can be more than one operator in a Kubernetes cluster, but each operator is configured with a list of the specific namespaces that it is responsible for. The operator will not take any action on any domain that is not in one of the namespaces the operator is configured to manage. Customers are responsible for load balancer configuration, which will typically be in the same namespace with domains or in a system, shared namespace such as the kube-system namespace. Customers are responsible for Elasticsearch and Kibana deployment, which are typically deployed in the default namespace.  Domain architecture The diagram below shows how the various parts of a WebLogic domain are manifest in Kubernetes by the operator.\nThis diagram shows the following details:\n An optional, persistent volume is created by the customer using one of the available providers. If the persistent volume is shared across the domain or members of a cluster, then the chosen provider must support “Read Write Many” access mode. The shared state on the persistent volume may include the “domain” directory, the “applications” directory, a directory for storing logs, and a directory for any file-based persistence stores. A pod is created for the WebLogic Administration Server. This pod is labeled with weblogic.domainUID, weblogic.serverName, and weblogic.domainName. One container runs in this pod. WebLogic Node Manager and Administration Server processes are run inside this container. The Node Manager process is used as an internal implementation detail for the liveness probe, for patching, and to provide monitoring and control capabilities to the Administration Console. It is not intended to be used for other purposes, and it may be removed in some future release. A ClusterIP type service is created for the Administration Server pod. This service provides a stable, well-known network (DNS) name for the Administration Server. This name is derived from the domainUID and the Administration Server name, and it is known before starting up any pod. The Administration Server ListenAddress is set to this well-known name. ClusterIP type services are only visible inside the Kubernetes cluster. They are used to provide the well-known names that all of the servers in a domain use to communicate with each other. This service is labeled with weblogic.domainUID and weblogic.domainName. A NodePort type service is optionally created for the Administration Server pod. This service provides HTTP access to the Administration Server to clients that are outside the Kubernetes cluster. This service is intended to be used to access the WebLogic Server Administration Console or for the T3 protocol for WLST connections. This service is labeled with weblogic.domainUID and weblogic.domainName. A pod is created for each WebLogic Managed Server. These pods are labeled with weblogic.domainUID, weblogic.serverName, and weblogic.domainName. One container runs in each pod. WebLogic Node Manager and Managed Server processes are run inside each of these containers. The Node Manager process is used as an internal implementation detail for the liveness probe. It is not intended to be used for other purposes, and it may be removed in some future release. A ClusterIP type service is created for each Managed Server pod that contains a Managed Server that is not part of a WebLogic cluster. These services are intended to be used to access applications running on the Managed Servers. These services are labeled with weblogic.domainUID and weblogic.domainName. Customers must expose these services using a load balancer or NodePort type service to expose these endpoints outside the Kubernetes cluster. An Ingress may optionally be created by the customer for each WebLogic cluster. An Ingress provides load balanced HTTP access to all Managed Servers in that WebLogic cluster. The load balancer updates its routing table for an Ingress every time a Managed Server in the WebLogic cluster becomes “ready” or ceases to be able to service requests, such that the Ingress always points to just those Managed Servers that are able to handle user requests.  The diagram below shows the components inside the containers running WebLogic Server instances:\nThe domain resource specifies a Docker image, defaulting to store/oracle/weblogic:12.2.1.3. All containers running WebLogic Server use this same Docker image. Depending on the use case, this image could contain the WebLogic Server product binaries or also include the domain directory. Note: During a rolling event caused by a change to the domain resource\u0026rsquo;s image field, containers will be using a mix of the updated value of the image field and its previous value.\nWithin the container, the following aspects are configured by the operator:\n The ENTRYPOINT is configured by a script that starts up a Node Manager process, and then uses WLST to request that Node Manager start the server. Node Manager is used to start servers so that the socket connection to the server will be available to obtain server status even when the server is unresponsive. This is used by the liveness probe. The liveness probe is configured to check that the server is alive by querying the Node Manager process. The liveness probe is by default configured to check liveness every 15 seconds, and to timeout after 5 seconds. If a pod fails the liveness probe, Kubernetes will restart that container. The readiness probe is configured to use the WebLogic Server ReadyApp framework. The readiness probe is used to determine if the server is ready to accept user requests. The readiness is used to determine when a server should be included in a load balancer\u0026rsquo;s endpoints, when a restarted server is fully started in the case of a rolling restart, and for various other purposes. A shutdown hook is configured that will execute a script that performs a graceful shutdown of the server. This ensures that servers have an opportunity to shut down cleanly before they are killed.  Domain state stored outside Docker images The operator expects (and requires) that all state be stored outside of the Docker images that are used to run the domain. This means either in a persistent file system, or in a database. The WebLogic configuration, that is, the domain directory and the applications directory may come from the Docker image or a persistent volume. However, other state, such as file-based persistent stores, and such, must be stored on a persistent volume or in a database. All of the containers that are participating in the WebLogic domain use the same image, and take on their personality; that is, which server they execute, at startup time. Each pod mounts storage, according to the domain resource, and has access to the state information that it needs to fulfill its role in the domain.\nIt is worth providing some background information on why this approach was adopted, in addition to the fact that this separation is consistent with other existing operators (for other products) and the Kubernetes “cattle, not pets” philosophy when it comes to containers.\nThe external state approach allows the operator to treat the Docker images as essentially immutable, read-only, binary images. This means that the image needs to be pulled only once, and that many domains can share the same image. This helps to minimize the amount of bandwidth and storage needed for WebLogic Server Docker images.\nThis approach also eliminates the need to manage any state created in a running container, because all of the state that needs to be preserved is written into either the persistent volume or a database back end. The containers and pods are completely throwaway and can be replaced with new containers and pods, as necessary. This makes handling failures and rolling restarts much simpler because there is no need to preserve any state inside a running container.\nWhen users wish to apply a binary patch to WebLogic Server, it is necessary to create only a single new, patched Docker image. If desired, any domains that are running may be updated to this new patched image with a rolling restart, because there is no state in the containers.\nIt is envisaged that in some future release of the operator, it will be desirable to be able to “move” or “copy” domains in order to support scenarios like Kubernetes federation, high availability, and disaster recovery. Separating the state from the running containers is seen as a way to greatly simplify this feature, and to minimize the amount of data that would need to be moved over the network, because the configuration is generally much smaller than the size of WebLogic Server Docker images.\nThe team developing the operator felt that these considerations provided adequate justification for adopting the external state approach.\nNetwork name predictability The operator uses services to provide stable, well-known DNS names for each server. These names are known in advance of starting up a pod to run a server, and are used in the ListenAddress fields in the WebLogic Server configuration to ensure that servers will always be able to find each other. This also eliminates the need for pod names or the actual WebLogic Server instance names to be the same as the DNS addresses.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/accessing-the-domain/rest/",
	"title": "WebLogic REST APIs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/accessing-the-domain/wlst/",
	"title": "Using WLST",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/security/encryption/",
	"title": "Encryption",
	"tags": [],
	"description": "WebLogic Domain encryption and the WebLogic Operator",
	"content": "TODO\n"
},
{
	"uri": "/weblogic-kubernetes-operator/samples/simple/domains/domain-home-in-image/",
	"title": "Domain Home in Image",
	"tags": [],
	"description": "",
	"content": " WebLogic sample domain home in Docker image The sample scripts demonstrate the creation of a WebLogic domain home in a Docker image using one of the domain home in image samples in the WebLogic Server Domain Docker image samples GitHub project. The sample scripts have an option of putting the WebLogic domain log, server logs, server output files, and the Node Manager logs on an existing Kubernetes persistent volume (PV) and persistent volume claim (PVC). The scripts also generate the domain YAML file, which can then be used by the scripts or used manually to start the Kubernetes artifacts of the corresponding domain, including the WebLogic Server pods and services.\nPrerequisites Before you begin, read this guide, Domain Resource.\nThe following prerequisites must be handled prior to running the create domain script:\n The WDT sample requires that JAVA_HOME is set to a Java JDK version 1.8 or later. The operator requires WebLogic Server 12.2.1.3.0 with patch 29135930 applied. The existing WebLogic Docker image, store/oracle/weblogic:12.2.1.3, was updated on January 17, 2019, and has all the necessary patches applied; a docker pull is required if you pulled the image prior to that date. Refer to WebLogic Docker images for details on how to obtain or create the image. Create a Kubernetes namespace for the domain unless the intention is to use the default namespace. If logHomeOnPV is enabled, create the Kubernetes persistent volume where the log home will be hosted, and the Kubernetes persistent volume claim for the domain in the same Kubernates namespace. For samples to create a PV and PVC, see Create sample PV and PVC. Create a Kubernetes secret for the WebLogic administrator credentials that contains the fields username and password, and make sure that the secret name matches the value specified for weblogicCredentialsSecretName (see Configuration table below). For example:  $ cd ./kubernetes/samples/scripts/create-weblogic-domain-credentials $ create-weblogic-credentials.sh -u weblogic -p welcome1 -d domain1 -n default -s domain1-weblogic-credentials  NOTE: Then make sure to configure weblogicCredentialsSecretName to be domain1-weblogic-credentials.\nUse the script to create a domain Note: The create-domain.sh script generates a new Docker image on each run with a new domain home and a different internal domain secret in it. To prevent having disparate images with different domain secrets in the same domain, we strongly recommend that a new domain uses a domainUID that is different from any of the active domains, or that you delete the existing domain resource using the following command and wait until all the server pods are terminated before you create a domain with the same domainUID:\n$kubectl delete domain [domainUID] -n [domainNamespace]  Make a copy of the create-domain-inputs.yaml file, and run the create script, pointing it at your inputs file and an output directory:\n$ ./create-domain.sh \\ -u \u0026lt;username\u0026gt; \\ -p \u0026lt;password\u0026gt; \\ -i create-domain-inputs.yaml \\ -o /path/to/output-directory  The script will perform the following steps:\n Create a directory for the generated properties and Kubernetes YAML files for this domain if it does not already exist. The pathname is /path/to/weblogic-operator-output-directory/weblogic-domains/\u0026lt;domainUID\u0026gt;. If the directory already exists, its contents will be removed. Create a properties file, domain.properties, in the directory that is created above. This properties file will be used to create a sample WebLogic Server domain. Clone the WebLogic docker-images project into the directory that is derived from the domainHomeImageBuildPath property using git clone https://github.com/oracle/docker-images.git. By default, the script always cleans up the directory and clones it again on every run. You need to specify the -k option if you want to use a previously cloned project. Note that if the specified domainHomeImageBuildPath is empty, the script will still clone the project even if the -k option is specified. Replace the built-in user name and password in the properties/docker-build/domain_security.properties file with the username and password that are supplied on the command line using the -u and -p options. These credentials need to match the WebLogic domain admin credentials in the secret that is specified via the weblogicCredentialsSecretName property in the create-domain-inputs.yaml file. Build a Docker image based on the Docker sample, Example Image with a WebLogic Server Domain using the Oracle WebLogic Scripting Tooling (WLST) or Example Image with a WebLogic Server Domain using the Oracle WebLogic Deploy Tooling (WDT). It will create a sample WebLogic Server domain in the Docker image. Oracle strongly recommends storing the image containing the domain home as private in the registry (e.g. Oracle Cloud Infrastructure Registry, Docker Hub, etc.) as this image contains sensitive information about the domain including keys and credentials that are used to access external resources (e.g. datasource password). For more information about domain home in image protection see the Security section.\n\r Create a tag that refers to the generated Docker image. Create a Kubernetes domain YAML file, domain.yaml, in the directory that is created above. This YAML file can be used to create the Kubernetes resource using the kubectl create -f or kubectl apply -f command.  $ kubectl apply -f /path/to/output-directory/weblogic-domains/\u0026lt;domainUID\u0026gt;/domain.yaml   As a convenience, using the -e option, the script can optionally create the domain object, which in turn results in the creation of the corresponding WebLogic Server pods and services. This option should be used in a single node Kubernetes cluster only.\nFor a multi-node Kubernetes cluster, make sure that the generated image is available on all nodes before creating the domain resource using the kubectl apply -f command.\nThe usage of the create script is as follows:\n$ sh create-domain.sh -h usage: create-domain.sh -o dir -i file -u username -p password [-k] [-e] [-h] -i Parameter inputs file, must be specified. -o Ouput directory for the generated properties and YAML files, must be specified. -u User name used in building the Docker image for WebLogic domain in image. -p Password used in building the Docker image for WebLogic domain in image. -e Also create the resources in the generated YAML files, optional. -v Validate the existence of persistentVolumeClaim, optional. -k Keep what has been previously cloned from https://github.com/oracle/docker-images.git, optional. If not specified, this script will always remove the existing project and clone again. -h Help  If you copy the sample scripts to a different location, make sure that you copy everything in the \u0026lt;weblogic-kubernetes-operator-project\u0026gt;/kubernetes/samples/scripts directory together into the target directory, maintaining the original directory hierarchy.\nThe default domain created by the script has the following characteristics:\n An Administration Server named admin-server listening on port 7001. A dynamic cluster named cluster-1 of size 5. Two Managed Servers, named managed-server1 and managed-server2, listening on port 8001. No applications deployed. A T3 channel.  If you run the sample from a machine that is remote to the Kubernetes cluster, and you need to push the new image to a registry that is local to the cluster, you need to do the following (also see the image property in the Configuration parameters table in the next section):\n Set the image property in the inputs file to the target image name (including the registry hostname/port and the tag, if needed). Run the create-domain.sh script without the -e option. Push the image to the target registry. Run the following command to create the domain:  $ kubectl apply -f /path/to/output-directory/weblogic-domains/\u0026lt;domainUID\u0026gt;/domain.yaml  The domain creation inputs can be customized by editing create-domain-inputs.yaml.\nConfiguration parameters The following parameters can be provided in the inputs file.\n   Parameter Definition Default     adminPort Port number for the Administration Server inside the Kubernetes cluster. 7001   adminNodePort Port number of the Administration Server outside the Kubernetes cluster. 30701   adminServerName Name of the Administration Server. admin-server   clusterName Name of the WebLogic cluster instance to generate for the domain. cluster-1   configuredManagedServerCount Number of Managed Server instances to generate for the domain. 5   domainHomeImageBase Base WebLogic binary image used to build the WebLogic domain image. The operator requires WebLogic Server 12.2.1.3.0 with patch 29135930 applied. The existing WebLogic Docker image, store/oracle/weblogic:12.2.1.3, was updated on January 17, 2019, and has all the necessary patches applied; a docker pull is required if you pulled the image prior to that date. Refer to WebLogic Docker images for details on how to obtain or create the image. store/oracle/weblogic:12.2.1.3   domainHomeImageBuildPath Location of the WebLogic \u0026ldquo;domain home in image\u0026rdquo; Docker image in https://github.com/oracle/docker-images.git project. If not specified, use \u0026ldquo;./docker-images/OracleWebLogic/samples/12213-domain-home-in-image\u0026rdquo;. Another possible value is \u0026ldquo;./docker-images/OracleWebLogic/samples/12213-domain-home-in-image-wdt\u0026rdquo; which uses WDT, instead of WLST, to generate the domain configuration. ./docker-images/OracleWebLogic/samples/12213-domain-home-in-image   domainPVMountPath Mount path of the domain persistent volume. This parameter is required if logHomeOnPV is true. Otherwise, it is ignored. /shared   domainUID Unique ID that will be used to identify this particular domain. Used as the name of the generated WebLogic domain as well as the name of the Kubernetes domain resource. This ID must be unique across all domains in a Kubernetes cluster. This ID cannot contain any character that is not valid in a Kubernetes service name. domain1   exposeAdminNodePort Boolean indicating if the Administration Server is exposed outside of the Kubernetes cluster. false   exposeAdminT3Channel Boolean indicating if the T3 administrative channel is exposed outside the Kubernetes cluster. false   image WebLogic Server Docker image that the operator uses to start the domain. The create domain scripts generate a WebLogic Server Docker image with a domain home in it. By default, the scripts tag the generated WebLogic server Docker image as either domain-home-in-image or domain-home-in-image-wdt based on the domainHomeImageBuildPath property, and use it plus the tag that is obtained from the domainHomeImageBase to set the image element in the generated domain YAML file. If this property is set, the create domain scripts will use the value specified, instead of the default value, to tag the generated image and set the image in the domain YAML file. A unique value is required for each domain that is created using the scripts. If you are running the sample scripts from a machine that is remote to the Kubernetes cluster where the domain is going to be running, you need to set this property to the image name that is intended to be used in a registry local to that Kubernetes cluster. You also need to push the image to that registry before starting the domain using the kubectl create -f or kubectl apply -f command.    imagePullPolicy WebLogic Docker image pull policy. Legal values are IfNotPresent, Always, or Never. IfNotPresent   imagePullSecretName Name of the Kubernetes secret to access the Docker Store to pull the WebLogic Server Docker image. The presence of the secret will be validated when this parameter is specified.    includeServerOutInPodLog Boolean indicating whether to include server.out to the pod\u0026rsquo;s stdout. true   initialManagedServerReplicas Number of Managed Servers to initially start for the domain. 2   javaOptions Java options for starting the Administration and Managed Servers. A Java option can have references to one or more of the following pre-defined variables to obtain WebLogic domain information: $(DOMAIN_NAME), $(DOMAIN_HOME), $(ADMIN_NAME), $(ADMIN_PORT), and $(SERVER_NAME). -Dweblogic.StdoutDebugEnabled=false   logHomeOnPV Specifies whether the log home is stored on the persistent volume. If set to true, then you must specify the logHome, persistentVolumeClaimName and domainPVMountPath parameters. false   logHome The in-pod location for domain log, server logs, server out, and Node Manager log files. If not specified, the value is derived from the domainUID as /shared/logs/\u0026lt;domainUID\u0026gt;. This parameter is required if logHomeOnPV is true. Otherwise, it is ignored. /shared/logs/domain1   managedServerNameBase Base string used to generate Managed Server names. managed-server   managedServerPort Port number for each Managed Server. 8001   namespace Kubernetes namespace in which to create the domain. default   persistentVolumeClaimName Name of the persistent volume claim. If not specified, the value is derived from the domainUID as \u0026lt;domainUID\u0026gt;-weblogic-sample-pvc. This parameter is required if logHomeOnPV is true. Otherwise, it is ignored. domain1-weblogic-sample-pvc   productionModeEnabled Boolean indicating if production mode is enabled for the domain. true   serverStartPolicy Determines which WebLogic Servers will be started up. Legal values are NEVER, IF_NEEDED, ADMIN_ONLY. IF_NEEDED   t3ChannelPort Port for the T3 channel of the NetworkAccessPoint. 30012   t3PublicAddress Public address for the T3 channel. This should be set to the public address of the Kubernetes cluster. This would normally be a load balancer address. For development environments only: In a single server (all-in-one) Kubernetes deployment, this may be set to the address of the master, or at the very least, it must be set to the address of one of the worker nodes. If not provided, the script will attempt to set it to the IP address of the kubernetes cluster   weblogicCredentialsSecretName Name of the Kubernetes secret for the Administration Server\u0026rsquo;s user name and password. domain1-weblogic-credentials    Note that the names of the Kubernetes resources in the generated YAML files may be formed with the value of some of the properties specified in the create-inputs.yaml file. Those properties include the adminServerName, clusterName and managedServerNameBase. If those values contain any characters that are invalid in a Kubernetes service name, those characters are converted to valid values in the generated YAML files. For example, an uppercase letter is converted to a lowercase letter and an underscore (\u0026quot;_\u0026quot;) is converted to a hyphen (\u0026quot;-\u0026quot;).\nThe sample demonstrates how to create a WebLogic domain home and associated Kubernetes resources for a domain that has only one cluster. In addition, the sample provides the capability for users to supply their own scripts to create the domain home for other use cases. Also, the generated domain YAML file can be modified to cover more use cases.\nVerify the results The create script will verify that the domain was created, and will report failure if there was any error. However, it may be desirable to manually verify the domain, even if just to gain familiarity with the various Kubernetes objects that were created by the script.\nNote that the example results below use the default Kubernetes namespace. If you are using a different namespace, you need to replace NAMESPACE in the example kubectl commands with the actual Kubernetes namespace.\nGenerated YAML files with the default inputs The content of the generated domain.yaml:\n# Copyright 2017, 2019, Oracle Corporation and/or its affiliates. All rights reserved. # Licensed under the Universal Permissive License v 1.0 as shown at http://oss.oracle.com/licenses/upl. # # This is an example of how to define a Domain resource. # apiVersion: \u0026quot;weblogic.oracle/v2\u0026quot; kind: Domain metadata: name: domain1 namespace: default labels: weblogic.resourceVersion: domain-v2 weblogic.domainUID: domain1 spec: # The WebLogic Domain Home domainHome: /u01/oracle/user_projects/domains/domain1 # If the domain home is in the image domainHomeInImage: true # The WebLogic Server Docker image that the operator uses to start the domain image: \u0026quot;domain-home-in-image:12.2.1.3\u0026quot; # imagePullPolicy defaults to \u0026quot;Always\u0026quot; if image version is :latest imagePullPolicy: \u0026quot;IfNotPresent\u0026quot; # Identify which Secret contains the credentials for pulling an image #imagePullSecrets: #- name: # Identify which Secret contains the WebLogic Admin credentials (note that there is an example of # how to create that Secret at the end of this file) webLogicCredentialsSecret: name: domain1-weblogic-credentials # Whether to include the server out file into the pod's stdout, default is true includeServerOutInPodLog: true # Whether to enable log home # logHomeEnabled: false # The in-pod location for domain log, server logs, server out, and Node Manager log files # logHome: /shared/logs/domain1 # serverStartPolicy legal values are \u0026quot;NEVER\u0026quot;, \u0026quot;IF_NEEDED\u0026quot;, or \u0026quot;ADMIN_ONLY\u0026quot; # This determines which WebLogic Servers the operator will start up when it discovers this Domain # - \u0026quot;NEVER\u0026quot; will not start any server in the domain # - \u0026quot;ADMIN_ONLY\u0026quot; will start up only the administration server (no managed servers will be started) # - \u0026quot;IF_NEEDED\u0026quot; will start all non-clustered servers, including the administration server and clustered servers up to the replica count serverStartPolicy: \u0026quot;IF_NEEDED\u0026quot; serverPod: # an (optional) list of environment variable to be set on the servers env: - name: JAVA_OPTIONS value: \u0026quot;-Dweblogic.StdoutDebugEnabled=false\u0026quot; - name: USER_MEM_ARGS value: \u0026quot;-Djava.security.egd=file:/dev/./urandom -Xms64m -Xmx256m \u0026quot; # volumes: # - name: weblogic-domain-storage-volume # persistentVolumeClaim: # claimName: domain1-weblogic-sample-pvc # volumeMounts: # - mountPath: /shared # name: weblogic-domain-storage-volume # adminServer is used to configure the desired behavior for starting the administration server. adminServer: # serverStartState legal values are \u0026quot;RUNNING\u0026quot; or \u0026quot;ADMIN\u0026quot; # \u0026quot;RUNNING\u0026quot; means the listed server will be started up to \u0026quot;RUNNING\u0026quot; mode # \u0026quot;ADMIN\u0026quot; means the listed server will be start up to \u0026quot;ADMIN\u0026quot; mode serverStartState: \u0026quot;RUNNING\u0026quot; # adminService: # channels: # The Admin Server's NodePort # - channelName: default # nodePort: 30701 # Uncomment to export the T3Channel as a service # - channelName: T3Channel # clusters is used to configure the desired behavior for starting member servers of a cluster. # If you use this entry, then the rules will be applied to ALL servers that are members of the named clusters. clusters: - clusterName: cluster-1 serverStartState: \u0026quot;RUNNING\u0026quot; replicas: 2 # The number of managed servers to start for unlisted clusters # replicas: 1  Verify the domain To confirm that the domain was created, use this command:\n$ kubectl describe domain DOMAINUID -n NAMESPACE  Replace DOMAINUID with the domainUID and NAMESPACE with the actual namespace.\nHere is an example of the output of this command:\n$ kubectl describe domain domain1 Name: domain1 Namespace: default Labels: weblogic.domainUID=domain1 weblogic.resourceVersion=domain-v2 Annotations: \u0026lt;none\u0026gt; API Version: weblogic.oracle/v2 Kind: Domain Metadata: Cluster Name: Creation Timestamp: 2019-01-10T14:29:37Z Generation: 1 Resource Version: 3698533 Self Link: /apis/weblogic.oracle/v2/namespaces/default/domains/domain1 UID: 28655979-14e4-11e9-b751-fa163e855ac8 Spec: Admin Server: Server Pod: Annotations: Container Security Context: Env: Labels: Liveness Probe: Node Selector: Pod Security Context: Readiness Probe: Resources: Limits: Requests: Volume Mounts: Volumes: Server Service: Annotations: Labels: Server Start State: RUNNING Clusters: Cluster Name: cluster-1 Cluster Service: Annotations: Labels: Replicas: 2 Server Pod: Annotations: Container Security Context: Env: Labels: Liveness Probe: Node Selector: Pod Security Context: Readiness Probe: Resources: Limits: Requests: Volume Mounts: Volumes: Server Service: Annotations: Labels: Server Start State: RUNNING Domain Home: /u01/oracle/user_projects/domains/domain1 Domain Home In Image: true Image: domain-home-in-image:12.2.1.3 Image Pull Policy: IfNotPresent Include Server Out In Pod Log: true Managed Servers: Server Pod: Annotations: Container Security Context: Env: Name: JAVA_OPTIONS Value: -Dweblogic.StdoutDebugEnabled=false Name: USER_MEM_ARGS Value: -Xms64m -Xmx256m Labels: Liveness Probe: Node Selector: Pod Security Context: Readiness Probe: Resources: Limits: Requests: Volume Mounts: Volumes: Server Service: Annotations: Labels: Server Start Policy: IF_NEEDED Web Logic Credentials Secret: Name: domain1-weblogic-credentials Status: Conditions: Last Transition Time: 2019-01-10T14:31:10.681Z Reason: ServersReady Status: True Type: Available Servers: Health: Activation Time: 2019-01-10T14:30:47.432Z Overall Health: ok Subsystems: Node Name: slc16ffk Server Name: admin-server State: RUNNING Cluster Name: cluster-1 Health: Activation Time: 2019-01-10T14:32:01.467Z Overall Health: ok Subsystems: Node Name: slc16ffk Server Name: managed-server1 State: RUNNING Cluster Name: cluster-1 Health: Activation Time: 2019-01-10T14:32:04.532Z Overall Health: ok Subsystems: Node Name: slc16ffk Server Name: managed-server2 State: RUNNING Start Time: 2019-01-10T14:29:37.455Z Events: \u0026lt;none\u0026gt;  In the Status section of the output, the available servers and clusters are listed. Note that if this command is issued very soon after the script finishes, there may be no servers available yet, or perhaps only the Administration Server but no Managed Servers. The operator will start up the Administration Server first and wait for it to become ready before starting the Managed Servers.\nVerify the pods Use the following command to see the pods running the servers:\n$ kubectl get pods -n NAMESPACE  Here is an example of the output of this command:\n$ kubectl get pods NAME READY STATUS RESTARTS AGE domain1-admin-server 1/1 Running 0 30m domain1-managed-server1 1/1 Running 0 29m domain1-managed-server2 1/1 Running 0 29m  Verify the services Use the following command to see the services for the domain:\n$ kubectl get services -n NAMESPACE  Here is an example of the output of this command:\n$ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE domain1-admin-server ClusterIP None \u0026lt;none\u0026gt; 7001/TCP 32m domain1-cluster-cluster-1 ClusterIP 10.99.151.142 \u0026lt;none\u0026gt; 8001/TCP 31m domain1-managed-server1 ClusterIP None \u0026lt;none\u0026gt; 8001/TCP 31m domain1-managed-server2 ClusterIP None \u0026lt;none\u0026gt; 8001/TCP 22m  Delete the domain The generated YAML file in the /path/to/weblogic-operator-output-directory/weblogic-domains/\u0026lt;domainUID\u0026gt; directory can be used to delete the Kubernetes resource. Use the following command to delete the domain:\n$ kubectl delete -f domain.yaml  "
},
{
	"uri": "/weblogic-kubernetes-operator/samples/simple/domains/",
	"title": "Domains",
	"tags": [],
	"description": "",
	"content": "These samples show various choices for working with domains.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/developerguide/building/",
	"title": "Building",
	"tags": [],
	"description": "",
	"content": " The operator is built using Apache Maven. The build machine will also need to have Docker installed.\nTo build the operator, issue the following command in the project directory:\n$ mvn clean install  This will compile the source files, build JAR files containing the compiled classes and libraries needed to run the operator, and will also execute all of the unit tests.\nContributions must conform to coding and formatting standards. To automatically update local code to conform to formatting standards, issue the following command:\n$ mvn fmt:format  Building Javadoc To build the Javadoc for the operator, issue the following command:\n$ mvn javadoc:javadoc  The Javadoc is also available in the GitHub repository here.\nBuilding the operator Docker image Log in to the Docker Store so that you will be able to pull the base image and create the Docker image as follows. These commands should be executed in the project root directory:\n$ docker login $ docker build --build-arg VERSION=\u0026lt;version\u0026gt; -t weblogic-kubernetes-operator:some-tag --no-cache=true .  Replace \u0026lt;version\u0026gt; with the version of the project found in the pom.xml file in the project root directory.\nIf you have not used the base image (store/oracle/serverjre:8) before, you will need to visit the Docker Store web interface and accept the license agreement before the Docker Store will give you permission to pull that image.\n\rWe recommend that you use a tag other than latest, to make it easy to distinguish your image. In the example above, the tag could be the GitHub ID of the developer.\nRunning the operator from an IDE The operator can be run from an IDE, which is useful for debugging. In order to do so, the machine running the IDE must be configured with a Kubernetes configuration file in ~/.kube/config or in a location pointed to by the KUBECONFIG environment variable.\nConfigure the IDE to run the class oracle.kubernetes.operator.Main.\nYou may need to create a directory called /operator on your machine. Please be aware that the operator code is targeted to Linux, and although it will run fine on macOS, it will probably not run on other operating systems. If you develop on another operating system, you should deploy the operator to a Kubernetes cluster and use remote debugging instead.\nRunning the operator in a Kubernetes cluster If you\u0026rsquo;re not running Kubernetes on your development machine, you\u0026rsquo;ll need to make the Docker image available to a registry visible to your Kubernetes cluster. Either docker push the image to a private registry or upload your image to a machine running Docker and Kubernetes as follows:\n# on your build machine $ docker save weblogic-kubernetes-operator:some-tag \u0026gt; operator.tar $ scp operator.tar YOUR_USER@YOUR_SERVER:/some/path/operator.tar # on the Kubernetes server $ docker load \u0026lt; /some/path/operator.tar  Use the Helm charts to install the operator.\nIf the operator\u0026rsquo;s behavior or pod log is insufficient to diagnose and resolve failures, then you can connect a Java debugger to the operator using the debugging options.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-operators/using-the-operator/the-rest-api/",
	"title": "The REST API",
	"tags": [],
	"description": "Use the operator&#39;s REST services",
	"content": " Use the operator\u0026rsquo;s REST services The operator provides a REST server which you can use to get a list of WebLogic domains and clusters and to initiate scaling operations. Swagger documentation for the REST API is available here.\nYou can access most of the REST services using GET, for example:\n To obtain a list of domains, send a GET request to the URL /operator/latest/domains To obtain a list of clusters in a domain, send a GET request to the URL /operator/latest/domains/\u0026lt;domainUID\u0026gt;/clusters  All of the REST services require authentication. Callers must pass in a valid token header and a CA certificate file. Callers should pass in the Accept:/application/json header.\nTo protect against Cross Site Request Forgery (CSRF) attacks, the operator REST API requires that you send in a X-Requested-By header when you invoke a REST endpoint that makes a change (for example when you POST to the /scale endpoint). The value is an arbitrary name such as MyClient. For example, when using curl:\ncurl ... -H X-Requested-By:MyClient ... -X POST .../scaling  If you do not pass in the X-Requested-By header, then you\u0026rsquo;ll get a 400 (bad request) response without any details explaining why the request is bad. The X-Requested-By header is not needed for requests that only read, for example when you GET any of the operator\u0026rsquo;s REST endpoints.\nBefore using the sample script below, you must:\n Update it to ensure it has the correct service account, namespaces, etc., and it points to the values.yaml that you used to install the operator (so that it can get the certificates). Add your operator\u0026rsquo;s certificate to your operating system\u0026rsquo;s trust store (see below). If you are using a self-signed certificate and your client is macOS, you may need to update the version of curl you have installed. The version of CURL that ships with macOS High Sierra (curl 7.54.0 (x86_64-apple-darwin17.0) libcurl/7.54.0 LibreSSL/2.0.20 zlib/1.2.11 nghttp2/1.24.0) has known issues with self-signed certificates. Oracle recommends curl 7.63.0 (x86_64-apple-darwin17.7.0) libcurl/7.63.0 SecureTransport zlib/1.2.11 which can be installed with brew install curl.  How to add your certificate to your operating system trust store For macOS, find the certificate in Finder, and double-click on it. This will add it to your keystore and open Keychain Access. Find the certificate in Keychain Access and double-click on it to open the details. Open the \u0026ldquo;Trust\u0026rdquo; pull-down menu and set the value of \u0026ldquo;When using this certificate\u0026rdquo; to \u0026ldquo;Always Trust\u0026rdquo;, then close the detail window and enter your password when prompted.\nFor Oracle Linux, run the script below once to copy the certificate into /tmp/operator.cert.pem then run these commands to add the certificate to the trust store:\n$ sudo cp /tmp/operator.cert.pem /etc/pki/ca-trust/source/anchors/ $ sudo update-ca-trust enable; sudo update-ca-trust extract $ openssl x509 -noout -hash -in /tmp/operator.cert.pem $ sudo ln -s /etc/pki/ca-trust/source/anchors/operator.cert.pem /etc/pki/tls/certs/e242d2da.0  In the final command, the filename e242d2da.0 should be the output of the previous command plus the suffix .0.\nPlease consult your operating system\u0026rsquo;s documentation (or Google) for other operating systems.\nSample operator REST client script Here is a small sample BASH script that may help to prepare the necessary token, certificates, and such, to call the operator\u0026rsquo;s REST services. Please read the important caveats above before using this script:\n#!/bin/bash KUBERNETES_SERVER=$1 URL_TAIL=$2 REST_PORT=`kubectl get services -n weblogic-operator -o jsonpath='{.items[?(@.metadata.name == \u0026quot;external-weblogic-operator-svc\u0026quot;)].spec.ports[?(@.name == \u0026quot;rest\u0026quot;)].nodePort}'` REST_ADDR=\u0026quot;https://${KUBERNETES_SERVER}:${REST_PORT}\u0026quot; SECRET=`kubectl get serviceaccount weblogic-operator -n weblogic-operator -o jsonpath='{.secrets[0].name}'` ENCODED_TOKEN=`kubectl get secret ${SECRET} -n weblogic-operator -o jsonpath='{.data.token}'` TOKEN=`echo ${ENCODED_TOKEN} | base64 --decode` OPERATOR_CERT_DATA=`grep externalOperatorCert weblogic-operator.yaml | awk '{ print $2 }'` OPERATOR_CERT_FILE=\u0026quot;/tmp/operator.cert.pem\u0026quot; echo ${OPERATOR_CERT_DATA} | base64 --decode \u0026gt; ${OPERATOR_CERT_FILE} cat ${OPERATOR_CERT_FILE} echo \u0026quot;Ready to call operator REST APIs\u0026quot; STATUS_CODE=`curl \\ -v \\ --cacert ${OPERATOR_CERT_FILE} \\ -H \u0026quot;Authorization: Bearer ${TOKEN}\u0026quot; \\ -H Accept:application/json \\ -X GET ${REST_ADDR}/${URL_TAIL} \\ -o curl.out \\ --stderr curl.err \\ -w \u0026quot;%{http_code}\u0026quot;` cat curl.err cat curl.out | jq .  You can use the -k option to bypass the check to verify that the operator\u0026rsquo;s certificate is trusted (instead of curl --cacert), but this is insecure.\n\rTo use this script, pass in the Kubernetes server address and then the URL you want to call. The script assumes jq is installed and uses it to format the response. This can be removed if desired. The script also prints out quite a bit of useful debugging information in addition to the response. Here is an example of the output of this script:\n$ ./rest.sh kubernetes001 operator/latest/domains/domain1/clusters Ready to call operator REST APIs Note: Unnecessary use of -X or --request, GET is already inferred. % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0* Trying 10.139.151.214... * TCP_NODELAY set * Connected to kubernetes001 (10.1.2.3) port 31001 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * Cipher selection: ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH * error setting certificate verify locations, continuing anyway: * CAfile: /tmp/operator.cert.pem CApath: none * TLSv1.2 (OUT), TLS handshake, Client hello (1): } [512 bytes data] * TLSv1.2 (IN), TLS handshake, Server hello (2): { [81 bytes data] * TLSv1.2 (IN), TLS handshake, Certificate (11): { [799 bytes data] * TLSv1.2 (IN), TLS handshake, Server key exchange (12): { [413 bytes data] * TLSv1.2 (IN), TLS handshake, Server finished (14): { [4 bytes data] * TLSv1.2 (OUT), TLS handshake, Client key exchange (16): } [150 bytes data] * TLSv1.2 (OUT), TLS change cipher, Client hello (1): } [1 bytes data] * TLSv1.2 (OUT), TLS handshake, Finished (20): } [16 bytes data] * TLSv1.2 (IN), TLS change cipher, Client hello (1): { [1 bytes data] * TLSv1.2 (IN), TLS handshake, Finished (20): { [16 bytes data] * SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256 * ALPN, server did not agree to a protocol * Server certificate: * subject: CN=weblogic-operator * start date: Jan 18 16:30:01 2018 GMT * expire date: Jan 16 16:30:01 2028 GMT * issuer: CN=weblogic-operator * SSL certificate verify result: unable to get local issuer certificate (20), continuing anyway. \u0026gt; GET /operator/latest/domains/domain1/clusters HTTP/1.1 \u0026gt; Host: kubernetes001:31001 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJ3ZWJsb2dpYy1vcGVyYXRvciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQ (truncated) 1vcGVyYXRvcjp3ZWJsb2dpYy1vcGVyYXRvciJ9.NgaGR0NbzbJpVXguQDjRKyDBnNTqwgwPEXv3NjWwMcaf0OlN54apHubdrIx6KYz9ONGz-QeTLnoMChFY7oWA6CBfbvjt-GQX6JvdoJYxsQo1pt-E6sO2YvqTFE4EG-gpEDaiCE_OjZ_bBpJydhIiFReToA3-mxpDAUK2_rUfkWe5YEaLGMWoYQfXPAykzFiH4vqIi_tzzyzNnGxI2tUcBxNh3tzWFPGXKhzG18HswiwlFU5pe7XEYv4gJbvtV5tlGz7YdmH74Rc0dveV-54qHD_VDC5M7JZVh0ZDlyJMAmWe4YcdwNQQNGs91jqo1-JEM0Wj8iQSDE3cZj6MB0wrdg \u0026gt; Accept:application/json \u0026gt; 0 0 0 0 0 0 0 0 --:--:-- 0:00:01 --:--:-- 0\u0026lt; HTTP/1.1 200 OK \u0026lt; Content-Type: application/json \u0026lt; Content-Length: 463 \u0026lt; { [463 bytes data] 100 463 100 463 0 0 205 0 0:00:02 0:00:02 --:--:-- 205 * Connection #0 to host kubernetes001 left intact { \u0026quot;links\u0026quot;: [ { \u0026quot;rel\u0026quot;: \u0026quot;self\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;href\u0026quot;: \u0026quot;/operator/latest/domains/domain1/clusters\u0026quot; }, { \u0026quot;rel\u0026quot;: \u0026quot;canonical\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;href\u0026quot;: \u0026quot;/operator/latest/domains/domain1/clusters\u0026quot; }, { \u0026quot;rel\u0026quot;: \u0026quot;parent\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;href\u0026quot;: \u0026quot;/operator/latest/domains/domain1\u0026quot; } ], \u0026quot;items\u0026quot;: [ { \u0026quot;links\u0026quot;: [ { \u0026quot;rel\u0026quot;: \u0026quot;self\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;href\u0026quot;: \u0026quot;/operator/latest/domains/domain1/clusters/cluster-1\u0026quot; }, { \u0026quot;rel\u0026quot;: \u0026quot;canonical\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;href\u0026quot;: \u0026quot;/operator/latest/domains/domain1/clusters/cluster-1\u0026quot; } ], \u0026quot;cluster\u0026quot;: \u0026quot;cluster-1\u0026quot; } ] }  "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/domain-lifecycle/scaling/",
	"title": "Scaling",
	"tags": [],
	"description": "",
	"content": " WebLogic Server supports two types of clustering configurations, configured and dynamic. Configured clusters are created by manually configuring each individual Managed Server instance. In dynamic clusters, the Managed Server configurations are generated from a single, shared template. With dynamic clusters, when additional server capacity is needed, new server instances can be added to the cluster without having to manually configure them individually. Also, unlike configured clusters, scaling up of dynamic clusters is not restricted to the set of servers defined in the cluster but can be increased based on runtime demands. For more information on how to create, configure, and use dynamic clusters in WebLogic Server, see Dynamic Clusters.\nThe following blogs provide more in-depth information on support for scaling WebLogic clusters in Kubernetes:\n Automatic Scaling of WebLogic Clusters on Kubernetes WebLogic Dynamic Clusters on Kubernetes  The operator provides several ways to initiate scaling of WebLogic clusters, including:\n On-demand, updating the domain resource directly (using kubectl). Calling the operator\u0026rsquo;s REST scale API, for example, from curl. Using a WLDF policy rule and script action to call the operator\u0026rsquo;s REST scale API. Using a Prometheus alert action to call the operator\u0026rsquo;s REST scale API.  On-demand, updating the domain resource directly The easiest way to scale a WebLogic cluster in Kubernetes is to simply edit the replicas property within a domain resource. This can be done by using the kubectl command-line interface for running commands against Kubernetes clusters. More specifically, you can modify the domain resource directly by using the kubectl edit command. For example:\n$ kubectl edit domain domain1 -n [namespace]  Here we are editing a domain resource named domain1. The kubectl edit command will open the domain resource definition in an editor and allow you to modify the replicas value directly. Once committed, the operator will be notified of the change and will immediately attempt to scale the corresponding dynamic cluster by reconciling the number of running pods/Managed Server instances with the replicas value specification.\nspec: ... clusters: - clusterName: cluster-1 replicas: 1 ...  Alternatively, you can specify a default replicas value for all the clusters. If you do this, then you don\u0026rsquo;t need to list the cluster in the domain resource (unless you want to customize another property of the cluster).\nspec: ... replicas: 1 ...  Calling the operator\u0026rsquo;s REST scale API Scaling up or scaling down a WebLogic cluster provides increased reliability of customer applications as well as optimization of resource usage. In Kubernetes cloud environments, scaling WebLogic clusters involves scaling the corresponding pods in which WebLogic Managed Server instances are running. Because the operator manages the life cycle of a WebLogic domain, the operator exposes a REST API that allows an authorized actor to request scaling of a WebLogic cluster.\nThe following URL format is used for describing the resources for scaling (up and down) a WebLogic cluster:\nhttp(s)://${OPERATOR_ENDPOINT}/operator/\u0026lt;version\u0026gt;/domains/\u0026lt;domainUID\u0026gt;/clusters/\u0026lt;clusterName\u0026gt;/scale  For example:\nhttp(s)://${OPERATOR_ENDPOINT}/operator/v1/domains/domain1/clusters/cluster-1/scale  In this URL format:\n OPERATOR_ENDPOINT is the host and port of the operator REST endpoint (internal or external). \u0026lt;version\u0026gt; denotes the version of the REST resource. \u0026lt;domainUID\u0026gt; is the unique identifier of the WebLogic domain. \u0026lt;clusterName\u0026gt; is the name of the WebLogic cluster to be scaled.  The /scale REST endpoint accepts an HTTP POST request and the request body supports the JSON \u0026quot;application/json\u0026quot; media type. The request body will be a simple name-value item named managedServerCount; for example:\n{ \u0026quot;managedServerCount\u0026quot;: 3 }  The managedServerCount value designates the number of WebLogic Server instances to scale to. Note that the scale resource is implemented using the JAX-RS framework, and so a successful scaling request will return an HTTP response code of 204 (“No Content”) because the resource method’s return type is void and does not return a message body.\nWhen you POST to the /scale REST endpoint, you must send the following headers:\n X-Requested-By request value. The value is an arbitrary name such as MyClient.\n Authorization: Bearer request value. The value of the Bearer token is the WebLogic domain service account token.  For example, when using curl:\ncurl -v -k -H X-Requested-By:MyClient -H Content-Type:application/json -H Accept:application/json -H \u0026quot;Authorization:Bearer ...\u0026quot; -d '{ \u0026quot;managedServerCount\u0026quot;: 3 }' https://.../scaling  If you omit the header, you\u0026rsquo;ll get a 400 (bad request) response without any details explaining why the request was bad. If you omit the Bearer Authentication header, then you\u0026rsquo;ll get a 401 (Unauthorized) response.\nOperator REST endpoints The WebLogic Kubernetes Operator can expose both an internal and external REST HTTPS endpoint. The internal REST endpoint is only accessible from within the Kubernetes cluster. The external REST endpoint is accessible from outside the Kubernetes cluster. The internal REST endpoint is enabled by default and thus always available, whereas the external REST endpoint is disabled by default and only exposed if explicitly configured. Detailed instructions for configuring the external REST endpoint are available here.\nRegardless of which endpoint is being invoked, the URL format for scaling is the same.\n\rWhat does the operator do in response to a scaling request? When the operator receives a scaling request, it will:\n Perform an authentication and authorization check to verify that the specified user is allowed to perform the specified operation on the specified resource. Validate that the specified domain, identified by domainUID, exists. Validate that the WebLogic cluster, identified by clusterName, exists. Verify that the specified WebLogic cluster has a sufficient number of configured servers to satisfy the scaling request. Initiate scaling by setting the replicas property within the corresponding domain resource, which can be done in either:  A cluster entry, if defined within its cluster list. At the domain level, if not defined in a cluster entry.   In response to a change to either replicas property, in the domain resource, the operator will increase or decrease the number of pods (Managed Servers) to match the desired replica count.\nUsing a WLDF policy rule and script action to call the operator\u0026rsquo;s REST scale API The WebLogic Diagnostics Framework (WLDF) is a suite of services and APIs that collect and surface metrics that provide visibility into server and application performance. To support automatic scaling of WebLogic clusters in Kubernetes, WLDF provides the Policies and Actions component, which lets you write policy expressions for automatically executing scaling operations on a cluster. These policies monitor one or more types of WebLogic Server metrics, such as memory, idle threads, and CPU load. When the configured threshold in a policy is met, the policy is triggered, and the corresponding scaling action is executed. The WebLogic Kubernetes Operator project provides a shell script, scalingAction.sh, for use as a Script Action, which illustrates how to issue a request to the operator’s REST endpoint.\nConfigure automatic scaling of WebLogic clusters in Kubernetes with WLDF The following steps are provided as a guideline on how to configure a WLDF Policy and Script Action component for issuing scaling requests to the operator\u0026rsquo;s REST endpoint:\n Copy the scalingAction.sh script to a directory (such as $DOMAIN_HOME/bin/scripts) so that it\u0026rsquo;s accessible within the Administration Server pod.\n Configure a WLDF policy and action as part of a diagnostic module targeted to the Administration Server. For information about configuring the WLDF Policies and Actions component, see Configuring Policies and Actions in Configuring and Using the Diagnostics Framework for Oracle WebLogic Server.\na. Configure a WLDF policy with a rule expression for monitoring WebLogic Server metrics, such as memory, idle threads, and CPU load for example.\nb. Configure a WLDF script action and associate the scalingAction.sh script.\n  Important notes about the configuration properties for the Script Action:\nThe scalingAction.sh script requires access to the SSL certificate of the operator’s endpoint and this is provided through the environment variable INTERNAL_OPERATOR_CERT.\nThe operator’s SSL certificate can be found in the internalOperatorCert entry of the operator’s ConfigMap weblogic-operator-cm:\nFor example:\n#\u0026gt; kubectl describe configmap weblogic-operator-cm -n weblogic-operator ... Data ==== internalOperatorCert: ---- LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUR3akNDQXFxZ0F3SUJBZ0lFRzhYT1N6QU... ...  The scalingAction.sh script accepts a number of customizable parameters:\n action - scaleUp or scaleDown (Required)\n domain_uid - WebLogic domain unique identifier (Required)\n cluster_name - WebLogic cluster name (Required)\n kubernetes_master - Kubernetes master URL, default=https://kubernetes\n  Set this to https://kubernetes.default.svc when invoking scalingAction.sh from the Administration Server pod.\n\r access_token - Service Account Bearer token for authentication and authorization for access to REST Resources\n wls_domain_namespace - Kubernetes namespace in which the WebLogic domain is defined, default=default\n operator_service_name - WebLogic Operator Service name of the REST endpoint, default=internal-weblogic-operator-service\n operator_service_account - Kubernetes Service Account name for the WebLogic Operator, default=weblogic-operator\n operator_namespace – Namespace in which the WebLogic Operator is deployed, default=weblogic-operator\n scaling_size – Incremental number of WebLogic Server instances by which to scale up or down, default=1\n  You can use any of the following tools to configure policies for diagnostic system modules:\n WebLogic Server Administration Console WLST REST JMX application\n  A more in-depth description and example on using WLDF\u0026rsquo;s Policies and Actions component for initiating scaling requests through the operator\u0026rsquo;s REST endpoint can be found in the blogs:\n Automatic Scaling of WebLogic Clusters on Kubernetes WebLogic Dynamic Clusters on Kubernetes  Create cluster role bindings to allow a namespace user to query WLS Kubernetes cluster information The script scalingAction.sh, specified in the WLDF script action above, needs the appropriate RBAC permissions granted for the service account user (in the namespace in which the WebLogic domain is deployed) in order to query the Kubernetes API server for both configuration and runtime information of the domain resource. The following is an example YAML file for creating the appropriate Kubernetes cluster role bindings:\nIn the example cluster role binding definition below, the WebLogic domain is deployed to a namespace weblogic-domain. Replace the namespace value with the name of the namespace in which the WebLogic domain is deployed in your Kubernetes environment.\n\rkind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: weblogic-domain-cluster-role rules: - apiGroups: [\u0026quot;weblogic.oracle\u0026quot;] resources: [\u0026quot;domains\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;, \u0026quot;update\u0026quot;] --- # # creating role-bindings for cluster role # kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: domain-cluster-rolebinding subjects: - kind: ServiceAccount name: default namespace: weblogic-domain apiGroup: \u0026quot;\u0026quot; roleRef: kind: ClusterRole name: weblogic-domain-cluster-role apiGroup: \u0026quot;rbac.authorization.k8s.io\u0026quot; --- # # creating role-bindings # kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: weblogic-domain-operator-rolebinding namespace: weblogic-operator subjects: - kind: ServiceAccount name: default namespace: weblogic-domain apiGroup: \u0026quot;\u0026quot; roleRef: kind: ClusterRole name: cluster-admin apiGroup: \u0026quot;rbac.authorization.k8s.io\u0026quot; ---  Using a Prometheus alert action to call the operator\u0026rsquo;s REST scale API In addition to using the WebLogic Diagnostic Framework for automatic scaling of a dynamic cluster, you can use a third-party monitoring application like Prometheus. Please read the following blog for details about Using Prometheus to Automatically Scale WebLogic Clusters on Kubernetes.\nHelpful Tips Debugging scalingAction.sh The scalingAction.sh script was designed to be executed within the Administration Server pod because the associated diagnostic module is targed to the Administration Server.\nThe easiest way to verify and debug the scalingAction.sh script is to open a shell on the running Administration Server pod and execute the script on the command line.\nThe following example illustrates how to open a bash shell on a running Administration Server pod named domain1-admin-server and execute the scriptAction.sh script. It assumes that:\n The domain home is in /u01/oracle/user-projects/domains/domain1 (that is, the domain home is inside a Docker image). The Dockerfile copied scalingAction.sh to /u01/oracle/user-projects/domains/domain1/bin/scripts/scalingAction.sh.  \u0026gt; kubectl exec -it domain1-admin-server /bin/bash # bash\u0026gt; cd /u01/oracle/user-projects/domains/domain1/bin/scripts # bash\u0026gt; ./scalingAction.sh  A log, scalingAction.log, will be generated in the same directory in which the script was executed and can be examined for errors.\nExample on accessing the external REST endpoint The easiest way to test scaling using the external REST endpoint is to use a command-line tool like curl. Using curl to issue an HTTPS scale request requires these mandatory header properties:\n Bearer Authorization token SSL certificate for the operator\u0026rsquo;s external REST endpoint X-Requested-By header value  The following shell script is an example of how to issue a scaling request, with the necessary HTTP request header values, using curl. This example assumes the operator and domain resource are configured with the following properties in Kubernetes:\n Operator properties:  externalRestEnabled: true externalRestHttpsPort: 31001 operator\u0026rsquo;s namespace: weblogic-operator operator\u0026rsquo;s hostname is the same as the host shell script is executed on.  Domain resource properties:\n WebLogic cluster name: DockerCluster Domain UID: domain1   #!/bin/sh # Setup properties ophost=`uname -n` opport=31001 #externalRestHttpsPort cluster=cluster-1 size=3 #New cluster size ns=weblogic-operator # Operator NameSpace sa=weblogic-operator # Operator ServiceAccount domainuid=domain1 # Retrieve service account name for given namespace sec=`kubectl get serviceaccount ${sa} -n ${ns} -o jsonpath='{.secrets[0].name}'` #echo \u0026quot;Secret [${sec}]\u0026quot; # Retrieve base64 encoded secret for the given service account enc_token=`kubectl get secret ${sec} -n ${ns} -o jsonpath='{.data.token}'` #echo \u0026quot;enc_token [${enc_token}]\u0026quot; # Decode the base64 encoded token token=`echo ${enc_token} | base64 --decode` #echo \u0026quot;token [${token}]\u0026quot; # clean up any temporary files rm -rf operator.rest.response.body operator.rest.stderr operator.cert.pem # Retrieve SSL certificate from the Operator's external REST endpoint `openssl s_client -showcerts -connect ${ophost}:${opport} \u0026lt;/dev/null 2\u0026gt;/dev/null | openssl x509 -outform PEM \u0026gt; operator.cert.pem` echo \u0026quot;Rest EndPoint url https://${ophost}:${opport}/operator/v1/domains/${domainuid}/clusters/${cluster}/scale\u0026quot; # Issue 'curl' request to external REST endpoint curl --noproxy '*' -v --cacert operator.cert.pem \\ -H \u0026quot;Authorization: Bearer ${token}\u0026quot; \\ -H Accept:application/json \\ -H \u0026quot;Content-Type:application/json\u0026quot; \\ -H \u0026quot;X-Requested-By:WLDF\u0026quot; \\ -d \u0026quot;{\\\u0026quot;managedServerCount\\\u0026quot;: $size}\u0026quot; \\ -X POST https://${ophost}:${opport}/operator/v1/domains/${domainuid}/clusters/${cluster}/scale \\ -o operator.rest.response.body \\ --stderr operator.rest.stderr  "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/domain-in-image/domain-images/",
	"title": "Domain Images",
	"tags": [],
	"description": "",
	"content": "Oracle strongly recommends storing a domain image as private in the registry. A Docker image that contains a WebLogic Domain Home has sensitive information including keys and credentials that are used to access external resources (e.g. datasource password). For more information about domain home in image protection see the Security section.\n\r"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/domain-in-image/",
	"title": "Domain in Image",
	"tags": [],
	"description": "",
	"content": "Lorem Ipsum.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-operators/",
	"title": "Manage Operators",
	"tags": [],
	"description": "Helm is used to create and deploy necessary operator resources and to run the operator in a Kubernetes cluster.",
	"content": " Overview Helm is a framework that helps you manage Kubernetes applications, and Helm charts help you define and install Helm applications into a Kubernetes cluster. The operator\u0026rsquo;s Helm chart is located in the kubernetes/charts/weblogic-operator directory.\nIf you have an older version of the operator installed on your cluster, then you must remove it before installing this version. This includes the 2.0-rc1 version; it must be completely removed. You should remove the deployment (for example, kubectl delete deploy weblogic-operator -n your-namespace) and the custom resource definition (for example, kubectl delete crd domain). If you do not remove the custom resource definition, then you might see errors like this:\nError from server (BadRequest): error when creating \u0026quot;/scratch/output/uidomain/weblogic-domains/uidomain/domain.yaml\u0026quot;: the API version in the data (weblogic.oracle/v2) does not match the expected API version (weblogic.oracle/v1  \rYou should be able to upgrade from version 2.0-rc2 to 2.0 because there are no backward incompatible changes between these two releases.\n\rInstall Helm and Tiller Helm has two parts: a client (Helm) and a server (Tiller). Tiller runs inside of your Kubernetes cluster, and manages releases (installations) of your charts. See https://github.com/kubernetes/helm/blob/master/docs/install.md for detailed instructions on installing Helm and Tiller.\nIn order to use Helm to install and manage the operator, you need to ensure that the service account that Tiller uses has the cluster-admin role. The default would be default in namespace kube-system. You can give that service account the necessary permissions with this command:\ncat \u0026lt;\u0026lt; EOF | kubectl apply -f - apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: helm-user-cluster-admin-role roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: default namespace: kube-system EOF  Oracle strongly recommends that you create a new service account to be used exclusively by Tiller and grant cluster-admin to that service account, rather than using the default one.\n\rOperator\u0026rsquo;s Helm Chart Configuration The operator Helm chart is pre-configured with default values for the configuration of the operator.\nYou can override these values by doing one of the following:\n Creating a custom YAML file with only the values to be overridden, and specifying the --value option on the Helm command line. Overriding individual values directly on the Helm command line, using the --set option.  You can find out the configuration values that the Helm chart supports, as well as the default values, using this command:\n$ helm inspect values kubernetes/charts/weblogic-operator  The available configuration values are explained by category in Operator Helm configuration values.\nHelm commands are explained in more detail in Useful Helm operations.\nOptional: Configure the operator\u0026rsquo;s external REST HTTPS interface The operator can expose an external REST HTTPS interface which can be accessed from outside the Kubernetes cluster. As with the operator\u0026rsquo;s internal REST interface, the external REST interface requires an SSL/TLS certificate and private key that the operator will use as the identity of the external REST interface (see below).\nTo enable the external REST interface, configure these values in a custom configuration file, or on the Helm command line:\n Set externalRestEnabled to true. Set externalRestIdentitySecret to the name of the kubernetes tls secret that contains the certificate(s) and private key. Optionally, set externalRestHttpsPort to the external port number for the operator REST interface (defaults to 31001).  More detailed information about REST interface configuration values can be found from the operator Helm configuration values.\nSample SSL certificate and private key for the REST interface For testing purposes, the WebLogic Kubernetes Operator project provides a sample script that generates a self-signed certificate and private key for the operator external REST interface. The generated certificate and key is stored in a kubernetes tls secret and the sample script outputs the corresponding configuration values in YAML format. These values can be added to your custom YAML configuration file, for use when the operator\u0026rsquo;s Helm chart is installed.\nThe sample script should not be used in a production environment because typically a self-signed certificate for external communucation is not considered safe. A certficate signed by a commercial certificate authority is more widely accepted and should contain valid host names, expiration dates and key constraints.\n\rMore detailed information about the sample script and how to run the script can be found in the Samples section under the REST APIs.\nOptional: Elastic Stack (Elasticsearch, Logstash, and Kibana) integration The operator Helm chart includes the option of installing the necessary Kubernetes resources for Elastic Stack integration.\nYou are responsible for configuring Kibana and Elasticsearch, then configuring the operator Helm chart to send events to Elasticsearch. In turn, the operator Helm chart configures Logstash in the operator deployment to send the operator\u0026rsquo;s log contents to that Elasticsearch location.\nElastic Stack per-operator configuration As part of the Elastic Stack integration, Logstash configuration occurs for each deployed operator instance. You can use the following configuration values to configure the integration:\n Set elkIntegrationEnabled is true to enable the integration. Set logStashImage to override the default version of Logstash to be used (logstash:6.2). Set elasticSearchHost and elasticSearchPort to override the default location where Elasticsearch is running (elasticsearch2.default.svc.cluster.local:9201). This will configure Logstash to send the operator\u0026rsquo;s log contents there.  More detailed information about configuration values can be found in Operator Helm configuration values.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/quickstart/get-images/",
	"title": "Get images",
	"tags": [],
	"description": "",
	"content": " Get these images and put them into your local registry.  If you don\u0026rsquo;t already have one, obtain a Docker store account, log in to the Docker store and accept the license agreement for the WebLogic Server image.\n Log in to the Docker store from your Docker client:\n$ docker login  Pull the operator image:\n$ docker pull oracle/weblogic-kubernetes-operator:2.0-rc2  Pull the Traefik load balancer image:\n$ docker pull traefik:1.7.6  Pull the WebLogic 12.2.1.3 install image:\n$ docker pull store/oracle/weblogic:12.2.1.3  The existing WebLogic Docker image, store/oracle/weblogic:12.2.1.3, was updated on January 17, 2019, and has all the necessary patches applied; a docker pull is required if you pulled the image prior to that date.\n\r Copy the image to all the nodes in your cluster, or put it in a Docker registry that your cluster can access.\n  "
},
{
	"uri": "/weblogic-kubernetes-operator/samples/",
	"title": "Samples",
	"tags": [],
	"description": "",
	"content": "The samples are divided into two types: Simple and Production.\nThe simple samples provide demonstrations of how to accomplish common tasks. These samples are provided for educational and demonstration purposes only; they are not intended to be used in production deployments or to be depended upon to create production environments.\nThe production samples\u0026hellip;\nWhile these samples may be useful and usable as is, it is intended that you would read through all of the sample code in detail, understand how the given sample works, and then customize it to suit your needs.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/introduction/design/",
	"title": "Design philosophy",
	"tags": [],
	"description": "",
	"content": "The Oracle WebLogic Server Kubernetes Operator (the “operator”) is designed to fulfill a similar role to that which a human operator would fill in a traditional data center deployment. It contains a set of useful built-in knowledge about how to perform various life cycle operations on a domain correctly.\nHuman operators are normally responsible for starting and stopping environments, initiating backups, performing scaling operations, performing manual tasks associated with disaster recovery and high availability needs and coordinating actions with other operators in other data centers. It is envisaged that the operator will have similar responsibilities in a Kubernetes environment.\nIt is important to note the distinction between an operator and an administrator. A WebLogic Server administrator typically has different responsibilities centered around managing the detailed configuration of the WebLogic domains. The operator has only limited interest in the domain configuration, with its main concern being the high-level topology of the domain; for example, how many clusters and servers, and information about network access points, such as channels.\nHuman operators may manage more than one domain, and the operator is also designed to be able to manage more than one domain. Like its human counterpart, the operator will only take actions against domains that it is told to manage, and will ignore any other domains that may be present in the same environment.\nLike a human operator, the operator is designed to be event-based. It waits for a significant event to occur, or for a scheduled time to perform some action, and then takes the appropriate action. Examples of significant events include being made aware of a new domain that needs to be managed, receiving a request to scale up a WebLogic cluster, or receiving a request to perform a backup of a domain.\nThe operator is designed with security in mind from the outset. Some examples of the specific security practices we follow are:\n During the deployment of the operator, Kubernetes roles are defined and assigned to the operator. These roles are designed to give the operator the minimum amount of privileges that it requires to perform its tasks. The code base is regularly scanned with security auditing tools and any issues that are identified are promptly resolved. All HTTP communications – between the operator and an external client, between the operator and WebLogic Administration Servers, and so on – are configured to require SSL and TLS 1.2. Unused code is pruned from the code base regularly. Dependencies are kept as up-to-date as possible and are regularly reviewed for security vulnerabilities.  The operator is designed to avoid imposing any arbitrary restriction on how WebLogic Server may be configured or used in Kubernetes. Where there are restrictions, these are based on the availability of some specific feature in Kubernetes; for example, multicast support.\nThe operator learns of WebLogic domains through instances of a domain Kubernetes resource. When the operator is installed, it creates a Kubernetes Custom Resource Definition. This custom resource definition defines the domain resource type. After this type is defined, you can manage domain resources using kubectl just like any other resource type. For instance, kubectl get domain or kubectl edit domain domain1.\nSchema for domain resources is here.\nThe schema for the domain resource is designed to be as sparse as possible. It includes the connection details for the Administration Server, but all of the other content is operational details about which servers should be started, environment variables, and details about what should be exposed outside the Kubernetes cluster. This way, the WebLogic domain\u0026rsquo;s configuration remains the normative configuration.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/accessing-the-domain/applications/",
	"title": "Applications",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/security/service-accounts/",
	"title": "Service Accounts",
	"tags": [],
	"description": "Kubernetes service accounts for the WebLogic Operator",
	"content": "TODO\n"
},
{
	"uri": "/weblogic-kubernetes-operator/samples/simple/rest/",
	"title": "REST APIs",
	"tags": [],
	"description": "",
	"content": " Sample to create certificate and key When a user enables the operator\u0026rsquo;s external REST API (by setting externalRestEnabled to true when installing or upgrading the operator Helm chart), the user also needs to provide the certificate(s) and private key used for the SSL/TLS identity on the external REST API endpoint by creating a kubernetes tls secret and using that secret\u0026rsquo;s name with the operator Helm chart values.\nThis sample script generates a self-signed certificate and private key that can be used for the operator\u0026rsquo;s external REST API when experimenting with the operator.\nThe certificate and key generated with this script should not be used in a production environment.\n\rThe syntax of the script is:\n$ kubernetes/samples/scripts/rest/generate-external-rest-identity.sh \\ -a \u0026lt;SANs\u0026gt; -n \u0026lt;operator-namespace\u0026gt; [-s \u0026lt;secret-name\u0026gt;]  Where \u0026lt;SANs\u0026gt; lists the subject alternative names to put into the generated self-signed certificate for the external WebLogic Operator REST HTTPS interface, \u0026lt;operator-namespace\u0026gt; should match the namespace where the operator will be installed, and optionally the secret name, which defaults to weblogic-operator-external-rest-identity.\nYou should include the addresses of all masters and load balancers (i.e. what a client specifies to access the external REST endpoint) in the subject alternative name list. In addition, each name must be prefaced by DNS: for a host name, or IP: for an address, as with this example:\n-a \u0026quot;DNS:myhost,DNS:localhost,IP:127.0.0.1\u0026quot;  The external certificate and key can be changed after installation of the operator, for more information see updating operator external certificate in the Security section.\nThe script as used below will create the tls secret named weblogic-operator-identity in the namespace weblogic-operator-ns using a self-signed certificate and private key:\n$ echo \u0026quot;externalRestEnabled: true\u0026quot; \u0026gt; my_values.yaml $ generate-external-rest-identity.sh \\ -a \u0026quot;DNS:${HOSTNAME},DNS:localhost,IP:127.0.0.1\u0026quot; \\ -n weblogic-operator-ns -s weblogic-operator-identity \u0026gt;\u0026gt; my_values.yaml # $ kubectl -n weblogic-operator-ns describe secret weblogic-operator-identity # $ helm install kubernetes/charts/weblogic-operator --name my_operator \\ --namespace weblogic-operator-ns --values my_values.yaml --wait  "
},
{
	"uri": "/weblogic-kubernetes-operator/developerguide/integration-tests/",
	"title": "Integration Tests",
	"tags": [],
	"description": "",
	"content": "The project includes integration tests that can be run against a Kubernetes cluster. If you want to use these tests, you will need to provide your own Kubernetes cluster. The Kubernetes cluster must meet the version number requirements and have Helm installed. Ensure that the operator Docker image is in a Docker registry visible to the Kubernetes cluster.\nYou will need to obtain the kube.config file for an administrative user and make it available on the machine running the build. To run the tests, update the KUBECONFIG environment variable to point to your config file and then execute:\n$ mvn clean verify -P java-integration-tests  When you run the integrations tests, they do a cleanup of any operator or domains on that cluster.\n\r"
},
{
	"uri": "/weblogic-kubernetes-operator/developerguide/branching/",
	"title": "Branching",
	"tags": [],
	"description": "",
	"content": "The master branch is protected and contains source for the most recently published release, including release candidates.\nThe develop branch is protected and contains source for the latest completed features and bug fixes. While this branch contains active work, we expect to keep it always \u0026ldquo;ready to release.\u0026rdquo; Therefore, longer running feature work will be performed on specific branches, such as feature/dynamic-clusters.\nBecause we want to balance separating destabilizing work into feature branches against the possibility of later difficult merges, we encourage developers working on features to pull out any necessary refactoring or improvements that are general purpose into their own shorter-lived branches and create pull requests to develop when these smaller work items are completed.\nAll commits to develop must pass the integration test suite. Please run these tests locally before submitting a pull request. Additionally, each push to a branch in our GitHub repository triggers a run of a subset of the integration tests with the results visible here.\nPlease submit pull requests to the develop branch unless you are collaborating on a feature and have another target branch. Please see details on the Oracle Contributor Agreement (OCA) and guidelines for pull requests on the README.\nWe will create git tags for each release candidate and generally available (GA) release of the operator.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-operators/using-the-operator/lifecycle/",
	"title": "Life Cycle",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/domain-lifecycle/",
	"title": "Domain Life Cycle",
	"tags": [],
	"description": "",
	"content": "This section describes how you can start, stop, restart, and scale the domain\u0026rsquo;s servers.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/",
	"title": "Manage Domains",
	"tags": [],
	"description": "Important considerations for WebLogic domains in Kubernetes",
	"content": " Please be aware of the following important considerations for WebLogic domains running in Kubernetes.  Domain Home Location: The WebLogic domain home location is determined by the domain resource domainHome if set; otherwise, a default location is determined by the domainHomeInImage setting. If a domain resource domainHome field is not set and domainHomeInImage is true (the default), then the operator will assume that the domain home is a directory under /u01/oracle/user_projects/domains/ and report an error if no domain is found or more than one domain is found. If a domain resource domainHome field is not set and domainHomeInImage is false, then the operator will assume that the domain home is /shared/domains/DOMAIN_UID. Oracle strongly recommends storing an image containing a WebLogic Domain Home as private in the registry (e.g. Oracle Cloud Infrastructure Registry, Docker Hub, etc.). A Docker image that contains a WebLogic Domain has sensitive information including keys and credentials that are used access external resources (e.g. datasource password). For more information about domain home in image protection see the Security section.\n\r Log File Locations: The operator can automatically override WebLogic domain and server log locations using situational configuration overrides. This occurs if the domain resource logHomeEnabled field is explicitly set to true, or if logHomeEnabled isn\u0026rsquo;t set and domainHomeInImage is explicitly set to false. When overriding, the log location will be the location specified by the logHome setting.\n Listen Address Overrides: The operator will automatically override all WebLogic domain default, SSL, admin, or custom channel listen addresses (using situational configuration overrides). These will become domainUID followed by a hyphen and then the server name, all lower case, and underscores converted to hyphens. For example, if domainUID=domain1 and the WebLogic server name is Admin_Server, then its listen address becomes domain1-admin-server.\n Domain, Cluster, Server, and Network-Access-Point Names: WebLogic domain, cluster, server, and network-access-point (channel) names must contain only the characters A-Z, a-z, 0-9, -, or _. This ensures that they can be converted to meet Kubernetes resource and DNS1123 naming requirements. (When generating pod and service names, the operator will convert configured names to lower case and substitute a hyphen (-) for each underscore (_).)\n Node Ports: If you choose to expose any WebLogic channels outside the Kubernetes cluster via a NodePort, for example, the administration port or a T3 channel to allow WLST access, you need to ensure that you allocate each channel a unique port number across the entire Kubernetes cluster. If you expose the administration port in each WebLogic domain in the Kubernetes cluster, then each one must have a different port. This is required because NodePorts are used to expose channels outside the Kubernetes cluster.\nExposing admin, RMI, or T3 capable channels via a Kubernetes NodePort can create an insecure configuration. In general, only HTTP protocols should be made available externally and this exposure is usually accomplished by setting up an external load balancer that can access internal (non-NodePort) services. For more information about T3 channels see the Security section.\n\r Host Path Persistent Volumes: If using a hostPath persistent volume, then it must be available on all worker nodes in the cluster and have read/write/many permissions for all container/pods in the WebLogic Server deployment. Be aware that many cloud provider\u0026rsquo;s volume providers may not support volumes across availability zones. You may want to use NFS or a clustered file system to work around this limitation.\n Security Note: The USER_MEM_ARGS environment variable defaults to -Djava.security.egd=file:/dev/./urandom in all WebLogic Server pods and the WebLogic introspection job. It can be explicitly set to another value in your domain resource YAML file using the env attribute under the serverPod configuration.\n  The following features are not certified or supported in this release:\n Whole Server Migration Consensus Leasing Node Manager (although it is used internally for the liveness probe and to start WebLogic Server instances) Multicast Multitenancy Production redeployment  Please consult My Oracle Support Doc ID 2349228.1 for up-to-date information about the features of WebLogic Server that are supported in Kubernetes environments.\nCreating and managing WebLogic domains You can locate a WebLogic domain either in a persistent volume (PV) or in a Docker image. For examples of each, see the WebLogic operator samples.\nIf you want to create your own Docker images, for example, to choose a specific set of patches or to create a domain with a specific configuration and/or applications deployed, then you can create the domain custom resource manually to deploy your domain. This process is documented in this sample.\nModifying domain configurations You can modify the WebLogic domain configuration for both the \u0026ldquo;domain in persistent volume\u0026rdquo; and the \u0026ldquo;domain in image\u0026rdquo; options before deploying a domain resource:\n When the domain is in a persistent volume, you can use WLST or WDT to change the configuration. For either case, you can use configuration overrides.\n  Configuration overrides allow changing a configuration without modifying its original config.xml or system resource XML files, and also support parameterizing overrides so that you can inject values into them from Kubernetes secrets. For example, you can inject database user names, passwords, and URLs that are stored in a secret.\nAbout the domain resource For information about the domain resource, see Domain resource.\nManaging life cycle operations You can perform life cycle operations on WebLogic servers, clusters, or domains. See Starting, stopping, and restarting servers and Restarting WebLogic servers.\nScaling clusters The operator let\u0026rsquo;s you initiate scaling of clusters in various ways:\n Using kubectl to edit the domain resource Using the operator\u0026rsquo;s REST APIs Using WLDF policies Using a Prometheus action  "
},
{
	"uri": "/weblogic-kubernetes-operator/quickstart/install/",
	"title": "Install the operator and load balancer",
	"tags": [],
	"description": "",
	"content": " Grant the Helm service account the cluster-admin role. $ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: helm-user-cluster-admin-role roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: default namespace: kube-system EOF  Create a Traefik (Ingress-based) load balancer. Use helm to install the Traefik load balancer. Use the values.yaml in the sample but set kubernetes.namespaces specifically.\n$ helm install stable/traefik \\ --name traefik-operator \\ --namespace traefik \\ --values kubernetes/samples/charts/traefik/values.yaml \\ --set \u0026quot;kubernetes.namespaces={traefik}\u0026quot; \\ --wait  Install the operator.  Create a namespace for the operator:\n$ kubectl create namespace sample-weblogic-operator-ns  Create a service account for the operator in the operator\u0026rsquo;s namespace:\n$ kubectl create serviceaccount -n sample-weblogic-operator-ns sample-weblogic-operator-sa  Use helm to install and start the operator from the directory you just cloned:\n$ helm install kubernetes/charts/weblogic-operator \\ --name sample-weblogic-operator \\ --namespace sample-weblogic-operator-ns \\ --set image=oracle/weblogic-kubernetes-operator:2.0-rc2 \\ --set serviceAccount=sample-weblogic-operator-sa \\ --set \u0026quot;domainNamespaces={}\u0026quot; \\ --wait  Verify that the operator\u0026rsquo;s pod is running, by listing the pods in the operator\u0026rsquo;s namespace. You should see one for the operator.\n$ kubectl get pods -n sample-weblogic-operator-ns  Verify that the operator is up and running by viewing the operator pod\u0026rsquo;s log:\n$ kubectl logs -n sample-weblogic-operator-ns -c weblogic-operator deployments/weblogic-operator   "
},
{
	"uri": "/weblogic-kubernetes-operator/developerguide/",
	"title": "Developer Guide",
	"tags": [],
	"description": "",
	"content": " Developer Guide The Developer Guide provides information for developers who want to understand or contribute to the code.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/accessing-the-domain/",
	"title": "Accessing the Domain",
	"tags": [],
	"description": "",
	"content": "Lorem Ipsum.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/samples/simple/ingress/",
	"title": "Ingress",
	"tags": [],
	"description": "",
	"content": "Lorem Ipsum.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/developerguide/coding-standards/",
	"title": "Coding Standards",
	"tags": [],
	"description": "",
	"content": " This project has adopted the following coding standards:\n Code will be formated using Oracle / WebLogic standards, which are identical to the Google Java Style. Javadoc must be provided for all public packages, classes, and methods, and must include all parameters and returns. Javadoc is not required for methods that override or implement methods that are already documented. All non-trivial methods should include LOGGER.entering() and LOGGER.exiting() calls. The LOGGER.exiting() call should include the value that is going to be returned from the method, unless that value includes a credential or other sensitive information. All logged messages must be internationalized using the resource bundle src/main/resources/Operator.properties and using a key itemized in src/main/java/oracle/kubernetes/operator/logging/MessageKeys.java. After operator initialization, all operator work must be implemented using the asynchronous call model (described below). In particular, worker threads must not use sleep() or IO or lock-based blocking methods.  Code formatting plugins The following IDE plugins are available to assist with following the code formatting standards\nIntelliJ An IntelliJ plugin is available from the plugin repository.\nThe plugin will be enabled by default. To disable it in the current project, go to File \u0026gt; Settings... \u0026gt; google-java-format Settings (or IntelliJ IDEA \u0026gt; Preferences... \u0026gt; Other Settings \u0026gt; google-java-format Settings on macOS) and uncheck the \u0026ldquo;Enable google-java-format\u0026rdquo; checkbox.\nTo disable it by default in new projects, use File \u0026gt; Other Settings \u0026gt; Default Settings....\nWhen enabled, it will replace the normal \u0026ldquo;Reformat Code\u0026rdquo; action, which can be triggered from the \u0026ldquo;Code\u0026rdquo; menu or with the Ctrl-Alt-L (by default) keyboard shortcut.\nThe import ordering is not handled by this plugin, unfortunately. To fix the import order, download the IntelliJ Java Google Style file and import it into File→Settings→Editor→Code Style.\nEclipse An Eclipse plugin can be downloaded from the releases page. Drop it into the Eclipse drop-ins folder to activate the plugin.\nThe plugin adds a google-java-format formatter implementation that can be configured in Eclipse \u0026gt; Preferences \u0026gt; Java \u0026gt; Code Style \u0026gt; Formatter \u0026gt; Formatter Implementation.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/security/rbac/",
	"title": "RBAC",
	"tags": [],
	"description": "Role based authorization for the WebLogic Operator",
	"content": " The operator assumes that certain roles and role bindings are created on the Kubernetes cluster. The operator installation scripts create these, and the operator verifies that they are correct when the cluster starts up. This document lists the RBAC definitions that are created.\nThe general design goal is to provide the operator with the minimum amount of permissions that it requires, and to favor built-in roles over custom roles, where it make sense to do so.\nKubernetes role definitions    Cluster role Resources Verbs Notes     NAMESPACE-weblogic-operator-clusterrole-general namespaces, persistentvolumes get, list, watch 1    customresourcedefinitions in API group apiextensions.k8s.io get, list, watch, create, update, patch, delete, deletecollection     domains in API group weblogic.oracle get, list, watch, update, patch     Ingresses in API group extensions get, list, watch, create, update, patch, delete, deletecollection    NAMESPACE-weblogic-operator-clusterrole-nonresource nonResourceURLs: [\u0026ldquo;/version/*\u0026ldquo;] get 1   NAMESPACE-weblogic-operator-clusterrole-namespace secrets, persistentvolumeclaims get, list, watch 2    services, pods, networkpolicies get, list, watch, create, update, patch, delete, deletecollection    NAMESPACE-weblogic-operator-clusterrolebinding-discovery system:discovery in API group rbac.authorization.k8s.io  1   NAMESPACE-weblogic-operator-clusterrolebinding-auth-delegator system:auth-delegator in API group rbac.authorization.k8s.io  1    Notes:\n This cluster role is assigned to the operator’s service account in the operator’s namespace. The uppercase text NAMESPACE in the cluster role name is replaced with the operator’s namespace. This cluster role is assigned to the operator’s service account in each of the “target namespaces”; that is, each namespace that the operator is configured to manage.  "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-operators/using-the-operator/logs/",
	"title": "Logs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/reference/",
	"title": "Reference",
	"tags": [],
	"description": "",
	"content": " Chapter 5 Reference This section contains links to reference documentation.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/quickstart/prepare/",
	"title": "Prepare for a domain",
	"tags": [],
	"description": "",
	"content": " Create a namespace that can host one or more domains:\n$ kubectl create namespace sample-domain1-ns  Use helm to configure the operator to manage domains in this namespace:\n$ helm upgrade \\ --reuse-values \\ --set \u0026quot;domainNamespaces={sample-domain1-ns}\u0026quot; \\ --wait \\ sample-weblogic-operator \\ kubernetes/charts/weblogic-operator  Configure Traefik to manage Ingresses created in this namespace:\n$ helm upgrade \\ --reuse-values \\ --set \u0026quot;kubernetes.namespaces={traefik,sample-domain1-ns}\u0026quot; \\ --wait \\ traefik-operator \\ stable/traefik   "
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/ingress/",
	"title": "Ingress",
	"tags": [],
	"description": "",
	"content": "Lorem Ipsum.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/security/secrets/",
	"title": "Secrets",
	"tags": [],
	"description": "Kubernetes secrets for the WebLogic Operator",
	"content": "TODO\n"
},
{
	"uri": "/weblogic-kubernetes-operator/security/",
	"title": "Security",
	"tags": [],
	"description": "",
	"content": " Chapter 6 Security \rCertificates\r\rWebLogic Operator SSL/TLS certificate handling\n\rDomain Security\r\rWebLogic Domain security and the WebLogic Operator\n\rEncryption\r\rWebLogic Domain encryption and the WebLogic Operator\n\rService Accounts\r\rKubernetes service accounts for the WebLogic Operator\n\rRBAC\r\rRole based authorization for the WebLogic Operator\n\rSecrets\r\rKubernetes secrets for the WebLogic Operator\n\r"
},
{
	"uri": "/weblogic-kubernetes-operator/samples/simple/elastic-stack/",
	"title": "Elastic Stack",
	"tags": [],
	"description": "",
	"content": " Sample to deploy Elasticsearch and Kibana When you install the WebLogic operator Helm chart, you can set elkIntegrationEnabled to true in your values.yaml file to tell the operator to send the contents of the operator\u0026rsquo;s logs to Elasticsearch.\nTypically, you would have already configured Elasticsearch and Kibana in the Kubernetes cluster, and also would have specified elasticSearchHost and elasticSearchPort in your values.yaml file to point to where Elasticsearch is already running.\nThis sample configures the Elasticsearch and Kibana deployments and services. It\u0026rsquo;s useful for trying out the operator in a Kubernetes cluster that doesn\u0026rsquo;t already have them configured.\nIt runs the Elastic Stack on the same host and port that the operator\u0026rsquo;s Helm chart defaults to, therefore, you only need to set elkIntegrationEnabled to true in your values.yaml file.\nTo control Elasticsearch memory parameters (Heap allocation and Enabling/Disabling swapping) please open the file elasticsearch_and_kibana.yaml, search for env variables of the elasticsearch container and change the values of the following.\n ES_JAVA_OPTS: value may contain for example -Xms512m -Xmx512m to lower the default memory usage (please be aware that this value is only applicable for demo purpose and it is not the one recommended by Elasticsearch itself) bootstrap.memory_lock: value may contain true (enables the usage of mlockall to try to lock the process address space into RAM, preventing any Elasticsearch memory from being swapped out) or false (disables the usage of mlockall to try to lock the process address space into RAM, preventing any Elasticsearch memory from being swapped out).  To install Elasticsearch and Kibana, use:\n$ kubectl apply -f kubernetes/samples/scripts/elasticsearch-and-kibana/elasticsearch_and_kibana.yaml  To remove them, use:\n$ kubectl delete -f kubernetes/samples/scripts/elasticsearch-and-kibana/elasticsearch_and_kibana.yaml  "
},
{
	"uri": "/weblogic-kubernetes-operator/developerguide/code-structure/",
	"title": "Code Structure",
	"tags": [],
	"description": "",
	"content": " This project has the following directory structure:\n docs: Generated Javadoc and Swagger integration-tests: Integration test suite json-schema: Java model to JSON schema generator json-schema-maven-plugin: Maven plugin for schema generator kubernetes/charts: Helm charts kubernetes/samples: All samples, including for WebLogic domain creation model: Domain resource Java model operator: Operator runtime site: This documentation src/scripts: Scripts operator injects into WebLogic server instance Pods swagger: Swagger files for the Kubernetes API server and domain resource  Watch package The Watch API in the Kubernetes Java client provides a watch capability across a specific list of resources for a limited amount of time. As such, it is not ideally suited for our use case, where a continuous stream of watches is desired, with watch events generated in real time. The watch-wrapper in this repository extends the default Watch API to provide a continuous stream of watch events until the stream is specifically closed. It also provides resourceVersion tracking to exclude events that have already been seen. The watch-wrapper provides callbacks so events, as they occur, can trigger actions.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/quickstart/create-domain/",
	"title": "Create a domain",
	"tags": [],
	"description": "",
	"content": " Create a Kubernetes secret containing the username and password for the domain using the create-weblogic-credentials script:\n$ kubernetes/samples/scripts/create-weblogic-domain-credentials/create-weblogic-credentials.sh \\ -u weblogic -p welcome1 -n sample-domain1-ns -d sample-domain1  The sample will create a secret named domainUID-weblogic-credentials where the domainUID is replaced with the value you provided. For example, the command above would create a secret named sample-domain1-weblogic-credentials.\n Create a new image with a domain home by running the create-domain script. Follow the directions in the README file, including:\n Copying the sample kubernetes/samples/scripts/create-weblogic-domain/domain-home-in-image/create-domain-inputs.yaml file and updating your copy with the domainUID (sample-domain1), domain namespace (sample-domain1-ns), and the domainHomeImageBase (store/oracle/weblogic:12.2.1.3).\n Setting weblogicCredentialsSecretName to the name of the secret containing the WebLogic credentials, in this case, sample-domain1-weblogic-credentials.\n Leaving the image empty unless you need to tag the new image that the script builds to a different name. If you set the domainHomeImageBuildPath property to ./docker-images/OracleWebLogic/samples/12213-domain-home-in-image-wdt, make sure that your JAVA_HOME is set to a Java JDK version 1.8 or later.\n\r  For example, assuming you named your copy my-inputs.yaml:\n$ cd kubernetes/samples/scripts/create-weblogic-domain/domain-home-in-image $ ./create-domain.sh -i my-inputs.yaml -o /some/output/directory -u weblogic -p welcome1 -e  You need to provide the WebLogic administration user name and password in the -u and -p options respectively, as shown in the example. When using this sample, the WebLogic Server credentials that you specify, in three separate places, must be consistent:\n The secret that you create for the credentials. The properties files in the sample project you choose to create the Docker image from. The parameters you supply to the create-domain.sh script.  \rIf you specify the -e option, the script will generate the Kubernetes YAML files and apply them to your cluster. If you omit the -e option, the script will just generate the YAML files, but will not take any action on your cluster.\nIf you run the sample from a machine that is remote to the Kubernetes cluster, and you need to push the new image to a registry that is local to the cluster, you need to do the following:\n Set the image property in the inputs file to the target image name (including the registry hostname/port, and the tag if needed). If you want Kubernetes to pull the image from a private registry, create a Kubernetes secret to hold your credentials and set the imagePullSecretName property in the inputs file to the name of the secret. The Kubernetes secret must be in the same namespace where the domain will be running. For more information see the Security section about domain home in image protection.\n\r Run the create-domain.sh script without the -e option. Push the image to the registry. Run the following command to create the domain.  $ kubectl apply -f /some/output/directory/weblogic-domains/sample-domain1/domain.yaml  Confirm that the operator started the servers for the domain:\na. Use kubectl to show that the domain resource was created:\n$ kubectl describe domain sample-domain1 -n sample-domain1-ns  b. After a short time, you will see the Administration Server and Managed Servers running.\n$ kubectl get pods -n sample-domain1-ns  c. You should also see all the Kubernetes services for the domain.\n$ kubectl get services -n sample-domain1-ns  Create an Ingress for the domain, in the domain namespace, by using the sample Helm chart:\n$ helm install kubernetes/samples/charts/ingress-per-domain \\ --name sample-domain1-ingress \\ --namespace sample-domain1-ns \\ --set wlsDomain.domainUID=sample-domain1 \\ --set traefik.hostname=sample-domain1.org  To confirm that the load balancer noticed the new Ingress and is successfully routing to the domain\u0026rsquo;s server pods, you can send a request to the URL for the \u0026ldquo;WebLogic ReadyApp framework\u0026rdquo; which will return a HTTP 200 status code, as shown in the example below. If you used the host-based routing Ingress sample, you will need to provide the hostname in the -H option.\nSubstitute the Node IP address of the worker node for your.server.com. You can find it by running:\n$ kubectl get po -n sample-domain1-ns -o wide  $ curl -v -H 'host: sample-domain1.org' http://your.server.com:30305/weblogic/ready About to connect() to your.server.com port 30305 (#0) Trying 10.196.1.64... Connected to your.server.com (10.196.1.64) port 30305 (#0) \u0026gt; GET /weblogic/ HTTP/1.1 \u0026gt; User-Agent: curl/7.29.0 \u0026gt; Accept: */* \u0026gt; host: domain1.org \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Content-Length: 0 \u0026lt; Date: Thu, 20 Dec 2018 14:52:22 GMT \u0026lt; Vary: Accept-Encoding \u0026lt; Connection #0 to host your.server.com left intact  Depending on where your Kubernetes cluster is running, you may need to open firewall ports or update security lists to allow ingress to this port.\n\r To access the WLS Administration Console, edit the my-inputs.yaml file (assuming that you named your copy my-inputs.yaml) to set exposedAdminNodePort: true. Open a browser to http://your.server.com:30701. As in the previous step, substitute the Node IP address of the worker node for your.server.com.\n  "
},
{
	"uri": "/weblogic-kubernetes-operator/developerguide/asynchronous-call-model/",
	"title": "Asynchronous Call Model",
	"tags": [],
	"description": "",
	"content": " Our expectation is that customers will task the operator with managing hundreds of WebLogic domains across dozens of Kubernetes namespaces. Therefore, we have designed the operator with an efficient user-level threads pattern. We\u0026rsquo;ve used that pattern to implement an asynchronous call model for Kubernetes API requests. This call model has built-in support for timeouts, retries with exponential back-off, and lists that exceed the requested maximum size using the continuance functionality.\nUser-Level Thread Pattern The user-level thread pattern is implemented by the classes in the oracle.kubernetes.operator.work package.\n Engine: The executor service and factory for Fibers. Fiber: The user-level thread. Fibers represent the execution of a single processing flow through a series of Steps. Fibers may be suspended and later resumed, and do not consume a Thread while suspended. Step: Individual CPU-bound activity in a processing flow. Packet: Context of the processing flow. NextAction: Used by a Step when it returns control to the Fiber to indicate what should happen next. Common \u0026lsquo;next actions\u0026rsquo; are to execute another Step or to suspend the Fiber. Component: Provider of SPI\u0026rsquo;s that may be useful to the processing flow. Container: Represents the containing environment and is a Component.  Each Step has a reference to the next Step in the processing flow; however, Steps are not required to indicate that the next Step be invoked by the Fiber when the Step returns a NextAction to the Fiber. This leads to common use cases where Fibers invoke a series of Steps that are linked by the \u0026lsquo;is-next\u0026rsquo; relationship, but just as commonly, use cases where the Fiber will invoke sets of Steps along a detour before returning to the normal flow.\nIn this sample, the caller creates an Engine, Fiber, linked set of Step instances, and Packet. The Fiber is then started. The Engine would typically be a singleton, since it\u0026rsquo;s backed by a ScheduledExecutorService. The Packet would also typically be pre-loaded with values that the Steps would use in their apply() methods.\nstatic class SomeClass { public static void main(String[] args) { Engine engine = new Engine(\u0026quot;worker-pool\u0026quot;); Fiber fiber = engine.createFiber(); Step step = new StepOne(new StepTwo(new StepThree(null))); Packet packet = new Packet(); fiber.start( step, packet, new CompletionCallback() { @Override public void onCompletion(Packet packet) { // Fiber has completed successfully } @Override public void onThrowable(Packet packet, Throwable throwable) { // Fiber processing was terminated with an exception } }); } }  Steps must not invoke sleep or blocking calls from within apply(). This prevents the worker threads from serving other Fibers. Instead, use asynchronous calls and the Fiber suspend/resume pattern. Step provides a method, doDelay(), which creates a NextAction to drive Fiber suspend/resume that is a better option than sleep precisely because the worker thread can serve other Fibers during the delay. For asynchronous IO or similar patterns, suspend the Fiber. In the callback as the Fiber suspends, initiate the asynchronous call. Finally, when the call completes, resume the Fiber. The suspend/resume functionality handles the case where resumed before the suspending callback completes.\nIn this sample, the step uses asynchronous file IO and the suspend/resume Fiber pattern.\nstatic class StepTwo extends Step { public StepTwo(Step next) { super(next); } @Override public NextAction apply(Packet packet) { return doSuspend((fiber) -\u0026gt; { // The Fiber is now suspended // Start the asynchronous call try { Path path = Paths.get(URI.create(this.getClass().getResource(\u0026quot;/somefile.dat\u0026quot;).toString())); AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.READ); ByteBuffer buffer = ByteBuffer.allocate(1024); fileChannel.read(buffer, 0, buffer, new CompletionHandler\u0026lt;Integer, ByteBuffer\u0026gt;() { @Override void completed(Integer result, ByteBuffer attachment) { // Store data in Packet and resume Fiber packet.put(\u0026quot;DATA_SIZE_READ\u0026quot;, result); packet.put(\u0026quot;DATA_FROM_SOMEFILE\u0026quot;, attachment); fiber.resume(packet); } @Override public void failed(Throwable exc, ByteBuffer attachment) { // log exc completed(0, null); } }); } catch (IOException e) { // log exception // If not resumed here, Fiber will never be resumed } }); } }  Call Builder Pattern The asynchronous call model is implemented by classes in the oracle.kubernetes.operator.helpers package, including CallBuilder and ResponseStep. The model is based on the Fiber suspend/resume pattern described above. CallBuilder provides many methods having names ending with \u0026ldquo;Async\u0026rdquo;, such as listPodAsync() or deleteServiceAsync(). These methods return a Step that can be returned as part of a NextAction. When creating these Steps, the developer must provide a ResponseStep. Only ResponseStep.onSuccess() must be implemented; however, it is often useful to override onFailure() as Kubernetes treats 404 (Not Found) as a failure.\nIn this sample, the developer is using the pattern to list pods from the default namespace that are labeled as part of cluster-1.\nstatic class StepOne extends Step { public StepOne(Step next) { super(next); } @Override public NextAction apply(Packet packet) { String namespace = \u0026quot;default\u0026quot;; Step step = CallBuilder.create().with($ -\u0026gt; { $.labelSelector = \u0026quot;weblogic.clusterName=cluster-1\u0026quot;; $.limit = 50; $.timeoutSeconds = 30; }).listPodAsync(namespace, new ResponseStep\u0026lt;V1PodList\u0026gt;(next) { @Override public NextAction onFailure(Packet packet, ApiException e, int statusCode, Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; responseHeaders) { if (statusCode == CallBuilder.NOT_FOUND) { return onSuccess(packet, null, statusCode, responseHeaders); } return super.onFailure(packet, e, statusCode, responseHeaders); } @Override NextAction onSuccess(Packet packet, V1PodList result, int statusCode, Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; responseHeaders) { // do something with the result Pod, if not null return doNext(packet); } }); return doNext(step, packet); } }  Notice that the required parameters, such as namespace, are method arguments, but optional parameters are designated using a simplified builder pattern using with() and a lambda.\nThe default behavior of onFailure() will retry with an exponential backoff the request on status codes 429 (TooManyRequests), 500 (InternalServerError), 503 (ServiceUnavailable), 504 (ServerTimeout) or a simple timeout with no response from the server.\nIf the server responds with status code 409 (Conflict), then this indicates an optimistic locking failure. Common use cases are that the code read a Kubernetes object in one asynchronous step, modified the object, and attempted to replace the object in another asynchronous step; however, another activity replaced that same object in the interim. In this case, retrying the request would give the same result. Therefore, developers may provide an \u0026ldquo;on conflict\u0026rdquo; step when calling super.onFailure(). The conflict step will be invoked after an exponential backoff delay. In this example, that conflict step should be the step that reads the existing Kubernetes object.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/integrations/",
	"title": "Integrations",
	"tags": [],
	"description": "",
	"content": "Lorem Ipsum.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/faq/",
	"title": "Frequently Asked Questions",
	"tags": [],
	"description": "",
	"content": " Chapter 7 Frequently Asked Questions This section provides answers to frequently asked questions.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/quickstart/cleanup/",
	"title": "Clean up",
	"tags": [],
	"description": "",
	"content": " Remove the domain.  Remove the domain\u0026rsquo;s Ingress by using helm:\n$ helm delete --purge sample-domain1-ingress  Remove the domain resources by using the sample delete-weblogic-domain-resources script.\n$ kubernetes/samples/scripts/delete-domain/delete-weblogic-domain-resources.sh -d sample-domain1  Use kubectl to confirm that the server pods and domain resource are gone:\n$ kubectl get pods -n sample-domain1-ns $ kubectl get domains -n sample-domain1-ns   Remove the domain namespace.  Configure the Traefik load balancer to stop managing the Ingresses in the domain namespace:\n$ helm upgrade \\ --reuse-values \\ --set \u0026quot;kubernetes.namespaces={traefik}\u0026quot; \\ --wait \\ traefik-operator \\ stable/traefik  Configure the operator to stop managing the domain:\n$ helm upgrade \\ --reuse-values \\ --set \u0026quot;domainNamespaces={}\u0026quot; \\ --wait \\ sample-weblogic-operator \\ kubernetes/charts/weblogic-operator  Delete the domain namespace:\n$ kubectl delete namespace sample-domain1-ns   Remove the operator.  Remove the operator:\n$ helm delete --purge sample-weblogic-operator  Remove the operator\u0026rsquo;s namespace:\n$ kubectl delete namespace sample-weblogic-operator-ns   Remove the load balancer.  Remove the Traefik load balancer:\n$ helm delete --purge traefik-operator  Remove the Traefik namespace:\n$ kubectl delete namespace traefik   "
},
{
	"uri": "/weblogic-kubernetes-operator/developerguide/domain-processing/",
	"title": "Domain Processing",
	"tags": [],
	"description": "",
	"content": "When the operator starts, it lists all existing Domain resources and processes these domains to create the necessary Kubernetes resources, such as Pods and Services, if they don\u0026rsquo;t already exist. This initialization also includes looking for any stranded resources that, while created by the operator, no longer correlate with a Domain resource.\nAfter this, the operator starts watches for changes to Domain resources and any changes to other resources created by the operator. When a watch event is received, the operator processes the modified Domain resource to again bring the runtime presence in to alignment with the desired state.\nThe operator ensures that at most one Fiber is running for any given Domain. For instance, if the customer modifies a Domain resource to trigger a rolling restart, then the operator will create a Fiber to process this activity. However, if while the rolling restart is in process, the customer makes another change to the Domain resource, such as to increase the replicas field for a cluster, then the operator will cancel the in-flight Fiber and replace it with a new Fiber. This replacement processing must be able to handle taking over for the cancelled work regardless of where the earlier processing may have been in its flow. Therefore, domain processing always starts at the beginning of the \u0026ldquo;make right\u0026rdquo; flow without any state other than the current Domain resource.\nFinally, the operator periodically lists all Domains and rechecks them. This is a backstop against the possibility that a watch event is missed, such as because of a temporary network outage. Recheck activities will not interrupt already running processes for a given Domain.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/developerguide/backwards-compatibility/",
	"title": "Backward Compatibility",
	"tags": [],
	"description": "",
	"content": "Starting with the 2.0 release, future operator releases must be backward compatible with respect to the domain resource schema, operator Helm chart input values, configuration overrides template, Kubernetes resources created by the operator Helm chart, Kubernetes resources created by the operator, and the operator REST interface. We will maintain compatibility for three releases, except in the case of a clearly communicated deprecated feature, which will be maintained for one release after a replacement is available.\n"
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/integrations/exporting-logs/elastic-stack/",
	"title": "Elastic Stack",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/userguide/managing-domains/integrations/exporting-logs/log-exporter/",
	"title": "Log Exporter",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Oracle WebLogic Server Kubernetes Operator Oracle is finding ways for organizations using WebLogic Server to run important workloads, to move those workloads into the cloud. By certifying on industry standards, such as Docker and Kubernetes, WebLogic now runs in a cloud neutral infrastructure. In addition, we\u0026rsquo;ve provided an open-source Oracle WebLogic Server Kubernetes Operator (the “operator”) which has several key features to assist you with deploying and managing WebLogic domains in a Kubernetes environment. You can:\n Create WebLogic domains in a Kubernetes persistent volume. This persistent volume can reside in an NFS file system or other Kubernetes volume types. Create a WebLogic domain in a Docker image. Override certain aspects of the WebLogic domain configuration. Define WebLogic domains as a Kubernetes resource (using a Kubernetes custom resource definition). Start servers based on declarative startup parameters and desired states. Manage WebLogic configured or dynamic clusters. Expose the WebLogic Server Administration Console outside the Kubernetes cluster, if desired. Expose T3 channels outside the Kubernetes domain, if desired. Expose HTTP paths on a WebLogic domain outside the Kubernetes domain with load balancing and update the load balancer when Managed Servers in the WebLogic domain are started or stopped. Scale WebLogic domains by starting and stopping Managed Servers on demand, or by integrating with a REST API to initiate scaling based on WLDF, Prometheus, Grafana, or other rules. Publish operator and WebLogic Server logs into Elasticsearch and interact with them in Kibana.  The fastest way to experience the operator is to follow the Quick Start guide, or you can peruse our documentation, read our blogs, or try out the samples.\n+ The current release of the operator is 2.0-rc2, a release candidate for our 2.0 release. + This release candidate was published on Jan. 16, 2019. + We expect to publish the final 2.0 release later in January, 2019. + We expect that there will be some minor changes to documentation and samples in the final 2.0 release. + However, this release candidate is suitable for testing and early adopters.  Known issues    Issue Description          Operator earlier versions Documentation for prior releases of the operator is available here.\nBackward compatibility guidelines The 2.0 release introduces some breaking changes and does not maintain compatibility with previous releases.\nStarting with the 2.0 release, future operator releases are intended to be backward compatible with respect to the domain resource schema, operator Helm chart input values, configuration overrides template, Kubernetes resources created by the operator Helm chart, Kubernetes resources created by the operator, and the operator REST interface. We intend to maintain compatibility for three releases, except in the case of a clearly communicated deprecated feature, which will be maintained for one release after a replacement is available.\nAbout this documentation This documentation includes sections targeted to different audiences. To help you find what you are looking for more easily, please consult this table of contents:\n The Quick Start guide explains how to quickly get the operator running, using the defaults, nothing special. The User guide contains detailed usage information, including how to install and configure the operator, and how to use it to create and manage WebLogic domains.\n The Samples provide detailed example code and instructions that show you how to perform various tasks related to the operator. The Developer guide provides details for people who want to understand how the operator is built, tested, and so on. Those who wish to contribute to the operator code will find useful information here. This section also includes API documentation (Javadoc) and Swagger/OpenAPI documentation for the REST APIs. The Contributing section provides information about contribution requirements.  User guide The User guide provides detailed information about all aspects of using the operator including:\n Installing and configuring the operator. Using the operator to create and manage WebLogic domains. Manually creating WebLogic domains to be managed by the operator. Scaling WebLogic clusters. Configuring Kubernetes load balancers. Configuring Elasticsearch and Kibana to access the operator\u0026rsquo;s log files. Shutting down domains. Removing/deleting domains. And much more!  Samples Please refer to our samples for information about the available sample code.\nNeed more help? Have a suggestion? Come and say, \u0026ldquo;Hello!\u0026rdquo; We have a public Slack channel where you can get in touch with us to ask questions about using the operator or give us feedback or suggestions about what features and improvements you would like to see. We would love to hear from you. To join our channel, please visit this site to get an invitation. The invitation email will include details of how to access our Slack workspace. After you are logged in, please come to #operator and say, \u0026ldquo;hello!\u0026rdquo;\nRecent changes See Recent changes for changes to the operator, including any backward incompatible changes.\nDeveloper guide Developers interested in this project are encouraged to read the Developer guide to learn how to build the project, run tests, and so on. The Developer guide also provides details about the structure of the code, coding standards, and the Asynchronous Call facility used in the code to manage calls to the Kubernetes API.\nPlease take a look at our wish list to get an idea of the kind of features we would like to add to the operator. Maybe you will see something to which you would like to contribute!\nAPI documentation Documentation for APIs:\n The operator provides a REST API that you can use to obtain configuration information and to initiate scaling actions. For details about how to use the REST APIs, see Using the operator\u0026rsquo;s REST services.\n See the Swagger documentation for the operator\u0026rsquo;s REST interface.\n See the Javadoc for the operator.\n  Contributing to the operator Oracle welcomes contributions to this project from anyone. Contributions may be reporting an issue with the operator or submitting a pull request. Before embarking on significant development that may result in a large pull request, it is recommended that you create an issue and discuss the proposed changes with the existing developers first.\nIf you want to submit a pull request to fix a bug or enhance an existing feature, please first open an issue and link to that issue when you submit your pull request.\nIf you have any questions about a possible submission, feel free to open an issue too.\nContributing to the Oracle WebLogic Server Kubernetes Operator repository Pull requests can be made under The Oracle Contributor Agreement (OCA), which is available at https://www.oracle.com/technetwork/community/oca-486395.html.\nFor pull requests to be accepted, the bottom of the commit message must have the following line, using the contributor’s name and e-mail address as it appears in the OCA Signatories list.\nSigned-off-by: Your Name \u0026lt;you@example.org\u0026gt;  This can be automatically added to pull requests by committing with:\ngit commit --signoff  Only pull requests from committers that can be verified as having signed the OCA can be accepted.\nPull request process  Fork the repository. Create a branch in your fork to implement the changes. We recommend using the issue number as part of your branch name, for example, 1234-fixes. Ensure that any documentation is updated with the changes that are required by your fix. Ensure that any samples are updated if the base image has been changed. Submit the pull request. Do not leave the pull request blank. Explain exactly what your changes are meant to do and provide simple steps on how to validate your changes. Ensure that you reference the issue you created as well. We will assign the pull request to 2-3 people for review before it is merged.  Introducing a new dependency Please be aware that pull requests that seek to introduce a new dependency will be subject to additional review. In general, contributors should avoid dependencies with incompatible licenses, and should try to use recent versions of dependencies. Standard security vulnerability checklists will be consulted before accepting a new dependency. Dependencies on closed-source code, including WebLogic Server, will most likely be rejected.\nUse Helm Chart from Github chart repository Add this repo to Helm installation:\n$ helm repo add weblogic-operator https://oracle.github.io/weblogic-kubernetes-operator/charts  Verify repository was added correctly:\n$ helm repo list NAME URL weblogic-operator https://oracle.github.io/weblogic-kubernetes-operator/charts  Update with latest information about charts from chart repositories:\n$ helm repo update  Install Operator from the repo:\n$ helm install weblogic-operator/weblogic-operator --name weblogic-operator  "
},
{
	"uri": "/weblogic-kubernetes-operator/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/weblogic-kubernetes-operator/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]